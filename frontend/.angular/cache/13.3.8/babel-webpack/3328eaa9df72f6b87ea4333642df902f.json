{"ast":null,"code":"import _asyncToGenerator from \"/Users/leonardo/Desktop/GIT/angular-crud/frontend/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { getApp, _getProvider, SDK_VERSION as SDK_VERSION$1, _registerComponent, registerVersion } from '@firebase/app';\nimport { Component } from '@firebase/component';\nimport { stringify, jsonEval, contains, assert, isNodeSdk, base64, stringToByteArray, Sha1, deepCopy, base64Encode, isMobileCordova, stringLength, Deferred, safeGet, isAdmin, isValidFormat, isEmpty, isReactNative, assertionError, map, querystring, errorPrefix, getModularInstance, createMockUserToken } from '@firebase/util';\nimport { Logger, LogLevel } from '@firebase/logger';\nconst name = \"@firebase/database\";\nconst version = \"0.13.2\";\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** The semver (www.semver.org) version of the SDK. */\n\nlet SDK_VERSION = '';\n/**\r\n * SDK_VERSION should be set before any database instance is created\r\n * @internal\r\n */\n\nfunction setSDKVersion(version) {\n  SDK_VERSION = version;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Wraps a DOM Storage object and:\r\n * - automatically encode objects as JSON strings before storing them to allow us to store arbitrary types.\r\n * - prefixes names with \"firebase:\" to avoid collisions with app data.\r\n *\r\n * We automatically (see storage.js) create two such wrappers, one for sessionStorage,\r\n * and one for localStorage.\r\n *\r\n */\n\n\nclass DOMStorageWrapper {\n  /**\r\n   * @param domStorage_ - The underlying storage object (e.g. localStorage or sessionStorage)\r\n   */\n  constructor(domStorage_) {\n    this.domStorage_ = domStorage_; // Use a prefix to avoid collisions with other stuff saved by the app.\n\n    this.prefix_ = 'firebase:';\n  }\n  /**\r\n   * @param key - The key to save the value under\r\n   * @param value - The value being stored, or null to remove the key.\r\n   */\n\n\n  set(key, value) {\n    if (value == null) {\n      this.domStorage_.removeItem(this.prefixedName_(key));\n    } else {\n      this.domStorage_.setItem(this.prefixedName_(key), stringify(value));\n    }\n  }\n  /**\r\n   * @returns The value that was stored under this key, or null\r\n   */\n\n\n  get(key) {\n    const storedVal = this.domStorage_.getItem(this.prefixedName_(key));\n\n    if (storedVal == null) {\n      return null;\n    } else {\n      return jsonEval(storedVal);\n    }\n  }\n\n  remove(key) {\n    this.domStorage_.removeItem(this.prefixedName_(key));\n  }\n\n  prefixedName_(name) {\n    return this.prefix_ + name;\n  }\n\n  toString() {\n    return this.domStorage_.toString();\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An in-memory storage implementation that matches the API of DOMStorageWrapper\r\n * (TODO: create interface for both to implement).\r\n */\n\n\nclass MemoryStorage {\n  constructor() {\n    this.cache_ = {};\n    this.isInMemoryStorage = true;\n  }\n\n  set(key, value) {\n    if (value == null) {\n      delete this.cache_[key];\n    } else {\n      this.cache_[key] = value;\n    }\n  }\n\n  get(key) {\n    if (contains(this.cache_, key)) {\n      return this.cache_[key];\n    }\n\n    return null;\n  }\n\n  remove(key) {\n    delete this.cache_[key];\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Helper to create a DOMStorageWrapper or else fall back to MemoryStorage.\r\n * TODO: Once MemoryStorage and DOMStorageWrapper have a shared interface this method annotation should change\r\n * to reflect this type\r\n *\r\n * @param domStorageName - Name of the underlying storage object\r\n *   (e.g. 'localStorage' or 'sessionStorage').\r\n * @returns Turning off type information until a common interface is defined.\r\n */\n\n\nconst createStoragefor = function (domStorageName) {\n  try {\n    // NOTE: just accessing \"localStorage\" or \"window['localStorage']\" may throw a security exception,\n    // so it must be inside the try/catch.\n    if (typeof window !== 'undefined' && typeof window[domStorageName] !== 'undefined') {\n      // Need to test cache. Just because it's here doesn't mean it works\n      const domStorage = window[domStorageName];\n      domStorage.setItem('firebase:sentinel', 'cache');\n      domStorage.removeItem('firebase:sentinel');\n      return new DOMStorageWrapper(domStorage);\n    }\n  } catch (e) {} // Failed to create wrapper.  Just return in-memory storage.\n  // TODO: log?\n\n\n  return new MemoryStorage();\n};\n/** A storage object that lasts across sessions */\n\n\nconst PersistentStorage = createStoragefor('localStorage');\n/** A storage object that only lasts one session */\n\nconst SessionStorage = createStoragefor('sessionStorage');\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nconst logClient = new Logger('@firebase/database');\n/**\r\n * Returns a locally-unique ID (generated by just incrementing up from 0 each time its called).\r\n */\n\nconst LUIDGenerator = function () {\n  let id = 1;\n  return function () {\n    return id++;\n  };\n}();\n/**\r\n * Sha1 hash of the input string\r\n * @param str - The string to hash\r\n * @returns {!string} The resulting hash\r\n */\n\n\nconst sha1 = function (str) {\n  const utf8Bytes = stringToByteArray(str);\n  const sha1 = new Sha1();\n  sha1.update(utf8Bytes);\n  const sha1Bytes = sha1.digest();\n  return base64.encodeByteArray(sha1Bytes);\n};\n\nconst buildLogMessage_ = function (...varArgs) {\n  let message = '';\n\n  for (let i = 0; i < varArgs.length; i++) {\n    const arg = varArgs[i];\n\n    if (Array.isArray(arg) || arg && typeof arg === 'object' && // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    typeof arg.length === 'number') {\n      message += buildLogMessage_.apply(null, arg);\n    } else if (typeof arg === 'object') {\n      message += stringify(arg);\n    } else {\n      message += arg;\n    }\n\n    message += ' ';\n  }\n\n  return message;\n};\n/**\r\n * Use this for all debug messages in Firebase.\r\n */\n\n\nlet logger = null;\n/**\r\n * Flag to check for log availability on first log message\r\n */\n\nlet firstLog_ = true;\n/**\r\n * The implementation of Firebase.enableLogging (defined here to break dependencies)\r\n * @param logger_ - A flag to turn on logging, or a custom logger\r\n * @param persistent - Whether or not to persist logging settings across refreshes\r\n */\n\nconst enableLogging$1 = function (logger_, persistent) {\n  assert(!persistent || logger_ === true || logger_ === false, \"Can't turn on custom loggers persistently.\");\n\n  if (logger_ === true) {\n    logClient.logLevel = LogLevel.VERBOSE;\n    logger = logClient.log.bind(logClient);\n\n    if (persistent) {\n      SessionStorage.set('logging_enabled', true);\n    }\n  } else if (typeof logger_ === 'function') {\n    logger = logger_;\n  } else {\n    logger = null;\n    SessionStorage.remove('logging_enabled');\n  }\n};\n\nconst log = function (...varArgs) {\n  if (firstLog_ === true) {\n    firstLog_ = false;\n\n    if (logger === null && SessionStorage.get('logging_enabled') === true) {\n      enableLogging$1(true);\n    }\n  }\n\n  if (logger) {\n    const message = buildLogMessage_.apply(null, varArgs);\n    logger(message);\n  }\n};\n\nconst logWrapper = function (prefix) {\n  return function (...varArgs) {\n    log(prefix, ...varArgs);\n  };\n};\n\nconst error = function (...varArgs) {\n  const message = 'FIREBASE INTERNAL ERROR: ' + buildLogMessage_(...varArgs);\n  logClient.error(message);\n};\n\nconst fatal = function (...varArgs) {\n  const message = `FIREBASE FATAL ERROR: ${buildLogMessage_(...varArgs)}`;\n  logClient.error(message);\n  throw new Error(message);\n};\n\nconst warn = function (...varArgs) {\n  const message = 'FIREBASE WARNING: ' + buildLogMessage_(...varArgs);\n  logClient.warn(message);\n};\n/**\r\n * Logs a warning if the containing page uses https. Called when a call to new Firebase\r\n * does not use https.\r\n */\n\n\nconst warnIfPageIsSecure = function () {\n  // Be very careful accessing browser globals. Who knows what may or may not exist.\n  if (typeof window !== 'undefined' && window.location && window.location.protocol && window.location.protocol.indexOf('https:') !== -1) {\n    warn('Insecure Firebase access from a secure page. ' + 'Please use https in calls to new Firebase().');\n  }\n};\n/**\r\n * Returns true if data is NaN, or +/- Infinity.\r\n */\n\n\nconst isInvalidJSONNumber = function (data) {\n  return typeof data === 'number' && (data !== data || // NaN\n  data === Number.POSITIVE_INFINITY || data === Number.NEGATIVE_INFINITY);\n};\n\nconst executeWhenDOMReady = function (fn) {\n  if (isNodeSdk() || document.readyState === 'complete') {\n    fn();\n  } else {\n    // Modeled after jQuery. Try DOMContentLoaded and onreadystatechange (which\n    // fire before onload), but fall back to onload.\n    let called = false;\n\n    const wrappedFn = function () {\n      if (!document.body) {\n        setTimeout(wrappedFn, Math.floor(10));\n        return;\n      }\n\n      if (!called) {\n        called = true;\n        fn();\n      }\n    };\n\n    if (document.addEventListener) {\n      document.addEventListener('DOMContentLoaded', wrappedFn, false); // fallback to onload.\n\n      window.addEventListener('load', wrappedFn, false); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } else if (document.attachEvent) {\n      // IE.\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      document.attachEvent('onreadystatechange', () => {\n        if (document.readyState === 'complete') {\n          wrappedFn();\n        }\n      }); // fallback to onload.\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n      window.attachEvent('onload', wrappedFn); // jQuery has an extra hack for IE that we could employ (based on\n      // http://javascript.nwbox.com/IEContentLoaded/) But it looks really old.\n      // I'm hoping we don't need it.\n    }\n  }\n};\n/**\r\n * Minimum key name. Invalid for actual data, used as a marker to sort before any valid names\r\n */\n\n\nconst MIN_NAME = '[MIN_NAME]';\n/**\r\n * Maximum key name. Invalid for actual data, used as a marker to sort above any valid names\r\n */\n\nconst MAX_NAME = '[MAX_NAME]';\n/**\r\n * Compares valid Firebase key names, plus min and max name\r\n */\n\nconst nameCompare = function (a, b) {\n  if (a === b) {\n    return 0;\n  } else if (a === MIN_NAME || b === MAX_NAME) {\n    return -1;\n  } else if (b === MIN_NAME || a === MAX_NAME) {\n    return 1;\n  } else {\n    const aAsInt = tryParseInt(a),\n          bAsInt = tryParseInt(b);\n\n    if (aAsInt !== null) {\n      if (bAsInt !== null) {\n        return aAsInt - bAsInt === 0 ? a.length - b.length : aAsInt - bAsInt;\n      } else {\n        return -1;\n      }\n    } else if (bAsInt !== null) {\n      return 1;\n    } else {\n      return a < b ? -1 : 1;\n    }\n  }\n};\n/**\r\n * @returns {!number} comparison result.\r\n */\n\n\nconst stringCompare = function (a, b) {\n  if (a === b) {\n    return 0;\n  } else if (a < b) {\n    return -1;\n  } else {\n    return 1;\n  }\n};\n\nconst requireKey = function (key, obj) {\n  if (obj && key in obj) {\n    return obj[key];\n  } else {\n    throw new Error('Missing required key (' + key + ') in object: ' + stringify(obj));\n  }\n};\n\nconst ObjectToUniqueKey = function (obj) {\n  if (typeof obj !== 'object' || obj === null) {\n    return stringify(obj);\n  }\n\n  const keys = []; // eslint-disable-next-line guard-for-in\n\n  for (const k in obj) {\n    keys.push(k);\n  } // Export as json, but with the keys sorted.\n\n\n  keys.sort();\n  let key = '{';\n\n  for (let i = 0; i < keys.length; i++) {\n    if (i !== 0) {\n      key += ',';\n    }\n\n    key += stringify(keys[i]);\n    key += ':';\n    key += ObjectToUniqueKey(obj[keys[i]]);\n  }\n\n  key += '}';\n  return key;\n};\n/**\r\n * Splits a string into a number of smaller segments of maximum size\r\n * @param str - The string\r\n * @param segsize - The maximum number of chars in the string.\r\n * @returns The string, split into appropriately-sized chunks\r\n */\n\n\nconst splitStringBySize = function (str, segsize) {\n  const len = str.length;\n\n  if (len <= segsize) {\n    return [str];\n  }\n\n  const dataSegs = [];\n\n  for (let c = 0; c < len; c += segsize) {\n    if (c + segsize > len) {\n      dataSegs.push(str.substring(c, len));\n    } else {\n      dataSegs.push(str.substring(c, c + segsize));\n    }\n  }\n\n  return dataSegs;\n};\n/**\r\n * Apply a function to each (key, value) pair in an object or\r\n * apply a function to each (index, value) pair in an array\r\n * @param obj - The object or array to iterate over\r\n * @param fn - The function to apply\r\n */\n\n\nfunction each(obj, fn) {\n  for (const key in obj) {\n    if (obj.hasOwnProperty(key)) {\n      fn(key, obj[key]);\n    }\n  }\n}\n/**\r\n * Borrowed from http://hg.secondlife.com/llsd/src/tip/js/typedarray.js (MIT License)\r\n * I made one modification at the end and removed the NaN / Infinity\r\n * handling (since it seemed broken [caused an overflow] and we don't need it).  See MJL comments.\r\n * @param v - A double\r\n *\r\n */\n\n\nconst doubleToIEEE754String = function (v) {\n  assert(!isInvalidJSONNumber(v), 'Invalid JSON number'); // MJL\n\n  const ebits = 11,\n        fbits = 52;\n  const bias = (1 << ebits - 1) - 1;\n  let s, e, f, ln, i; // Compute sign, exponent, fraction\n  // Skip NaN / Infinity handling --MJL.\n\n  if (v === 0) {\n    e = 0;\n    f = 0;\n    s = 1 / v === -Infinity ? 1 : 0;\n  } else {\n    s = v < 0;\n    v = Math.abs(v);\n\n    if (v >= Math.pow(2, 1 - bias)) {\n      // Normalized\n      ln = Math.min(Math.floor(Math.log(v) / Math.LN2), bias);\n      e = ln + bias;\n      f = Math.round(v * Math.pow(2, fbits - ln) - Math.pow(2, fbits));\n    } else {\n      // Denormalized\n      e = 0;\n      f = Math.round(v / Math.pow(2, 1 - bias - fbits));\n    }\n  } // Pack sign, exponent, fraction\n\n\n  const bits = [];\n\n  for (i = fbits; i; i -= 1) {\n    bits.push(f % 2 ? 1 : 0);\n    f = Math.floor(f / 2);\n  }\n\n  for (i = ebits; i; i -= 1) {\n    bits.push(e % 2 ? 1 : 0);\n    e = Math.floor(e / 2);\n  }\n\n  bits.push(s ? 1 : 0);\n  bits.reverse();\n  const str = bits.join(''); // Return the data as a hex string. --MJL\n\n  let hexByteString = '';\n\n  for (i = 0; i < 64; i += 8) {\n    let hexByte = parseInt(str.substr(i, 8), 2).toString(16);\n\n    if (hexByte.length === 1) {\n      hexByte = '0' + hexByte;\n    }\n\n    hexByteString = hexByteString + hexByte;\n  }\n\n  return hexByteString.toLowerCase();\n};\n/**\r\n * Used to detect if we're in a Chrome content script (which executes in an\r\n * isolated environment where long-polling doesn't work).\r\n */\n\n\nconst isChromeExtensionContentScript = function () {\n  return !!(typeof window === 'object' && window['chrome'] && window['chrome']['extension'] && !/^chrome/.test(window.location.href));\n};\n/**\r\n * Used to detect if we're in a Windows 8 Store app.\r\n */\n\n\nconst isWindowsStoreApp = function () {\n  // Check for the presence of a couple WinRT globals\n  return typeof Windows === 'object' && typeof Windows.UI === 'object';\n};\n/**\r\n * Converts a server error code to a Javascript Error\r\n */\n\n\nfunction errorForServerCode(code, query) {\n  let reason = 'Unknown Error';\n\n  if (code === 'too_big') {\n    reason = 'The data requested exceeds the maximum size ' + 'that can be accessed with a single request.';\n  } else if (code === 'permission_denied') {\n    reason = \"Client doesn't have permission to access the desired data.\";\n  } else if (code === 'unavailable') {\n    reason = 'The service is unavailable';\n  }\n\n  const error = new Error(code + ' at ' + query._path.toString() + ': ' + reason); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n  error.code = code.toUpperCase();\n  return error;\n}\n/**\r\n * Used to test for integer-looking strings\r\n */\n\n\nconst INTEGER_REGEXP_ = new RegExp('^-?(0*)\\\\d{1,10}$');\n/**\r\n * For use in keys, the minimum possible 32-bit integer.\r\n */\n\nconst INTEGER_32_MIN = -2147483648;\n/**\r\n * For use in kyes, the maximum possible 32-bit integer.\r\n */\n\nconst INTEGER_32_MAX = 2147483647;\n/**\r\n * If the string contains a 32-bit integer, return it.  Else return null.\r\n */\n\nconst tryParseInt = function (str) {\n  if (INTEGER_REGEXP_.test(str)) {\n    const intVal = Number(str);\n\n    if (intVal >= INTEGER_32_MIN && intVal <= INTEGER_32_MAX) {\n      return intVal;\n    }\n  }\n\n  return null;\n};\n/**\r\n * Helper to run some code but catch any exceptions and re-throw them later.\r\n * Useful for preventing user callbacks from breaking internal code.\r\n *\r\n * Re-throwing the exception from a setTimeout is a little evil, but it's very\r\n * convenient (we don't have to try to figure out when is a safe point to\r\n * re-throw it), and the behavior seems reasonable:\r\n *\r\n * * If you aren't pausing on exceptions, you get an error in the console with\r\n *   the correct stack trace.\r\n * * If you're pausing on all exceptions, the debugger will pause on your\r\n *   exception and then again when we rethrow it.\r\n * * If you're only pausing on uncaught exceptions, the debugger will only pause\r\n *   on us re-throwing it.\r\n *\r\n * @param fn - The code to guard.\r\n */\n\n\nconst exceptionGuard = function (fn) {\n  try {\n    fn();\n  } catch (e) {\n    // Re-throw exception when it's safe.\n    setTimeout(() => {\n      // It used to be that \"throw e\" would result in a good console error with\n      // relevant context, but as of Chrome 39, you just get the firebase.js\n      // file/line number where we re-throw it, which is useless. So we log\n      // e.stack explicitly.\n      const stack = e.stack || '';\n      warn('Exception was thrown by user callback.', stack);\n      throw e;\n    }, Math.floor(0));\n  }\n};\n/**\r\n * @returns {boolean} true if we think we're currently being crawled.\r\n */\n\n\nconst beingCrawled = function () {\n  const userAgent = typeof window === 'object' && window['navigator'] && window['navigator']['userAgent'] || ''; // For now we whitelist the most popular crawlers.  We should refine this to be the set of crawlers we\n  // believe to support JavaScript/AJAX rendering.\n  // NOTE: Google Webmaster Tools doesn't really belong, but their \"This is how a visitor to your website\n  // would have seen the page\" is flaky if we don't treat it as a crawler.\n\n  return userAgent.search(/googlebot|google webmaster tools|bingbot|yahoo! slurp|baiduspider|yandexbot|duckduckbot/i) >= 0;\n};\n/**\r\n * Same as setTimeout() except on Node.JS it will /not/ prevent the process from exiting.\r\n *\r\n * It is removed with clearTimeout() as normal.\r\n *\r\n * @param fn - Function to run.\r\n * @param time - Milliseconds to wait before running.\r\n * @returns The setTimeout() return value.\r\n */\n\n\nconst setTimeoutNonBlocking = function (fn, time) {\n  const timeout = setTimeout(fn, time); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n  if (typeof timeout === 'object' && timeout['unref']) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    timeout['unref']();\n  }\n\n  return timeout;\n};\n/**\r\n * @license\r\n * Copyright 2021 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Abstraction around AppCheck's token fetching capabilities.\r\n */\n\n\nclass AppCheckTokenProvider {\n  constructor(appName_, appCheckProvider) {\n    this.appName_ = appName_;\n    this.appCheckProvider = appCheckProvider;\n    this.appCheck = appCheckProvider === null || appCheckProvider === void 0 ? void 0 : appCheckProvider.getImmediate({\n      optional: true\n    });\n\n    if (!this.appCheck) {\n      appCheckProvider === null || appCheckProvider === void 0 ? void 0 : appCheckProvider.get().then(appCheck => this.appCheck = appCheck);\n    }\n  }\n\n  getToken(forceRefresh) {\n    if (!this.appCheck) {\n      return new Promise((resolve, reject) => {\n        // Support delayed initialization of FirebaseAppCheck. This allows our\n        // customers to initialize the RTDB SDK before initializing Firebase\n        // AppCheck and ensures that all requests are authenticated if a token\n        // becomes available before the timoeout below expires.\n        setTimeout(() => {\n          if (this.appCheck) {\n            this.getToken(forceRefresh).then(resolve, reject);\n          } else {\n            resolve(null);\n          }\n        }, 0);\n      });\n    }\n\n    return this.appCheck.getToken(forceRefresh);\n  }\n\n  addTokenChangeListener(listener) {\n    var _a;\n\n    (_a = this.appCheckProvider) === null || _a === void 0 ? void 0 : _a.get().then(appCheck => appCheck.addTokenListener(listener));\n  }\n\n  notifyForInvalidToken() {\n    warn(`Provided AppCheck credentials for the app named \"${this.appName_}\" ` + 'are invalid. This usually indicates your app was not initialized correctly.');\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Abstraction around FirebaseApp's token fetching capabilities.\r\n */\n\n\nclass FirebaseAuthTokenProvider {\n  constructor(appName_, firebaseOptions_, authProvider_) {\n    this.appName_ = appName_;\n    this.firebaseOptions_ = firebaseOptions_;\n    this.authProvider_ = authProvider_;\n    this.auth_ = null;\n    this.auth_ = authProvider_.getImmediate({\n      optional: true\n    });\n\n    if (!this.auth_) {\n      authProvider_.onInit(auth => this.auth_ = auth);\n    }\n  }\n\n  getToken(forceRefresh) {\n    if (!this.auth_) {\n      return new Promise((resolve, reject) => {\n        // Support delayed initialization of FirebaseAuth. This allows our\n        // customers to initialize the RTDB SDK before initializing Firebase\n        // Auth and ensures that all requests are authenticated if a token\n        // becomes available before the timoeout below expires.\n        setTimeout(() => {\n          if (this.auth_) {\n            this.getToken(forceRefresh).then(resolve, reject);\n          } else {\n            resolve(null);\n          }\n        }, 0);\n      });\n    }\n\n    return this.auth_.getToken(forceRefresh).catch(error => {\n      // TODO: Need to figure out all the cases this is raised and whether\n      // this makes sense.\n      if (error && error.code === 'auth/token-not-initialized') {\n        log('Got auth/token-not-initialized error.  Treating as null token.');\n        return null;\n      } else {\n        return Promise.reject(error);\n      }\n    });\n  }\n\n  addTokenChangeListener(listener) {\n    // TODO: We might want to wrap the listener and call it with no args to\n    // avoid a leaky abstraction, but that makes removing the listener harder.\n    if (this.auth_) {\n      this.auth_.addAuthTokenListener(listener);\n    } else {\n      this.authProvider_.get().then(auth => auth.addAuthTokenListener(listener));\n    }\n  }\n\n  removeTokenChangeListener(listener) {\n    this.authProvider_.get().then(auth => auth.removeAuthTokenListener(listener));\n  }\n\n  notifyForInvalidToken() {\n    let errorMessage = 'Provided authentication credentials for the app named \"' + this.appName_ + '\" are invalid. This usually indicates your app was not ' + 'initialized correctly. ';\n\n    if ('credential' in this.firebaseOptions_) {\n      errorMessage += 'Make sure the \"credential\" property provided to initializeApp() ' + 'is authorized to access the specified \"databaseURL\" and is from the correct ' + 'project.';\n    } else if ('serviceAccount' in this.firebaseOptions_) {\n      errorMessage += 'Make sure the \"serviceAccount\" property provided to initializeApp() ' + 'is authorized to access the specified \"databaseURL\" and is from the correct ' + 'project.';\n    } else {\n      errorMessage += 'Make sure the \"apiKey\" and \"databaseURL\" properties provided to ' + 'initializeApp() match the values provided for your app at ' + 'https://console.firebase.google.com/.';\n    }\n\n    warn(errorMessage);\n  }\n\n}\n/* AuthTokenProvider that supplies a constant token. Used by Admin SDK or mockUserToken with emulators. */\n\n\nlet EmulatorTokenProvider = /*#__PURE__*/(() => {\n  class EmulatorTokenProvider {\n    constructor(accessToken) {\n      this.accessToken = accessToken;\n    }\n\n    getToken(forceRefresh) {\n      return Promise.resolve({\n        accessToken: this.accessToken\n      });\n    }\n\n    addTokenChangeListener(listener) {\n      // Invoke the listener immediately to match the behavior in Firebase Auth\n      // (see packages/auth/src/auth.js#L1807)\n      listener(this.accessToken);\n    }\n\n    removeTokenChangeListener(listener) {}\n\n    notifyForInvalidToken() {}\n\n  }\n\n  /** A string that is treated as an admin access token by the RTDB emulator. Used by Admin SDK. */\n  EmulatorTokenProvider.OWNER = 'owner';\n  /**\r\n   * @license\r\n   * Copyright 2017 Google LLC\r\n   *\r\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   * you may not use this file except in compliance with the License.\r\n   * You may obtain a copy of the License at\r\n   *\r\n   *   http://www.apache.org/licenses/LICENSE-2.0\r\n   *\r\n   * Unless required by applicable law or agreed to in writing, software\r\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   * See the License for the specific language governing permissions and\r\n   * limitations under the License.\r\n   */\n\n  return EmulatorTokenProvider;\n})();\nconst PROTOCOL_VERSION = '5';\nconst VERSION_PARAM = 'v';\nconst TRANSPORT_SESSION_PARAM = 's';\nconst REFERER_PARAM = 'r';\nconst FORGE_REF = 'f'; // Matches console.firebase.google.com, firebase-console-*.corp.google.com and\n// firebase.corp.google.com\n\nconst FORGE_DOMAIN_RE = /(console\\.firebase|firebase-console-\\w+\\.corp|firebase\\.corp)\\.google\\.com/;\nconst LAST_SESSION_PARAM = 'ls';\nconst APPLICATION_ID_PARAM = 'p';\nconst APP_CHECK_TOKEN_PARAM = 'ac';\nconst WEBSOCKET = 'websocket';\nconst LONG_POLLING = 'long_polling';\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A class that holds metadata about a Repo object\r\n */\n\nclass RepoInfo {\n  /**\r\n   * @param host - Hostname portion of the url for the repo\r\n   * @param secure - Whether or not this repo is accessed over ssl\r\n   * @param namespace - The namespace represented by the repo\r\n   * @param webSocketOnly - Whether to prefer websockets over all other transports (used by Nest).\r\n   * @param nodeAdmin - Whether this instance uses Admin SDK credentials\r\n   * @param persistenceKey - Override the default session persistence storage key\r\n   */\n  constructor(host, secure, namespace, webSocketOnly, nodeAdmin = false, persistenceKey = '', includeNamespaceInQueryParams = false) {\n    this.secure = secure;\n    this.namespace = namespace;\n    this.webSocketOnly = webSocketOnly;\n    this.nodeAdmin = nodeAdmin;\n    this.persistenceKey = persistenceKey;\n    this.includeNamespaceInQueryParams = includeNamespaceInQueryParams;\n    this._host = host.toLowerCase();\n    this._domain = this._host.substr(this._host.indexOf('.') + 1);\n    this.internalHost = PersistentStorage.get('host:' + host) || this._host;\n  }\n\n  isCacheableHost() {\n    return this.internalHost.substr(0, 2) === 's-';\n  }\n\n  isCustomHost() {\n    return this._domain !== 'firebaseio.com' && this._domain !== 'firebaseio-demo.com';\n  }\n\n  get host() {\n    return this._host;\n  }\n\n  set host(newHost) {\n    if (newHost !== this.internalHost) {\n      this.internalHost = newHost;\n\n      if (this.isCacheableHost()) {\n        PersistentStorage.set('host:' + this._host, this.internalHost);\n      }\n    }\n  }\n\n  toString() {\n    let str = this.toURLString();\n\n    if (this.persistenceKey) {\n      str += '<' + this.persistenceKey + '>';\n    }\n\n    return str;\n  }\n\n  toURLString() {\n    const protocol = this.secure ? 'https://' : 'http://';\n    const query = this.includeNamespaceInQueryParams ? `?ns=${this.namespace}` : '';\n    return `${protocol}${this.host}/${query}`;\n  }\n\n}\n\nfunction repoInfoNeedsQueryParam(repoInfo) {\n  return repoInfo.host !== repoInfo.internalHost || repoInfo.isCustomHost() || repoInfo.includeNamespaceInQueryParams;\n}\n/**\r\n * Returns the websocket URL for this repo\r\n * @param repoInfo - RepoInfo object\r\n * @param type - of connection\r\n * @param params - list\r\n * @returns The URL for this repo\r\n */\n\n\nfunction repoInfoConnectionURL(repoInfo, type, params) {\n  assert(typeof type === 'string', 'typeof type must == string');\n  assert(typeof params === 'object', 'typeof params must == object');\n  let connURL;\n\n  if (type === WEBSOCKET) {\n    connURL = (repoInfo.secure ? 'wss://' : 'ws://') + repoInfo.internalHost + '/.ws?';\n  } else if (type === LONG_POLLING) {\n    connURL = (repoInfo.secure ? 'https://' : 'http://') + repoInfo.internalHost + '/.lp?';\n  } else {\n    throw new Error('Unknown connection type: ' + type);\n  }\n\n  if (repoInfoNeedsQueryParam(repoInfo)) {\n    params['ns'] = repoInfo.namespace;\n  }\n\n  const pairs = [];\n  each(params, (key, value) => {\n    pairs.push(key + '=' + value);\n  });\n  return connURL + pairs.join('&');\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Tracks a collection of stats.\r\n */\n\n\nclass StatsCollection {\n  constructor() {\n    this.counters_ = {};\n  }\n\n  incrementCounter(name, amount = 1) {\n    if (!contains(this.counters_, name)) {\n      this.counters_[name] = 0;\n    }\n\n    this.counters_[name] += amount;\n  }\n\n  get() {\n    return deepCopy(this.counters_);\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nconst collections = {};\nconst reporters = {};\n\nfunction statsManagerGetCollection(repoInfo) {\n  const hashString = repoInfo.toString();\n\n  if (!collections[hashString]) {\n    collections[hashString] = new StatsCollection();\n  }\n\n  return collections[hashString];\n}\n\nfunction statsManagerGetOrCreateReporter(repoInfo, creatorFunction) {\n  const hashString = repoInfo.toString();\n\n  if (!reporters[hashString]) {\n    reporters[hashString] = creatorFunction();\n  }\n\n  return reporters[hashString];\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * This class ensures the packets from the server arrive in order\r\n * This class takes data from the server and ensures it gets passed into the callbacks in order.\r\n */\n\n\nclass PacketReceiver {\n  /**\r\n   * @param onMessage_\r\n   */\n  constructor(onMessage_) {\n    this.onMessage_ = onMessage_;\n    this.pendingResponses = [];\n    this.currentResponseNum = 0;\n    this.closeAfterResponse = -1;\n    this.onClose = null;\n  }\n\n  closeAfter(responseNum, callback) {\n    this.closeAfterResponse = responseNum;\n    this.onClose = callback;\n\n    if (this.closeAfterResponse < this.currentResponseNum) {\n      this.onClose();\n      this.onClose = null;\n    }\n  }\n  /**\r\n   * Each message from the server comes with a response number, and an array of data. The responseNumber\r\n   * allows us to ensure that we process them in the right order, since we can't be guaranteed that all\r\n   * browsers will respond in the same order as the requests we sent\r\n   */\n\n\n  handleResponse(requestNum, data) {\n    this.pendingResponses[requestNum] = data;\n\n    while (this.pendingResponses[this.currentResponseNum]) {\n      const toProcess = this.pendingResponses[this.currentResponseNum];\n      delete this.pendingResponses[this.currentResponseNum];\n\n      for (let i = 0; i < toProcess.length; ++i) {\n        if (toProcess[i]) {\n          exceptionGuard(() => {\n            this.onMessage_(toProcess[i]);\n          });\n        }\n      }\n\n      if (this.currentResponseNum === this.closeAfterResponse) {\n        if (this.onClose) {\n          this.onClose();\n          this.onClose = null;\n        }\n\n        break;\n      }\n\n      this.currentResponseNum++;\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// URL query parameters associated with longpolling\n\n\nconst FIREBASE_LONGPOLL_START_PARAM = 'start';\nconst FIREBASE_LONGPOLL_CLOSE_COMMAND = 'close';\nconst FIREBASE_LONGPOLL_COMMAND_CB_NAME = 'pLPCommand';\nconst FIREBASE_LONGPOLL_DATA_CB_NAME = 'pRTLPCB';\nconst FIREBASE_LONGPOLL_ID_PARAM = 'id';\nconst FIREBASE_LONGPOLL_PW_PARAM = 'pw';\nconst FIREBASE_LONGPOLL_SERIAL_PARAM = 'ser';\nconst FIREBASE_LONGPOLL_CALLBACK_ID_PARAM = 'cb';\nconst FIREBASE_LONGPOLL_SEGMENT_NUM_PARAM = 'seg';\nconst FIREBASE_LONGPOLL_SEGMENTS_IN_PACKET = 'ts';\nconst FIREBASE_LONGPOLL_DATA_PARAM = 'd';\nconst FIREBASE_LONGPOLL_DISCONN_FRAME_REQUEST_PARAM = 'dframe'; //Data size constants.\n//TODO: Perf: the maximum length actually differs from browser to browser.\n// We should check what browser we're on and set accordingly.\n\nconst MAX_URL_DATA_SIZE = 1870;\nconst SEG_HEADER_SIZE = 30; //ie: &seg=8299234&ts=982389123&d=\n\nconst MAX_PAYLOAD_SIZE = MAX_URL_DATA_SIZE - SEG_HEADER_SIZE;\n/**\r\n * Keepalive period\r\n * send a fresh request at minimum every 25 seconds. Opera has a maximum request\r\n * length of 30 seconds that we can't exceed.\r\n */\n\nconst KEEPALIVE_REQUEST_INTERVAL = 25000;\n/**\r\n * How long to wait before aborting a long-polling connection attempt.\r\n */\n\nconst LP_CONNECT_TIMEOUT = 30000;\n/**\r\n * This class manages a single long-polling connection.\r\n */\n\nclass BrowserPollConnection {\n  /**\r\n   * @param connId An identifier for this connection, used for logging\r\n   * @param repoInfo The info for the endpoint to send data to.\r\n   * @param applicationId The Firebase App ID for this project.\r\n   * @param appCheckToken The AppCheck token for this client.\r\n   * @param authToken The AuthToken to use for this connection.\r\n   * @param transportSessionId Optional transportSessionid if we are\r\n   * reconnecting for an existing transport session\r\n   * @param lastSessionId Optional lastSessionId if the PersistentConnection has\r\n   * already created a connection previously\r\n   */\n  constructor(connId, repoInfo, applicationId, appCheckToken, authToken, transportSessionId, lastSessionId) {\n    this.connId = connId;\n    this.repoInfo = repoInfo;\n    this.applicationId = applicationId;\n    this.appCheckToken = appCheckToken;\n    this.authToken = authToken;\n    this.transportSessionId = transportSessionId;\n    this.lastSessionId = lastSessionId;\n    this.bytesSent = 0;\n    this.bytesReceived = 0;\n    this.everConnected_ = false;\n    this.log_ = logWrapper(connId);\n    this.stats_ = statsManagerGetCollection(repoInfo);\n\n    this.urlFn = params => {\n      // Always add the token if we have one.\n      if (this.appCheckToken) {\n        params[APP_CHECK_TOKEN_PARAM] = this.appCheckToken;\n      }\n\n      return repoInfoConnectionURL(repoInfo, LONG_POLLING, params);\n    };\n  }\n  /**\r\n   * @param onMessage - Callback when messages arrive\r\n   * @param onDisconnect - Callback with connection lost.\r\n   */\n\n\n  open(onMessage, onDisconnect) {\n    this.curSegmentNum = 0;\n    this.onDisconnect_ = onDisconnect;\n    this.myPacketOrderer = new PacketReceiver(onMessage);\n    this.isClosed_ = false;\n    this.connectTimeoutTimer_ = setTimeout(() => {\n      this.log_('Timed out trying to connect.'); // Make sure we clear the host cache\n\n      this.onClosed_();\n      this.connectTimeoutTimer_ = null; // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    }, Math.floor(LP_CONNECT_TIMEOUT)); // Ensure we delay the creation of the iframe until the DOM is loaded.\n\n    executeWhenDOMReady(() => {\n      if (this.isClosed_) {\n        return;\n      } //Set up a callback that gets triggered once a connection is set up.\n\n\n      this.scriptTagHolder = new FirebaseIFrameScriptHolder((...args) => {\n        const [command, arg1, arg2, arg3, arg4] = args;\n        this.incrementIncomingBytes_(args);\n\n        if (!this.scriptTagHolder) {\n          return; // we closed the connection.\n        }\n\n        if (this.connectTimeoutTimer_) {\n          clearTimeout(this.connectTimeoutTimer_);\n          this.connectTimeoutTimer_ = null;\n        }\n\n        this.everConnected_ = true;\n\n        if (command === FIREBASE_LONGPOLL_START_PARAM) {\n          this.id = arg1;\n          this.password = arg2;\n        } else if (command === FIREBASE_LONGPOLL_CLOSE_COMMAND) {\n          // Don't clear the host cache. We got a response from the server, so we know it's reachable\n          if (arg1) {\n            // We aren't expecting any more data (other than what the server's already in the process of sending us\n            // through our already open polls), so don't send any more.\n            this.scriptTagHolder.sendNewPolls = false; // arg1 in this case is the last response number sent by the server. We should try to receive\n            // all of the responses up to this one before closing\n\n            this.myPacketOrderer.closeAfter(arg1, () => {\n              this.onClosed_();\n            });\n          } else {\n            this.onClosed_();\n          }\n        } else {\n          throw new Error('Unrecognized command received: ' + command);\n        }\n      }, (...args) => {\n        const [pN, data] = args;\n        this.incrementIncomingBytes_(args);\n        this.myPacketOrderer.handleResponse(pN, data);\n      }, () => {\n        this.onClosed_();\n      }, this.urlFn); //Send the initial request to connect. The serial number is simply to keep the browser from pulling previous results\n      //from cache.\n\n      const urlParams = {};\n      urlParams[FIREBASE_LONGPOLL_START_PARAM] = 't';\n      urlParams[FIREBASE_LONGPOLL_SERIAL_PARAM] = Math.floor(Math.random() * 100000000);\n\n      if (this.scriptTagHolder.uniqueCallbackIdentifier) {\n        urlParams[FIREBASE_LONGPOLL_CALLBACK_ID_PARAM] = this.scriptTagHolder.uniqueCallbackIdentifier;\n      }\n\n      urlParams[VERSION_PARAM] = PROTOCOL_VERSION;\n\n      if (this.transportSessionId) {\n        urlParams[TRANSPORT_SESSION_PARAM] = this.transportSessionId;\n      }\n\n      if (this.lastSessionId) {\n        urlParams[LAST_SESSION_PARAM] = this.lastSessionId;\n      }\n\n      if (this.applicationId) {\n        urlParams[APPLICATION_ID_PARAM] = this.applicationId;\n      }\n\n      if (this.appCheckToken) {\n        urlParams[APP_CHECK_TOKEN_PARAM] = this.appCheckToken;\n      }\n\n      if (typeof location !== 'undefined' && location.hostname && FORGE_DOMAIN_RE.test(location.hostname)) {\n        urlParams[REFERER_PARAM] = FORGE_REF;\n      }\n\n      const connectURL = this.urlFn(urlParams);\n      this.log_('Connecting via long-poll to ' + connectURL);\n      this.scriptTagHolder.addTag(connectURL, () => {\n        /* do nothing */\n      });\n    });\n  }\n  /**\r\n   * Call this when a handshake has completed successfully and we want to consider the connection established\r\n   */\n\n\n  start() {\n    this.scriptTagHolder.startLongPoll(this.id, this.password);\n    this.addDisconnectPingFrame(this.id, this.password);\n  }\n  /**\r\n   * Forces long polling to be considered as a potential transport\r\n   */\n\n\n  static forceAllow() {\n    BrowserPollConnection.forceAllow_ = true;\n  }\n  /**\r\n   * Forces longpolling to not be considered as a potential transport\r\n   */\n\n\n  static forceDisallow() {\n    BrowserPollConnection.forceDisallow_ = true;\n  } // Static method, use string literal so it can be accessed in a generic way\n\n\n  static isAvailable() {\n    if (isNodeSdk()) {\n      return false;\n    } else if (BrowserPollConnection.forceAllow_) {\n      return true;\n    } else {\n      // NOTE: In React-Native there's normally no 'document', but if you debug a React-Native app in\n      // the Chrome debugger, 'document' is defined, but document.createElement is null (2015/06/08).\n      return !BrowserPollConnection.forceDisallow_ && typeof document !== 'undefined' && document.createElement != null && !isChromeExtensionContentScript() && !isWindowsStoreApp();\n    }\n  }\n  /**\r\n   * No-op for polling\r\n   */\n\n\n  markConnectionHealthy() {}\n  /**\r\n   * Stops polling and cleans up the iframe\r\n   */\n\n\n  shutdown_() {\n    this.isClosed_ = true;\n\n    if (this.scriptTagHolder) {\n      this.scriptTagHolder.close();\n      this.scriptTagHolder = null;\n    } //remove the disconnect frame, which will trigger an XHR call to the server to tell it we're leaving.\n\n\n    if (this.myDisconnFrame) {\n      document.body.removeChild(this.myDisconnFrame);\n      this.myDisconnFrame = null;\n    }\n\n    if (this.connectTimeoutTimer_) {\n      clearTimeout(this.connectTimeoutTimer_);\n      this.connectTimeoutTimer_ = null;\n    }\n  }\n  /**\r\n   * Triggered when this transport is closed\r\n   */\n\n\n  onClosed_() {\n    if (!this.isClosed_) {\n      this.log_('Longpoll is closing itself');\n      this.shutdown_();\n\n      if (this.onDisconnect_) {\n        this.onDisconnect_(this.everConnected_);\n        this.onDisconnect_ = null;\n      }\n    }\n  }\n  /**\r\n   * External-facing close handler. RealTime has requested we shut down. Kill our connection and tell the server\r\n   * that we've left.\r\n   */\n\n\n  close() {\n    if (!this.isClosed_) {\n      this.log_('Longpoll is being closed.');\n      this.shutdown_();\n    }\n  }\n  /**\r\n   * Send the JSON object down to the server. It will need to be stringified, base64 encoded, and then\r\n   * broken into chunks (since URLs have a small maximum length).\r\n   * @param data - The JSON data to transmit.\r\n   */\n\n\n  send(data) {\n    const dataStr = stringify(data);\n    this.bytesSent += dataStr.length;\n    this.stats_.incrementCounter('bytes_sent', dataStr.length); //first, lets get the base64-encoded data\n\n    const base64data = base64Encode(dataStr); //We can only fit a certain amount in each URL, so we need to split this request\n    //up into multiple pieces if it doesn't fit in one request.\n\n    const dataSegs = splitStringBySize(base64data, MAX_PAYLOAD_SIZE); //Enqueue each segment for transmission. We assign each chunk a sequential ID and a total number\n    //of segments so that we can reassemble the packet on the server.\n\n    for (let i = 0; i < dataSegs.length; i++) {\n      this.scriptTagHolder.enqueueSegment(this.curSegmentNum, dataSegs.length, dataSegs[i]);\n      this.curSegmentNum++;\n    }\n  }\n  /**\r\n   * This is how we notify the server that we're leaving.\r\n   * We aren't able to send requests with DHTML on a window close event, but we can\r\n   * trigger XHR requests in some browsers (everything but Opera basically).\r\n   */\n\n\n  addDisconnectPingFrame(id, pw) {\n    if (isNodeSdk()) {\n      return;\n    }\n\n    this.myDisconnFrame = document.createElement('iframe');\n    const urlParams = {};\n    urlParams[FIREBASE_LONGPOLL_DISCONN_FRAME_REQUEST_PARAM] = 't';\n    urlParams[FIREBASE_LONGPOLL_ID_PARAM] = id;\n    urlParams[FIREBASE_LONGPOLL_PW_PARAM] = pw;\n    this.myDisconnFrame.src = this.urlFn(urlParams);\n    this.myDisconnFrame.style.display = 'none';\n    document.body.appendChild(this.myDisconnFrame);\n  }\n  /**\r\n   * Used to track the bytes received by this client\r\n   */\n\n\n  incrementIncomingBytes_(args) {\n    // TODO: This is an annoying perf hit just to track the number of incoming bytes.  Maybe it should be opt-in.\n    const bytesReceived = stringify(args).length;\n    this.bytesReceived += bytesReceived;\n    this.stats_.incrementCounter('bytes_received', bytesReceived);\n  }\n\n}\n/*********************************************************************************************\r\n * A wrapper around an iframe that is used as a long-polling script holder.\r\n *********************************************************************************************/\n\n\nclass FirebaseIFrameScriptHolder {\n  /**\r\n   * @param commandCB - The callback to be called when control commands are recevied from the server.\r\n   * @param onMessageCB - The callback to be triggered when responses arrive from the server.\r\n   * @param onDisconnect - The callback to be triggered when this tag holder is closed\r\n   * @param urlFn - A function that provides the URL of the endpoint to send data to.\r\n   */\n  constructor(commandCB, onMessageCB, onDisconnect, urlFn) {\n    this.onDisconnect = onDisconnect;\n    this.urlFn = urlFn; //We maintain a count of all of the outstanding requests, because if we have too many active at once it can cause\n    //problems in some browsers.\n\n    this.outstandingRequests = new Set(); //A queue of the pending segments waiting for transmission to the server.\n\n    this.pendingSegs = []; //A serial number. We use this for two things:\n    // 1) A way to ensure the browser doesn't cache responses to polls\n    // 2) A way to make the server aware when long-polls arrive in a different order than we started them. The\n    //    server needs to release both polls in this case or it will cause problems in Opera since Opera can only execute\n    //    JSONP code in the order it was added to the iframe.\n\n    this.currentSerial = Math.floor(Math.random() * 100000000); // This gets set to false when we're \"closing down\" the connection (e.g. we're switching transports but there's still\n    // incoming data from the server that we're waiting for).\n\n    this.sendNewPolls = true;\n\n    if (!isNodeSdk()) {\n      //Each script holder registers a couple of uniquely named callbacks with the window. These are called from the\n      //iframes where we put the long-polling script tags. We have two callbacks:\n      //   1) Command Callback - Triggered for control issues, like starting a connection.\n      //   2) Message Callback - Triggered when new data arrives.\n      this.uniqueCallbackIdentifier = LUIDGenerator();\n      window[FIREBASE_LONGPOLL_COMMAND_CB_NAME + this.uniqueCallbackIdentifier] = commandCB;\n      window[FIREBASE_LONGPOLL_DATA_CB_NAME + this.uniqueCallbackIdentifier] = onMessageCB; //Create an iframe for us to add script tags to.\n\n      this.myIFrame = FirebaseIFrameScriptHolder.createIFrame_(); // Set the iframe's contents.\n\n      let script = ''; // if we set a javascript url, it's IE and we need to set the document domain. The javascript url is sufficient\n      // for ie9, but ie8 needs to do it again in the document itself.\n\n      if (this.myIFrame.src && this.myIFrame.src.substr(0, 'javascript:'.length) === 'javascript:') {\n        const currentDomain = document.domain;\n        script = '<script>document.domain=\"' + currentDomain + '\";</script>';\n      }\n\n      const iframeContents = '<html><body>' + script + '</body></html>';\n\n      try {\n        this.myIFrame.doc.open();\n        this.myIFrame.doc.write(iframeContents);\n        this.myIFrame.doc.close();\n      } catch (e) {\n        log('frame writing exception');\n\n        if (e.stack) {\n          log(e.stack);\n        }\n\n        log(e);\n      }\n    } else {\n      this.commandCB = commandCB;\n      this.onMessageCB = onMessageCB;\n    }\n  }\n  /**\r\n   * Each browser has its own funny way to handle iframes. Here we mush them all together into one object that I can\r\n   * actually use.\r\n   */\n\n\n  static createIFrame_() {\n    const iframe = document.createElement('iframe');\n    iframe.style.display = 'none'; // This is necessary in order to initialize the document inside the iframe\n\n    if (document.body) {\n      document.body.appendChild(iframe);\n\n      try {\n        // If document.domain has been modified in IE, this will throw an error, and we need to set the\n        // domain of the iframe's document manually. We can do this via a javascript: url as the src attribute\n        // Also note that we must do this *after* the iframe has been appended to the page. Otherwise it doesn't work.\n        const a = iframe.contentWindow.document;\n\n        if (!a) {\n          // Apologies for the log-spam, I need to do something to keep closure from optimizing out the assignment above.\n          log('No IE domain setting required');\n        }\n      } catch (e) {\n        const domain = document.domain;\n        iframe.src = \"javascript:void((function(){document.open();document.domain='\" + domain + \"';document.close();})())\";\n      }\n    } else {\n      // LongPollConnection attempts to delay initialization until the document is ready, so hopefully this\n      // never gets hit.\n      throw 'Document body has not initialized. Wait to initialize Firebase until after the document is ready.';\n    } // Get the document of the iframe in a browser-specific way.\n\n\n    if (iframe.contentDocument) {\n      iframe.doc = iframe.contentDocument; // Firefox, Opera, Safari\n    } else if (iframe.contentWindow) {\n      iframe.doc = iframe.contentWindow.document; // Internet Explorer\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } else if (iframe.document) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      iframe.doc = iframe.document; //others?\n    }\n\n    return iframe;\n  }\n  /**\r\n   * Cancel all outstanding queries and remove the frame.\r\n   */\n\n\n  close() {\n    //Mark this iframe as dead, so no new requests are sent.\n    this.alive = false;\n\n    if (this.myIFrame) {\n      //We have to actually remove all of the html inside this iframe before removing it from the\n      //window, or IE will continue loading and executing the script tags we've already added, which\n      //can lead to some errors being thrown. Setting innerHTML seems to be the easiest way to do this.\n      this.myIFrame.doc.body.innerHTML = '';\n      setTimeout(() => {\n        if (this.myIFrame !== null) {\n          document.body.removeChild(this.myIFrame);\n          this.myIFrame = null;\n        }\n      }, Math.floor(0));\n    } // Protect from being called recursively.\n\n\n    const onDisconnect = this.onDisconnect;\n\n    if (onDisconnect) {\n      this.onDisconnect = null;\n      onDisconnect();\n    }\n  }\n  /**\r\n   * Actually start the long-polling session by adding the first script tag(s) to the iframe.\r\n   * @param id - The ID of this connection\r\n   * @param pw - The password for this connection\r\n   */\n\n\n  startLongPoll(id, pw) {\n    this.myID = id;\n    this.myPW = pw;\n    this.alive = true; //send the initial request. If there are requests queued, make sure that we transmit as many as we are currently able to.\n\n    while (this.newRequest_()) {}\n  }\n  /**\r\n   * This is called any time someone might want a script tag to be added. It adds a script tag when there aren't\r\n   * too many outstanding requests and we are still alive.\r\n   *\r\n   * If there are outstanding packet segments to send, it sends one. If there aren't, it sends a long-poll anyways if\r\n   * needed.\r\n   */\n\n\n  newRequest_() {\n    // We keep one outstanding request open all the time to receive data, but if we need to send data\n    // (pendingSegs.length > 0) then we create a new request to send the data.  The server will automatically\n    // close the old request.\n    if (this.alive && this.sendNewPolls && this.outstandingRequests.size < (this.pendingSegs.length > 0 ? 2 : 1)) {\n      //construct our url\n      this.currentSerial++;\n      const urlParams = {};\n      urlParams[FIREBASE_LONGPOLL_ID_PARAM] = this.myID;\n      urlParams[FIREBASE_LONGPOLL_PW_PARAM] = this.myPW;\n      urlParams[FIREBASE_LONGPOLL_SERIAL_PARAM] = this.currentSerial;\n      let theURL = this.urlFn(urlParams); //Now add as much data as we can.\n\n      let curDataString = '';\n      let i = 0;\n\n      while (this.pendingSegs.length > 0) {\n        //first, lets see if the next segment will fit.\n        const nextSeg = this.pendingSegs[0];\n\n        if (nextSeg.d.length + SEG_HEADER_SIZE + curDataString.length <= MAX_URL_DATA_SIZE) {\n          //great, the segment will fit. Lets append it.\n          const theSeg = this.pendingSegs.shift();\n          curDataString = curDataString + '&' + FIREBASE_LONGPOLL_SEGMENT_NUM_PARAM + i + '=' + theSeg.seg + '&' + FIREBASE_LONGPOLL_SEGMENTS_IN_PACKET + i + '=' + theSeg.ts + '&' + FIREBASE_LONGPOLL_DATA_PARAM + i + '=' + theSeg.d;\n          i++;\n        } else {\n          break;\n        }\n      }\n\n      theURL = theURL + curDataString;\n      this.addLongPollTag_(theURL, this.currentSerial);\n      return true;\n    } else {\n      return false;\n    }\n  }\n  /**\r\n   * Queue a packet for transmission to the server.\r\n   * @param segnum - A sequential id for this packet segment used for reassembly\r\n   * @param totalsegs - The total number of segments in this packet\r\n   * @param data - The data for this segment.\r\n   */\n\n\n  enqueueSegment(segnum, totalsegs, data) {\n    //add this to the queue of segments to send.\n    this.pendingSegs.push({\n      seg: segnum,\n      ts: totalsegs,\n      d: data\n    }); //send the data immediately if there isn't already data being transmitted, unless\n    //startLongPoll hasn't been called yet.\n\n    if (this.alive) {\n      this.newRequest_();\n    }\n  }\n  /**\r\n   * Add a script tag for a regular long-poll request.\r\n   * @param url - The URL of the script tag.\r\n   * @param serial - The serial number of the request.\r\n   */\n\n\n  addLongPollTag_(url, serial) {\n    //remember that we sent this request.\n    this.outstandingRequests.add(serial);\n\n    const doNewRequest = () => {\n      this.outstandingRequests.delete(serial);\n      this.newRequest_();\n    }; // If this request doesn't return on its own accord (by the server sending us some data), we'll\n    // create a new one after the KEEPALIVE interval to make sure we always keep a fresh request open.\n\n\n    const keepaliveTimeout = setTimeout(doNewRequest, Math.floor(KEEPALIVE_REQUEST_INTERVAL));\n\n    const readyStateCB = () => {\n      // Request completed.  Cancel the keepalive.\n      clearTimeout(keepaliveTimeout); // Trigger a new request so we can continue receiving data.\n\n      doNewRequest();\n    };\n\n    this.addTag(url, readyStateCB);\n  }\n  /**\r\n   * Add an arbitrary script tag to the iframe.\r\n   * @param url - The URL for the script tag source.\r\n   * @param loadCB - A callback to be triggered once the script has loaded.\r\n   */\n\n\n  addTag(url, loadCB) {\n    if (isNodeSdk()) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      this.doNodeLongPoll(url, loadCB);\n    } else {\n      setTimeout(() => {\n        try {\n          // if we're already closed, don't add this poll\n          if (!this.sendNewPolls) {\n            return;\n          }\n\n          const newScript = this.myIFrame.doc.createElement('script');\n          newScript.type = 'text/javascript';\n          newScript.async = true;\n          newScript.src = url; // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n          newScript.onload = newScript.onreadystatechange = function () {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            const rstate = newScript.readyState;\n\n            if (!rstate || rstate === 'loaded' || rstate === 'complete') {\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              newScript.onload = newScript.onreadystatechange = null;\n\n              if (newScript.parentNode) {\n                newScript.parentNode.removeChild(newScript);\n              }\n\n              loadCB();\n            }\n          };\n\n          newScript.onerror = () => {\n            log('Long-poll script failed to load: ' + url);\n            this.sendNewPolls = false;\n            this.close();\n          };\n\n          this.myIFrame.doc.body.appendChild(newScript);\n        } catch (e) {// TODO: we should make this error visible somehow\n        }\n      }, Math.floor(1));\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nconst WEBSOCKET_MAX_FRAME_SIZE = 16384;\nconst WEBSOCKET_KEEPALIVE_INTERVAL = 45000;\nlet WebSocketImpl = null;\n\nif (typeof MozWebSocket !== 'undefined') {\n  WebSocketImpl = MozWebSocket;\n} else if (typeof WebSocket !== 'undefined') {\n  WebSocketImpl = WebSocket;\n}\n/**\r\n * Create a new websocket connection with the given callbacks.\r\n */\n\n\nlet WebSocketConnection = /*#__PURE__*/(() => {\n  class WebSocketConnection {\n    /**\r\n     * @param connId identifier for this transport\r\n     * @param repoInfo The info for the websocket endpoint.\r\n     * @param applicationId The Firebase App ID for this project.\r\n     * @param appCheckToken The App Check Token for this client.\r\n     * @param authToken The Auth Token for this client.\r\n     * @param transportSessionId Optional transportSessionId if this is connecting\r\n     * to an existing transport session\r\n     * @param lastSessionId Optional lastSessionId if there was a previous\r\n     * connection\r\n     */\n    constructor(connId, repoInfo, applicationId, appCheckToken, authToken, transportSessionId, lastSessionId) {\n      this.connId = connId;\n      this.applicationId = applicationId;\n      this.appCheckToken = appCheckToken;\n      this.authToken = authToken;\n      this.keepaliveTimer = null;\n      this.frames = null;\n      this.totalFrames = 0;\n      this.bytesSent = 0;\n      this.bytesReceived = 0;\n      this.log_ = logWrapper(this.connId);\n      this.stats_ = statsManagerGetCollection(repoInfo);\n      this.connURL = WebSocketConnection.connectionURL_(repoInfo, transportSessionId, lastSessionId, appCheckToken, applicationId);\n      this.nodeAdmin = repoInfo.nodeAdmin;\n    }\n    /**\r\n     * @param repoInfo - The info for the websocket endpoint.\r\n     * @param transportSessionId - Optional transportSessionId if this is connecting to an existing transport\r\n     *                                         session\r\n     * @param lastSessionId - Optional lastSessionId if there was a previous connection\r\n     * @returns connection url\r\n     */\n\n\n    static connectionURL_(repoInfo, transportSessionId, lastSessionId, appCheckToken, applicationId) {\n      const urlParams = {};\n      urlParams[VERSION_PARAM] = PROTOCOL_VERSION;\n\n      if (!isNodeSdk() && typeof location !== 'undefined' && location.hostname && FORGE_DOMAIN_RE.test(location.hostname)) {\n        urlParams[REFERER_PARAM] = FORGE_REF;\n      }\n\n      if (transportSessionId) {\n        urlParams[TRANSPORT_SESSION_PARAM] = transportSessionId;\n      }\n\n      if (lastSessionId) {\n        urlParams[LAST_SESSION_PARAM] = lastSessionId;\n      }\n\n      if (appCheckToken) {\n        urlParams[APP_CHECK_TOKEN_PARAM] = appCheckToken;\n      }\n\n      if (applicationId) {\n        urlParams[APPLICATION_ID_PARAM] = applicationId;\n      }\n\n      return repoInfoConnectionURL(repoInfo, WEBSOCKET, urlParams);\n    }\n    /**\r\n     * @param onMessage - Callback when messages arrive\r\n     * @param onDisconnect - Callback with connection lost.\r\n     */\n\n\n    open(onMessage, onDisconnect) {\n      this.onDisconnect = onDisconnect;\n      this.onMessage = onMessage;\n      this.log_('Websocket connecting to ' + this.connURL);\n      this.everConnected_ = false; // Assume failure until proven otherwise.\n\n      PersistentStorage.set('previous_websocket_failure', true);\n\n      try {\n        let options;\n\n        if (isNodeSdk()) {\n          const device = this.nodeAdmin ? 'AdminNode' : 'Node'; // UA Format: Firebase/<wire_protocol>/<sdk_version>/<platform>/<device>\n\n          const options = {\n            headers: {\n              'User-Agent': `Firebase/${PROTOCOL_VERSION}/${SDK_VERSION}/${process.platform}/${device}`,\n              'X-Firebase-GMPID': this.applicationId || ''\n            }\n          }; // If using Node with admin creds, AppCheck-related checks are unnecessary.\n          // Note that we send the credentials here even if they aren't admin credentials, which is\n          // not a problem.\n          // Note that this header is just used to bypass appcheck, and the token should still be sent\n          // through the websocket connection once it is established.\n\n          if (this.authToken) {\n            options.headers['Authorization'] = `Bearer ${this.authToken}`;\n          }\n\n          if (this.appCheckToken) {\n            options.headers['X-Firebase-AppCheck'] = this.appCheckToken;\n          } // Plumb appropriate http_proxy environment variable into faye-websocket if it exists.\n\n\n          const env = process['env'];\n          const proxy = this.connURL.indexOf('wss://') === 0 ? env['HTTPS_PROXY'] || env['https_proxy'] : env['HTTP_PROXY'] || env['http_proxy'];\n\n          if (proxy) {\n            options['proxy'] = {\n              origin: proxy\n            };\n          }\n        }\n\n        this.mySock = new WebSocketImpl(this.connURL, [], options);\n      } catch (e) {\n        this.log_('Error instantiating WebSocket.');\n        const error = e.message || e.data;\n\n        if (error) {\n          this.log_(error);\n        }\n\n        this.onClosed_();\n        return;\n      }\n\n      this.mySock.onopen = () => {\n        this.log_('Websocket connected.');\n        this.everConnected_ = true;\n      };\n\n      this.mySock.onclose = () => {\n        this.log_('Websocket connection was disconnected.');\n        this.mySock = null;\n        this.onClosed_();\n      };\n\n      this.mySock.onmessage = m => {\n        this.handleIncomingFrame(m);\n      };\n\n      this.mySock.onerror = e => {\n        this.log_('WebSocket error.  Closing connection.'); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n        const error = e.message || e.data;\n\n        if (error) {\n          this.log_(error);\n        }\n\n        this.onClosed_();\n      };\n    }\n    /**\r\n     * No-op for websockets, we don't need to do anything once the connection is confirmed as open\r\n     */\n\n\n    start() {}\n\n    static forceDisallow() {\n      WebSocketConnection.forceDisallow_ = true;\n    }\n\n    static isAvailable() {\n      let isOldAndroid = false;\n\n      if (typeof navigator !== 'undefined' && navigator.userAgent) {\n        const oldAndroidRegex = /Android ([0-9]{0,}\\.[0-9]{0,})/;\n        const oldAndroidMatch = navigator.userAgent.match(oldAndroidRegex);\n\n        if (oldAndroidMatch && oldAndroidMatch.length > 1) {\n          if (parseFloat(oldAndroidMatch[1]) < 4.4) {\n            isOldAndroid = true;\n          }\n        }\n      }\n\n      return !isOldAndroid && WebSocketImpl !== null && !WebSocketConnection.forceDisallow_;\n    }\n    /**\r\n     * Returns true if we previously failed to connect with this transport.\r\n     */\n\n\n    static previouslyFailed() {\n      // If our persistent storage is actually only in-memory storage,\n      // we default to assuming that it previously failed to be safe.\n      return PersistentStorage.isInMemoryStorage || PersistentStorage.get('previous_websocket_failure') === true;\n    }\n\n    markConnectionHealthy() {\n      PersistentStorage.remove('previous_websocket_failure');\n    }\n\n    appendFrame_(data) {\n      this.frames.push(data);\n\n      if (this.frames.length === this.totalFrames) {\n        const fullMess = this.frames.join('');\n        this.frames = null;\n        const jsonMess = jsonEval(fullMess); //handle the message\n\n        this.onMessage(jsonMess);\n      }\n    }\n    /**\r\n     * @param frameCount - The number of frames we are expecting from the server\r\n     */\n\n\n    handleNewFrameCount_(frameCount) {\n      this.totalFrames = frameCount;\n      this.frames = [];\n    }\n    /**\r\n     * Attempts to parse a frame count out of some text. If it can't, assumes a value of 1\r\n     * @returns Any remaining data to be process, or null if there is none\r\n     */\n\n\n    extractFrameCount_(data) {\n      assert(this.frames === null, 'We already have a frame buffer'); // TODO: The server is only supposed to send up to 9999 frames (i.e. length <= 4), but that isn't being enforced\n      // currently.  So allowing larger frame counts (length <= 6).  See https://app.asana.com/0/search/8688598998380/8237608042508\n\n      if (data.length <= 6) {\n        const frameCount = Number(data);\n\n        if (!isNaN(frameCount)) {\n          this.handleNewFrameCount_(frameCount);\n          return null;\n        }\n      }\n\n      this.handleNewFrameCount_(1);\n      return data;\n    }\n    /**\r\n     * Process a websocket frame that has arrived from the server.\r\n     * @param mess - The frame data\r\n     */\n\n\n    handleIncomingFrame(mess) {\n      if (this.mySock === null) {\n        return; // Chrome apparently delivers incoming packets even after we .close() the connection sometimes.\n      }\n\n      const data = mess['data'];\n      this.bytesReceived += data.length;\n      this.stats_.incrementCounter('bytes_received', data.length);\n      this.resetKeepAlive();\n\n      if (this.frames !== null) {\n        // we're buffering\n        this.appendFrame_(data);\n      } else {\n        // try to parse out a frame count, otherwise, assume 1 and process it\n        const remainingData = this.extractFrameCount_(data);\n\n        if (remainingData !== null) {\n          this.appendFrame_(remainingData);\n        }\n      }\n    }\n    /**\r\n     * Send a message to the server\r\n     * @param data - The JSON object to transmit\r\n     */\n\n\n    send(data) {\n      this.resetKeepAlive();\n      const dataStr = stringify(data);\n      this.bytesSent += dataStr.length;\n      this.stats_.incrementCounter('bytes_sent', dataStr.length); //We can only fit a certain amount in each websocket frame, so we need to split this request\n      //up into multiple pieces if it doesn't fit in one request.\n\n      const dataSegs = splitStringBySize(dataStr, WEBSOCKET_MAX_FRAME_SIZE); //Send the length header\n\n      if (dataSegs.length > 1) {\n        this.sendString_(String(dataSegs.length));\n      } //Send the actual data in segments.\n\n\n      for (let i = 0; i < dataSegs.length; i++) {\n        this.sendString_(dataSegs[i]);\n      }\n    }\n\n    shutdown_() {\n      this.isClosed_ = true;\n\n      if (this.keepaliveTimer) {\n        clearInterval(this.keepaliveTimer);\n        this.keepaliveTimer = null;\n      }\n\n      if (this.mySock) {\n        this.mySock.close();\n        this.mySock = null;\n      }\n    }\n\n    onClosed_() {\n      if (!this.isClosed_) {\n        this.log_('WebSocket is closing itself');\n        this.shutdown_(); // since this is an internal close, trigger the close listener\n\n        if (this.onDisconnect) {\n          this.onDisconnect(this.everConnected_);\n          this.onDisconnect = null;\n        }\n      }\n    }\n    /**\r\n     * External-facing close handler.\r\n     * Close the websocket and kill the connection.\r\n     */\n\n\n    close() {\n      if (!this.isClosed_) {\n        this.log_('WebSocket is being closed');\n        this.shutdown_();\n      }\n    }\n    /**\r\n     * Kill the current keepalive timer and start a new one, to ensure that it always fires N seconds after\r\n     * the last activity.\r\n     */\n\n\n    resetKeepAlive() {\n      clearInterval(this.keepaliveTimer);\n      this.keepaliveTimer = setInterval(() => {\n        //If there has been no websocket activity for a while, send a no-op\n        if (this.mySock) {\n          this.sendString_('0');\n        }\n\n        this.resetKeepAlive(); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      }, Math.floor(WEBSOCKET_KEEPALIVE_INTERVAL));\n    }\n    /**\r\n     * Send a string over the websocket.\r\n     *\r\n     * @param str - String to send.\r\n     */\n\n\n    sendString_(str) {\n      // Firefox seems to sometimes throw exceptions (NS_ERROR_UNEXPECTED) from websocket .send()\n      // calls for some unknown reason.  We treat these as an error and disconnect.\n      // See https://app.asana.com/0/58926111402292/68021340250410\n      try {\n        this.mySock.send(str);\n      } catch (e) {\n        this.log_('Exception thrown from WebSocket.send():', e.message || e.data, 'Closing connection.');\n        setTimeout(this.onClosed_.bind(this), 0);\n      }\n    }\n\n  }\n\n  /**\r\n   * Number of response before we consider the connection \"healthy.\"\r\n   */\n  WebSocketConnection.responsesRequiredToBeHealthy = 2;\n  /**\r\n   * Time to wait for the connection te become healthy before giving up.\r\n   */\n\n  WebSocketConnection.healthyTimeout = 30000;\n  /**\r\n   * @license\r\n   * Copyright 2017 Google LLC\r\n   *\r\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   * you may not use this file except in compliance with the License.\r\n   * You may obtain a copy of the License at\r\n   *\r\n   *   http://www.apache.org/licenses/LICENSE-2.0\r\n   *\r\n   * Unless required by applicable law or agreed to in writing, software\r\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   * See the License for the specific language governing permissions and\r\n   * limitations under the License.\r\n   */\n\n  /**\r\n   * Currently simplistic, this class manages what transport a Connection should use at various stages of its\r\n   * lifecycle.\r\n   *\r\n   * It starts with longpolling in a browser, and httppolling on node. It then upgrades to websockets if\r\n   * they are available.\r\n   */\n\n  return WebSocketConnection;\n})();\nlet TransportManager = /*#__PURE__*/(() => {\n  class TransportManager {\n    /**\r\n     * @param repoInfo - Metadata around the namespace we're connecting to\r\n     */\n    constructor(repoInfo) {\n      this.initTransports_(repoInfo);\n    }\n\n    static get ALL_TRANSPORTS() {\n      return [BrowserPollConnection, WebSocketConnection];\n    }\n    /**\r\n     * Returns whether transport has been selected to ensure WebSocketConnection or BrowserPollConnection are not called after\r\n     * TransportManager has already set up transports_\r\n     */\n\n\n    static get IS_TRANSPORT_INITIALIZED() {\n      return this.globalTransportInitialized_;\n    }\n\n    initTransports_(repoInfo) {\n      const isWebSocketsAvailable = WebSocketConnection && WebSocketConnection['isAvailable']();\n      let isSkipPollConnection = isWebSocketsAvailable && !WebSocketConnection.previouslyFailed();\n\n      if (repoInfo.webSocketOnly) {\n        if (!isWebSocketsAvailable) {\n          warn(\"wss:// URL used, but browser isn't known to support websockets.  Trying anyway.\");\n        }\n\n        isSkipPollConnection = true;\n      }\n\n      if (isSkipPollConnection) {\n        this.transports_ = [WebSocketConnection];\n      } else {\n        const transports = this.transports_ = [];\n\n        for (const transport of TransportManager.ALL_TRANSPORTS) {\n          if (transport && transport['isAvailable']()) {\n            transports.push(transport);\n          }\n        }\n\n        TransportManager.globalTransportInitialized_ = true;\n      }\n    }\n    /**\r\n     * @returns The constructor for the initial transport to use\r\n     */\n\n\n    initialTransport() {\n      if (this.transports_.length > 0) {\n        return this.transports_[0];\n      } else {\n        throw new Error('No transports available');\n      }\n    }\n    /**\r\n     * @returns The constructor for the next transport, or null\r\n     */\n\n\n    upgradeTransport() {\n      if (this.transports_.length > 1) {\n        return this.transports_[1];\n      } else {\n        return null;\n      }\n    }\n\n  }\n\n  // Keeps track of whether the TransportManager has already chosen a transport to use\n  TransportManager.globalTransportInitialized_ = false;\n  /**\r\n   * @license\r\n   * Copyright 2017 Google LLC\r\n   *\r\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   * you may not use this file except in compliance with the License.\r\n   * You may obtain a copy of the License at\r\n   *\r\n   *   http://www.apache.org/licenses/LICENSE-2.0\r\n   *\r\n   * Unless required by applicable law or agreed to in writing, software\r\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   * See the License for the specific language governing permissions and\r\n   * limitations under the License.\r\n   */\n  // Abort upgrade attempt if it takes longer than 60s.\n\n  return TransportManager;\n})();\nconst UPGRADE_TIMEOUT = 60000; // For some transports (WebSockets), we need to \"validate\" the transport by exchanging a few requests and responses.\n// If we haven't sent enough requests within 5s, we'll start sending noop ping requests.\n\nconst DELAY_BEFORE_SENDING_EXTRA_REQUESTS = 5000; // If the initial data sent triggers a lot of bandwidth (i.e. it's a large put or a listen for a large amount of data)\n// then we may not be able to exchange our ping/pong requests within the healthy timeout.  So if we reach the timeout\n// but we've sent/received enough bytes, we don't cancel the connection.\n\nconst BYTES_SENT_HEALTHY_OVERRIDE = 10 * 1024;\nconst BYTES_RECEIVED_HEALTHY_OVERRIDE = 100 * 1024;\nconst MESSAGE_TYPE = 't';\nconst MESSAGE_DATA = 'd';\nconst CONTROL_SHUTDOWN = 's';\nconst CONTROL_RESET = 'r';\nconst CONTROL_ERROR = 'e';\nconst CONTROL_PONG = 'o';\nconst SWITCH_ACK = 'a';\nconst END_TRANSMISSION = 'n';\nconst PING = 'p';\nconst SERVER_HELLO = 'h';\n/**\r\n * Creates a new real-time connection to the server using whichever method works\r\n * best in the current browser.\r\n */\n\nclass Connection {\n  /**\r\n   * @param id - an id for this connection\r\n   * @param repoInfo_ - the info for the endpoint to connect to\r\n   * @param applicationId_ - the Firebase App ID for this project\r\n   * @param appCheckToken_ - The App Check Token for this device.\r\n   * @param authToken_ - The auth token for this session.\r\n   * @param onMessage_ - the callback to be triggered when a server-push message arrives\r\n   * @param onReady_ - the callback to be triggered when this connection is ready to send messages.\r\n   * @param onDisconnect_ - the callback to be triggered when a connection was lost\r\n   * @param onKill_ - the callback to be triggered when this connection has permanently shut down.\r\n   * @param lastSessionId - last session id in persistent connection. is used to clean up old session in real-time server\r\n   */\n  constructor(id, repoInfo_, applicationId_, appCheckToken_, authToken_, onMessage_, onReady_, onDisconnect_, onKill_, lastSessionId) {\n    this.id = id;\n    this.repoInfo_ = repoInfo_;\n    this.applicationId_ = applicationId_;\n    this.appCheckToken_ = appCheckToken_;\n    this.authToken_ = authToken_;\n    this.onMessage_ = onMessage_;\n    this.onReady_ = onReady_;\n    this.onDisconnect_ = onDisconnect_;\n    this.onKill_ = onKill_;\n    this.lastSessionId = lastSessionId;\n    this.connectionCount = 0;\n    this.pendingDataMessages = [];\n    this.state_ = 0\n    /* CONNECTING */\n    ;\n    this.log_ = logWrapper('c:' + this.id + ':');\n    this.transportManager_ = new TransportManager(repoInfo_);\n    this.log_('Connection created');\n    this.start_();\n  }\n  /**\r\n   * Starts a connection attempt\r\n   */\n\n\n  start_() {\n    const conn = this.transportManager_.initialTransport();\n    this.conn_ = new conn(this.nextTransportId_(), this.repoInfo_, this.applicationId_, this.appCheckToken_, this.authToken_, null, this.lastSessionId); // For certain transports (WebSockets), we need to send and receive several messages back and forth before we\n    // can consider the transport healthy.\n\n    this.primaryResponsesRequired_ = conn['responsesRequiredToBeHealthy'] || 0;\n    const onMessageReceived = this.connReceiver_(this.conn_);\n    const onConnectionLost = this.disconnReceiver_(this.conn_);\n    this.tx_ = this.conn_;\n    this.rx_ = this.conn_;\n    this.secondaryConn_ = null;\n    this.isHealthy_ = false;\n    /*\r\n     * Firefox doesn't like when code from one iframe tries to create another iframe by way of the parent frame.\r\n     * This can occur in the case of a redirect, i.e. we guessed wrong on what server to connect to and received a reset.\r\n     * Somehow, setTimeout seems to make this ok. That doesn't make sense from a security perspective, since you should\r\n     * still have the context of your originating frame.\r\n     */\n\n    setTimeout(() => {\n      // this.conn_ gets set to null in some of the tests. Check to make sure it still exists before using it\n      this.conn_ && this.conn_.open(onMessageReceived, onConnectionLost);\n    }, Math.floor(0));\n    const healthyTimeoutMS = conn['healthyTimeout'] || 0;\n\n    if (healthyTimeoutMS > 0) {\n      this.healthyTimeout_ = setTimeoutNonBlocking(() => {\n        this.healthyTimeout_ = null;\n\n        if (!this.isHealthy_) {\n          if (this.conn_ && this.conn_.bytesReceived > BYTES_RECEIVED_HEALTHY_OVERRIDE) {\n            this.log_('Connection exceeded healthy timeout but has received ' + this.conn_.bytesReceived + ' bytes.  Marking connection healthy.');\n            this.isHealthy_ = true;\n            this.conn_.markConnectionHealthy();\n          } else if (this.conn_ && this.conn_.bytesSent > BYTES_SENT_HEALTHY_OVERRIDE) {\n            this.log_('Connection exceeded healthy timeout but has sent ' + this.conn_.bytesSent + ' bytes.  Leaving connection alive.'); // NOTE: We don't want to mark it healthy, since we have no guarantee that the bytes have made it to\n            // the server.\n          } else {\n            this.log_('Closing unhealthy connection after timeout.');\n            this.close();\n          }\n        } // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n      }, Math.floor(healthyTimeoutMS));\n    }\n  }\n\n  nextTransportId_() {\n    return 'c:' + this.id + ':' + this.connectionCount++;\n  }\n\n  disconnReceiver_(conn) {\n    return everConnected => {\n      if (conn === this.conn_) {\n        this.onConnectionLost_(everConnected);\n      } else if (conn === this.secondaryConn_) {\n        this.log_('Secondary connection lost.');\n        this.onSecondaryConnectionLost_();\n      } else {\n        this.log_('closing an old connection');\n      }\n    };\n  }\n\n  connReceiver_(conn) {\n    return message => {\n      if (this.state_ !== 2\n      /* DISCONNECTED */\n      ) {\n        if (conn === this.rx_) {\n          this.onPrimaryMessageReceived_(message);\n        } else if (conn === this.secondaryConn_) {\n          this.onSecondaryMessageReceived_(message);\n        } else {\n          this.log_('message on old connection');\n        }\n      }\n    };\n  }\n  /**\r\n   * @param dataMsg - An arbitrary data message to be sent to the server\r\n   */\n\n\n  sendRequest(dataMsg) {\n    // wrap in a data message envelope and send it on\n    const msg = {\n      t: 'd',\n      d: dataMsg\n    };\n    this.sendData_(msg);\n  }\n\n  tryCleanupConnection() {\n    if (this.tx_ === this.secondaryConn_ && this.rx_ === this.secondaryConn_) {\n      this.log_('cleaning up and promoting a connection: ' + this.secondaryConn_.connId);\n      this.conn_ = this.secondaryConn_;\n      this.secondaryConn_ = null; // the server will shutdown the old connection\n    }\n  }\n\n  onSecondaryControl_(controlData) {\n    if (MESSAGE_TYPE in controlData) {\n      const cmd = controlData[MESSAGE_TYPE];\n\n      if (cmd === SWITCH_ACK) {\n        this.upgradeIfSecondaryHealthy_();\n      } else if (cmd === CONTROL_RESET) {\n        // Most likely the session wasn't valid. Abandon the switch attempt\n        this.log_('Got a reset on secondary, closing it');\n        this.secondaryConn_.close(); // If we were already using this connection for something, than we need to fully close\n\n        if (this.tx_ === this.secondaryConn_ || this.rx_ === this.secondaryConn_) {\n          this.close();\n        }\n      } else if (cmd === CONTROL_PONG) {\n        this.log_('got pong on secondary.');\n        this.secondaryResponsesRequired_--;\n        this.upgradeIfSecondaryHealthy_();\n      }\n    }\n  }\n\n  onSecondaryMessageReceived_(parsedData) {\n    const layer = requireKey('t', parsedData);\n    const data = requireKey('d', parsedData);\n\n    if (layer === 'c') {\n      this.onSecondaryControl_(data);\n    } else if (layer === 'd') {\n      // got a data message, but we're still second connection. Need to buffer it up\n      this.pendingDataMessages.push(data);\n    } else {\n      throw new Error('Unknown protocol layer: ' + layer);\n    }\n  }\n\n  upgradeIfSecondaryHealthy_() {\n    if (this.secondaryResponsesRequired_ <= 0) {\n      this.log_('Secondary connection is healthy.');\n      this.isHealthy_ = true;\n      this.secondaryConn_.markConnectionHealthy();\n      this.proceedWithUpgrade_();\n    } else {\n      // Send a ping to make sure the connection is healthy.\n      this.log_('sending ping on secondary.');\n      this.secondaryConn_.send({\n        t: 'c',\n        d: {\n          t: PING,\n          d: {}\n        }\n      });\n    }\n  }\n\n  proceedWithUpgrade_() {\n    // tell this connection to consider itself open\n    this.secondaryConn_.start(); // send ack\n\n    this.log_('sending client ack on secondary');\n    this.secondaryConn_.send({\n      t: 'c',\n      d: {\n        t: SWITCH_ACK,\n        d: {}\n      }\n    }); // send end packet on primary transport, switch to sending on this one\n    // can receive on this one, buffer responses until end received on primary transport\n\n    this.log_('Ending transmission on primary');\n    this.conn_.send({\n      t: 'c',\n      d: {\n        t: END_TRANSMISSION,\n        d: {}\n      }\n    });\n    this.tx_ = this.secondaryConn_;\n    this.tryCleanupConnection();\n  }\n\n  onPrimaryMessageReceived_(parsedData) {\n    // Must refer to parsedData properties in quotes, so closure doesn't touch them.\n    const layer = requireKey('t', parsedData);\n    const data = requireKey('d', parsedData);\n\n    if (layer === 'c') {\n      this.onControl_(data);\n    } else if (layer === 'd') {\n      this.onDataMessage_(data);\n    }\n  }\n\n  onDataMessage_(message) {\n    this.onPrimaryResponse_(); // We don't do anything with data messages, just kick them up a level\n\n    this.onMessage_(message);\n  }\n\n  onPrimaryResponse_() {\n    if (!this.isHealthy_) {\n      this.primaryResponsesRequired_--;\n\n      if (this.primaryResponsesRequired_ <= 0) {\n        this.log_('Primary connection is healthy.');\n        this.isHealthy_ = true;\n        this.conn_.markConnectionHealthy();\n      }\n    }\n  }\n\n  onControl_(controlData) {\n    const cmd = requireKey(MESSAGE_TYPE, controlData);\n\n    if (MESSAGE_DATA in controlData) {\n      const payload = controlData[MESSAGE_DATA];\n\n      if (cmd === SERVER_HELLO) {\n        this.onHandshake_(payload);\n      } else if (cmd === END_TRANSMISSION) {\n        this.log_('recvd end transmission on primary');\n        this.rx_ = this.secondaryConn_;\n\n        for (let i = 0; i < this.pendingDataMessages.length; ++i) {\n          this.onDataMessage_(this.pendingDataMessages[i]);\n        }\n\n        this.pendingDataMessages = [];\n        this.tryCleanupConnection();\n      } else if (cmd === CONTROL_SHUTDOWN) {\n        // This was previously the 'onKill' callback passed to the lower-level connection\n        // payload in this case is the reason for the shutdown. Generally a human-readable error\n        this.onConnectionShutdown_(payload);\n      } else if (cmd === CONTROL_RESET) {\n        // payload in this case is the host we should contact\n        this.onReset_(payload);\n      } else if (cmd === CONTROL_ERROR) {\n        error('Server Error: ' + payload);\n      } else if (cmd === CONTROL_PONG) {\n        this.log_('got pong on primary.');\n        this.onPrimaryResponse_();\n        this.sendPingOnPrimaryIfNecessary_();\n      } else {\n        error('Unknown control packet command: ' + cmd);\n      }\n    }\n  }\n  /**\r\n   * @param handshake - The handshake data returned from the server\r\n   */\n\n\n  onHandshake_(handshake) {\n    const timestamp = handshake.ts;\n    const version = handshake.v;\n    const host = handshake.h;\n    this.sessionId = handshake.s;\n    this.repoInfo_.host = host; // if we've already closed the connection, then don't bother trying to progress further\n\n    if (this.state_ === 0\n    /* CONNECTING */\n    ) {\n      this.conn_.start();\n      this.onConnectionEstablished_(this.conn_, timestamp);\n\n      if (PROTOCOL_VERSION !== version) {\n        warn('Protocol version mismatch detected');\n      } // TODO: do we want to upgrade? when? maybe a delay?\n\n\n      this.tryStartUpgrade_();\n    }\n  }\n\n  tryStartUpgrade_() {\n    const conn = this.transportManager_.upgradeTransport();\n\n    if (conn) {\n      this.startUpgrade_(conn);\n    }\n  }\n\n  startUpgrade_(conn) {\n    this.secondaryConn_ = new conn(this.nextTransportId_(), this.repoInfo_, this.applicationId_, this.appCheckToken_, this.authToken_, this.sessionId); // For certain transports (WebSockets), we need to send and receive several messages back and forth before we\n    // can consider the transport healthy.\n\n    this.secondaryResponsesRequired_ = conn['responsesRequiredToBeHealthy'] || 0;\n    const onMessage = this.connReceiver_(this.secondaryConn_);\n    const onDisconnect = this.disconnReceiver_(this.secondaryConn_);\n    this.secondaryConn_.open(onMessage, onDisconnect); // If we haven't successfully upgraded after UPGRADE_TIMEOUT, give up and kill the secondary.\n\n    setTimeoutNonBlocking(() => {\n      if (this.secondaryConn_) {\n        this.log_('Timed out trying to upgrade.');\n        this.secondaryConn_.close();\n      }\n    }, Math.floor(UPGRADE_TIMEOUT));\n  }\n\n  onReset_(host) {\n    this.log_('Reset packet received.  New host: ' + host);\n    this.repoInfo_.host = host; // TODO: if we're already \"connected\", we need to trigger a disconnect at the next layer up.\n    // We don't currently support resets after the connection has already been established\n\n    if (this.state_ === 1\n    /* CONNECTED */\n    ) {\n      this.close();\n    } else {\n      // Close whatever connections we have open and start again.\n      this.closeConnections_();\n      this.start_();\n    }\n  }\n\n  onConnectionEstablished_(conn, timestamp) {\n    this.log_('Realtime connection established.');\n    this.conn_ = conn;\n    this.state_ = 1\n    /* CONNECTED */\n    ;\n\n    if (this.onReady_) {\n      this.onReady_(timestamp, this.sessionId);\n      this.onReady_ = null;\n    } // If after 5 seconds we haven't sent enough requests to the server to get the connection healthy,\n    // send some pings.\n\n\n    if (this.primaryResponsesRequired_ === 0) {\n      this.log_('Primary connection is healthy.');\n      this.isHealthy_ = true;\n    } else {\n      setTimeoutNonBlocking(() => {\n        this.sendPingOnPrimaryIfNecessary_();\n      }, Math.floor(DELAY_BEFORE_SENDING_EXTRA_REQUESTS));\n    }\n  }\n\n  sendPingOnPrimaryIfNecessary_() {\n    // If the connection isn't considered healthy yet, we'll send a noop ping packet request.\n    if (!this.isHealthy_ && this.state_ === 1\n    /* CONNECTED */\n    ) {\n      this.log_('sending ping on primary.');\n      this.sendData_({\n        t: 'c',\n        d: {\n          t: PING,\n          d: {}\n        }\n      });\n    }\n  }\n\n  onSecondaryConnectionLost_() {\n    const conn = this.secondaryConn_;\n    this.secondaryConn_ = null;\n\n    if (this.tx_ === conn || this.rx_ === conn) {\n      // we are relying on this connection already in some capacity. Therefore, a failure is real\n      this.close();\n    }\n  }\n  /**\r\n   * @param everConnected - Whether or not the connection ever reached a server. Used to determine if\r\n   * we should flush the host cache\r\n   */\n\n\n  onConnectionLost_(everConnected) {\n    this.conn_ = null; // NOTE: IF you're seeing a Firefox error for this line, I think it might be because it's getting\n    // called on window close and RealtimeState.CONNECTING is no longer defined.  Just a guess.\n\n    if (!everConnected && this.state_ === 0\n    /* CONNECTING */\n    ) {\n      this.log_('Realtime connection failed.'); // Since we failed to connect at all, clear any cached entry for this namespace in case the machine went away\n\n      if (this.repoInfo_.isCacheableHost()) {\n        PersistentStorage.remove('host:' + this.repoInfo_.host); // reset the internal host to what we would show the user, i.e. <ns>.firebaseio.com\n\n        this.repoInfo_.internalHost = this.repoInfo_.host;\n      }\n    } else if (this.state_ === 1\n    /* CONNECTED */\n    ) {\n      this.log_('Realtime connection lost.');\n    }\n\n    this.close();\n  }\n\n  onConnectionShutdown_(reason) {\n    this.log_('Connection shutdown command received. Shutting down...');\n\n    if (this.onKill_) {\n      this.onKill_(reason);\n      this.onKill_ = null;\n    } // We intentionally don't want to fire onDisconnect (kill is a different case),\n    // so clear the callback.\n\n\n    this.onDisconnect_ = null;\n    this.close();\n  }\n\n  sendData_(data) {\n    if (this.state_ !== 1\n    /* CONNECTED */\n    ) {\n      throw 'Connection is not connected';\n    } else {\n      this.tx_.send(data);\n    }\n  }\n  /**\r\n   * Cleans up this connection, calling the appropriate callbacks\r\n   */\n\n\n  close() {\n    if (this.state_ !== 2\n    /* DISCONNECTED */\n    ) {\n      this.log_('Closing realtime connection.');\n      this.state_ = 2\n      /* DISCONNECTED */\n      ;\n      this.closeConnections_();\n\n      if (this.onDisconnect_) {\n        this.onDisconnect_();\n        this.onDisconnect_ = null;\n      }\n    }\n  }\n\n  closeConnections_() {\n    this.log_('Shutting down all connections');\n\n    if (this.conn_) {\n      this.conn_.close();\n      this.conn_ = null;\n    }\n\n    if (this.secondaryConn_) {\n      this.secondaryConn_.close();\n      this.secondaryConn_ = null;\n    }\n\n    if (this.healthyTimeout_) {\n      clearTimeout(this.healthyTimeout_);\n      this.healthyTimeout_ = null;\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Interface defining the set of actions that can be performed against the Firebase server\r\n * (basically corresponds to our wire protocol).\r\n *\r\n * @interface\r\n */\n\n\nclass ServerActions {\n  put(pathString, data, onComplete, hash) {}\n\n  merge(pathString, data, onComplete, hash) {}\n  /**\r\n   * Refreshes the auth token for the current connection.\r\n   * @param token - The authentication token\r\n   */\n\n\n  refreshAuthToken(token) {}\n  /**\r\n   * Refreshes the app check token for the current connection.\r\n   * @param token The app check token\r\n   */\n\n\n  refreshAppCheckToken(token) {}\n\n  onDisconnectPut(pathString, data, onComplete) {}\n\n  onDisconnectMerge(pathString, data, onComplete) {}\n\n  onDisconnectCancel(pathString, onComplete) {}\n\n  reportStats(stats) {}\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Base class to be used if you want to emit events. Call the constructor with\r\n * the set of allowed event names.\r\n */\n\n\nclass EventEmitter {\n  constructor(allowedEvents_) {\n    this.allowedEvents_ = allowedEvents_;\n    this.listeners_ = {};\n    assert(Array.isArray(allowedEvents_) && allowedEvents_.length > 0, 'Requires a non-empty array');\n  }\n  /**\r\n   * To be called by derived classes to trigger events.\r\n   */\n\n\n  trigger(eventType, ...varArgs) {\n    if (Array.isArray(this.listeners_[eventType])) {\n      // Clone the list, since callbacks could add/remove listeners.\n      const listeners = [...this.listeners_[eventType]];\n\n      for (let i = 0; i < listeners.length; i++) {\n        listeners[i].callback.apply(listeners[i].context, varArgs);\n      }\n    }\n  }\n\n  on(eventType, callback, context) {\n    this.validateEventType_(eventType);\n    this.listeners_[eventType] = this.listeners_[eventType] || [];\n    this.listeners_[eventType].push({\n      callback,\n      context\n    });\n    const eventData = this.getInitialEvent(eventType);\n\n    if (eventData) {\n      callback.apply(context, eventData);\n    }\n  }\n\n  off(eventType, callback, context) {\n    this.validateEventType_(eventType);\n    const listeners = this.listeners_[eventType] || [];\n\n    for (let i = 0; i < listeners.length; i++) {\n      if (listeners[i].callback === callback && (!context || context === listeners[i].context)) {\n        listeners.splice(i, 1);\n        return;\n      }\n    }\n  }\n\n  validateEventType_(eventType) {\n    assert(this.allowedEvents_.find(et => {\n      return et === eventType;\n    }), 'Unknown event: ' + eventType);\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Monitors online state (as reported by window.online/offline events).\r\n *\r\n * The expectation is that this could have many false positives (thinks we are online\r\n * when we're not), but no false negatives.  So we can safely use it to determine when\r\n * we definitely cannot reach the internet.\r\n */\n\n\nclass OnlineMonitor extends EventEmitter {\n  constructor() {\n    super(['online']);\n    this.online_ = true; // We've had repeated complaints that Cordova apps can get stuck \"offline\", e.g.\n    // https://forum.ionicframework.com/t/firebase-connection-is-lost-and-never-come-back/43810\n    // It would seem that the 'online' event does not always fire consistently. So we disable it\n    // for Cordova.\n\n    if (typeof window !== 'undefined' && typeof window.addEventListener !== 'undefined' && !isMobileCordova()) {\n      window.addEventListener('online', () => {\n        if (!this.online_) {\n          this.online_ = true;\n          this.trigger('online', true);\n        }\n      }, false);\n      window.addEventListener('offline', () => {\n        if (this.online_) {\n          this.online_ = false;\n          this.trigger('online', false);\n        }\n      }, false);\n    }\n  }\n\n  static getInstance() {\n    return new OnlineMonitor();\n  }\n\n  getInitialEvent(eventType) {\n    assert(eventType === 'online', 'Unknown event type: ' + eventType);\n    return [this.online_];\n  }\n\n  currentlyOnline() {\n    return this.online_;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Maximum key depth. */\n\n\nconst MAX_PATH_DEPTH = 32;\n/** Maximum number of (UTF8) bytes in a Firebase path. */\n\nconst MAX_PATH_LENGTH_BYTES = 768;\n/**\r\n * An immutable object representing a parsed path.  It's immutable so that you\r\n * can pass them around to other functions without worrying about them changing\r\n * it.\r\n */\n\nclass Path {\n  /**\r\n   * @param pathOrString - Path string to parse, or another path, or the raw\r\n   * tokens array\r\n   */\n  constructor(pathOrString, pieceNum) {\n    if (pieceNum === void 0) {\n      this.pieces_ = pathOrString.split('/'); // Remove empty pieces.\n\n      let copyTo = 0;\n\n      for (let i = 0; i < this.pieces_.length; i++) {\n        if (this.pieces_[i].length > 0) {\n          this.pieces_[copyTo] = this.pieces_[i];\n          copyTo++;\n        }\n      }\n\n      this.pieces_.length = copyTo;\n      this.pieceNum_ = 0;\n    } else {\n      this.pieces_ = pathOrString;\n      this.pieceNum_ = pieceNum;\n    }\n  }\n\n  toString() {\n    let pathString = '';\n\n    for (let i = this.pieceNum_; i < this.pieces_.length; i++) {\n      if (this.pieces_[i] !== '') {\n        pathString += '/' + this.pieces_[i];\n      }\n    }\n\n    return pathString || '/';\n  }\n\n}\n\nfunction newEmptyPath() {\n  return new Path('');\n}\n\nfunction pathGetFront(path) {\n  if (path.pieceNum_ >= path.pieces_.length) {\n    return null;\n  }\n\n  return path.pieces_[path.pieceNum_];\n}\n/**\r\n * @returns The number of segments in this path\r\n */\n\n\nfunction pathGetLength(path) {\n  return path.pieces_.length - path.pieceNum_;\n}\n\nfunction pathPopFront(path) {\n  let pieceNum = path.pieceNum_;\n\n  if (pieceNum < path.pieces_.length) {\n    pieceNum++;\n  }\n\n  return new Path(path.pieces_, pieceNum);\n}\n\nfunction pathGetBack(path) {\n  if (path.pieceNum_ < path.pieces_.length) {\n    return path.pieces_[path.pieces_.length - 1];\n  }\n\n  return null;\n}\n\nfunction pathToUrlEncodedString(path) {\n  let pathString = '';\n\n  for (let i = path.pieceNum_; i < path.pieces_.length; i++) {\n    if (path.pieces_[i] !== '') {\n      pathString += '/' + encodeURIComponent(String(path.pieces_[i]));\n    }\n  }\n\n  return pathString || '/';\n}\n/**\r\n * Shallow copy of the parts of the path.\r\n *\r\n */\n\n\nfunction pathSlice(path, begin = 0) {\n  return path.pieces_.slice(path.pieceNum_ + begin);\n}\n\nfunction pathParent(path) {\n  if (path.pieceNum_ >= path.pieces_.length) {\n    return null;\n  }\n\n  const pieces = [];\n\n  for (let i = path.pieceNum_; i < path.pieces_.length - 1; i++) {\n    pieces.push(path.pieces_[i]);\n  }\n\n  return new Path(pieces, 0);\n}\n\nfunction pathChild(path, childPathObj) {\n  const pieces = [];\n\n  for (let i = path.pieceNum_; i < path.pieces_.length; i++) {\n    pieces.push(path.pieces_[i]);\n  }\n\n  if (childPathObj instanceof Path) {\n    for (let i = childPathObj.pieceNum_; i < childPathObj.pieces_.length; i++) {\n      pieces.push(childPathObj.pieces_[i]);\n    }\n  } else {\n    const childPieces = childPathObj.split('/');\n\n    for (let i = 0; i < childPieces.length; i++) {\n      if (childPieces[i].length > 0) {\n        pieces.push(childPieces[i]);\n      }\n    }\n  }\n\n  return new Path(pieces, 0);\n}\n/**\r\n * @returns True if there are no segments in this path\r\n */\n\n\nfunction pathIsEmpty(path) {\n  return path.pieceNum_ >= path.pieces_.length;\n}\n/**\r\n * @returns The path from outerPath to innerPath\r\n */\n\n\nfunction newRelativePath(outerPath, innerPath) {\n  const outer = pathGetFront(outerPath),\n        inner = pathGetFront(innerPath);\n\n  if (outer === null) {\n    return innerPath;\n  } else if (outer === inner) {\n    return newRelativePath(pathPopFront(outerPath), pathPopFront(innerPath));\n  } else {\n    throw new Error('INTERNAL ERROR: innerPath (' + innerPath + ') is not within ' + 'outerPath (' + outerPath + ')');\n  }\n}\n/**\r\n * @returns -1, 0, 1 if left is less, equal, or greater than the right.\r\n */\n\n\nfunction pathCompare(left, right) {\n  const leftKeys = pathSlice(left, 0);\n  const rightKeys = pathSlice(right, 0);\n\n  for (let i = 0; i < leftKeys.length && i < rightKeys.length; i++) {\n    const cmp = nameCompare(leftKeys[i], rightKeys[i]);\n\n    if (cmp !== 0) {\n      return cmp;\n    }\n  }\n\n  if (leftKeys.length === rightKeys.length) {\n    return 0;\n  }\n\n  return leftKeys.length < rightKeys.length ? -1 : 1;\n}\n/**\r\n * @returns true if paths are the same.\r\n */\n\n\nfunction pathEquals(path, other) {\n  if (pathGetLength(path) !== pathGetLength(other)) {\n    return false;\n  }\n\n  for (let i = path.pieceNum_, j = other.pieceNum_; i <= path.pieces_.length; i++, j++) {\n    if (path.pieces_[i] !== other.pieces_[j]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n/**\r\n * @returns True if this path is a parent of (or the same as) other\r\n */\n\n\nfunction pathContains(path, other) {\n  let i = path.pieceNum_;\n  let j = other.pieceNum_;\n\n  if (pathGetLength(path) > pathGetLength(other)) {\n    return false;\n  }\n\n  while (i < path.pieces_.length) {\n    if (path.pieces_[i] !== other.pieces_[j]) {\n      return false;\n    }\n\n    ++i;\n    ++j;\n  }\n\n  return true;\n}\n/**\r\n * Dynamic (mutable) path used to count path lengths.\r\n *\r\n * This class is used to efficiently check paths for valid\r\n * length (in UTF8 bytes) and depth (used in path validation).\r\n *\r\n * Throws Error exception if path is ever invalid.\r\n *\r\n * The definition of a path always begins with '/'.\r\n */\n\n\nclass ValidationPath {\n  /**\r\n   * @param path - Initial Path.\r\n   * @param errorPrefix_ - Prefix for any error messages.\r\n   */\n  constructor(path, errorPrefix_) {\n    this.errorPrefix_ = errorPrefix_;\n    this.parts_ = pathSlice(path, 0);\n    /** Initialize to number of '/' chars needed in path. */\n\n    this.byteLength_ = Math.max(1, this.parts_.length);\n\n    for (let i = 0; i < this.parts_.length; i++) {\n      this.byteLength_ += stringLength(this.parts_[i]);\n    }\n\n    validationPathCheckValid(this);\n  }\n\n}\n\nfunction validationPathPush(validationPath, child) {\n  // Count the needed '/'\n  if (validationPath.parts_.length > 0) {\n    validationPath.byteLength_ += 1;\n  }\n\n  validationPath.parts_.push(child);\n  validationPath.byteLength_ += stringLength(child);\n  validationPathCheckValid(validationPath);\n}\n\nfunction validationPathPop(validationPath) {\n  const last = validationPath.parts_.pop();\n  validationPath.byteLength_ -= stringLength(last); // Un-count the previous '/'\n\n  if (validationPath.parts_.length > 0) {\n    validationPath.byteLength_ -= 1;\n  }\n}\n\nfunction validationPathCheckValid(validationPath) {\n  if (validationPath.byteLength_ > MAX_PATH_LENGTH_BYTES) {\n    throw new Error(validationPath.errorPrefix_ + 'has a key path longer than ' + MAX_PATH_LENGTH_BYTES + ' bytes (' + validationPath.byteLength_ + ').');\n  }\n\n  if (validationPath.parts_.length > MAX_PATH_DEPTH) {\n    throw new Error(validationPath.errorPrefix_ + 'path specified exceeds the maximum depth that can be written (' + MAX_PATH_DEPTH + ') or object contains a cycle ' + validationPathToErrorString(validationPath));\n  }\n}\n/**\r\n * String for use in error messages - uses '.' notation for path.\r\n */\n\n\nfunction validationPathToErrorString(validationPath) {\n  if (validationPath.parts_.length === 0) {\n    return '';\n  }\n\n  return \"in property '\" + validationPath.parts_.join('.') + \"'\";\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass VisibilityMonitor extends EventEmitter {\n  constructor() {\n    super(['visible']);\n    let hidden;\n    let visibilityChange;\n\n    if (typeof document !== 'undefined' && typeof document.addEventListener !== 'undefined') {\n      if (typeof document['hidden'] !== 'undefined') {\n        // Opera 12.10 and Firefox 18 and later support\n        visibilityChange = 'visibilitychange';\n        hidden = 'hidden';\n      } else if (typeof document['mozHidden'] !== 'undefined') {\n        visibilityChange = 'mozvisibilitychange';\n        hidden = 'mozHidden';\n      } else if (typeof document['msHidden'] !== 'undefined') {\n        visibilityChange = 'msvisibilitychange';\n        hidden = 'msHidden';\n      } else if (typeof document['webkitHidden'] !== 'undefined') {\n        visibilityChange = 'webkitvisibilitychange';\n        hidden = 'webkitHidden';\n      }\n    } // Initially, we always assume we are visible. This ensures that in browsers\n    // without page visibility support or in cases where we are never visible\n    // (e.g. chrome extension), we act as if we are visible, i.e. don't delay\n    // reconnects\n\n\n    this.visible_ = true;\n\n    if (visibilityChange) {\n      document.addEventListener(visibilityChange, () => {\n        const visible = !document[hidden];\n\n        if (visible !== this.visible_) {\n          this.visible_ = visible;\n          this.trigger('visible', visible);\n        }\n      }, false);\n    }\n  }\n\n  static getInstance() {\n    return new VisibilityMonitor();\n  }\n\n  getInitialEvent(eventType) {\n    assert(eventType === 'visible', 'Unknown event type: ' + eventType);\n    return [this.visible_];\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nconst RECONNECT_MIN_DELAY = 1000;\nconst RECONNECT_MAX_DELAY_DEFAULT = 60 * 5 * 1000; // 5 minutes in milliseconds (Case: 1858)\n\nconst GET_CONNECT_TIMEOUT = 3 * 1000;\nconst RECONNECT_MAX_DELAY_FOR_ADMINS = 30 * 1000; // 30 seconds for admin clients (likely to be a backend server)\n\nconst RECONNECT_DELAY_MULTIPLIER = 1.3;\nconst RECONNECT_DELAY_RESET_TIMEOUT = 30000; // Reset delay back to MIN_DELAY after being connected for 30sec.\n\nconst SERVER_KILL_INTERRUPT_REASON = 'server_kill'; // If auth fails repeatedly, we'll assume something is wrong and log a warning / back off.\n\nconst INVALID_TOKEN_THRESHOLD = 3;\n/**\r\n * Firebase connection.  Abstracts wire protocol and handles reconnecting.\r\n *\r\n * NOTE: All JSON objects sent to the realtime connection must have property names enclosed\r\n * in quotes to make sure the closure compiler does not minify them.\r\n */\n\nlet PersistentConnection = /*#__PURE__*/(() => {\n  class PersistentConnection extends ServerActions {\n    /**\r\n     * @param repoInfo_ - Data about the namespace we are connecting to\r\n     * @param applicationId_ - The Firebase App ID for this project\r\n     * @param onDataUpdate_ - A callback for new data from the server\r\n     */\n    constructor(repoInfo_, applicationId_, onDataUpdate_, onConnectStatus_, onServerInfoUpdate_, authTokenProvider_, appCheckTokenProvider_, authOverride_) {\n      super();\n      this.repoInfo_ = repoInfo_;\n      this.applicationId_ = applicationId_;\n      this.onDataUpdate_ = onDataUpdate_;\n      this.onConnectStatus_ = onConnectStatus_;\n      this.onServerInfoUpdate_ = onServerInfoUpdate_;\n      this.authTokenProvider_ = authTokenProvider_;\n      this.appCheckTokenProvider_ = appCheckTokenProvider_;\n      this.authOverride_ = authOverride_; // Used for diagnostic logging.\n\n      this.id = PersistentConnection.nextPersistentConnectionId_++;\n      this.log_ = logWrapper('p:' + this.id + ':');\n      this.interruptReasons_ = {};\n      this.listens = new Map();\n      this.outstandingPuts_ = [];\n      this.outstandingGets_ = [];\n      this.outstandingPutCount_ = 0;\n      this.outstandingGetCount_ = 0;\n      this.onDisconnectRequestQueue_ = [];\n      this.connected_ = false;\n      this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n      this.maxReconnectDelay_ = RECONNECT_MAX_DELAY_DEFAULT;\n      this.securityDebugCallback_ = null;\n      this.lastSessionId = null;\n      this.establishConnectionTimer_ = null;\n      this.visible_ = false; // Before we get connected, we keep a queue of pending messages to send.\n\n      this.requestCBHash_ = {};\n      this.requestNumber_ = 0;\n      this.realtime_ = null;\n      this.authToken_ = null;\n      this.appCheckToken_ = null;\n      this.forceTokenRefresh_ = false;\n      this.invalidAuthTokenCount_ = 0;\n      this.invalidAppCheckTokenCount_ = 0;\n      this.firstConnection_ = true;\n      this.lastConnectionAttemptTime_ = null;\n      this.lastConnectionEstablishedTime_ = null;\n\n      if (authOverride_ && !isNodeSdk()) {\n        throw new Error('Auth override specified in options, but not supported on non Node.js platforms');\n      }\n\n      VisibilityMonitor.getInstance().on('visible', this.onVisible_, this);\n\n      if (repoInfo_.host.indexOf('fblocal') === -1) {\n        OnlineMonitor.getInstance().on('online', this.onOnline_, this);\n      }\n    }\n\n    sendRequest(action, body, onResponse) {\n      const curReqNum = ++this.requestNumber_;\n      const msg = {\n        r: curReqNum,\n        a: action,\n        b: body\n      };\n      this.log_(stringify(msg));\n      assert(this.connected_, \"sendRequest call when we're not connected not allowed.\");\n      this.realtime_.sendRequest(msg);\n\n      if (onResponse) {\n        this.requestCBHash_[curReqNum] = onResponse;\n      }\n    }\n\n    get(query) {\n      this.initConnection_();\n      const deferred = new Deferred();\n      const request = {\n        p: query._path.toString(),\n        q: query._queryObject\n      };\n      const outstandingGet = {\n        action: 'g',\n        request,\n        onComplete: message => {\n          const payload = message['d'];\n\n          if (message['s'] === 'ok') {\n            deferred.resolve(payload);\n          } else {\n            deferred.reject(payload);\n          }\n        }\n      };\n      this.outstandingGets_.push(outstandingGet);\n      this.outstandingGetCount_++;\n      const index = this.outstandingGets_.length - 1;\n\n      if (!this.connected_) {\n        setTimeout(() => {\n          const get = this.outstandingGets_[index];\n\n          if (get === undefined || outstandingGet !== get) {\n            return;\n          }\n\n          delete this.outstandingGets_[index];\n          this.outstandingGetCount_--;\n\n          if (this.outstandingGetCount_ === 0) {\n            this.outstandingGets_ = [];\n          }\n\n          this.log_('get ' + index + ' timed out on connection');\n          deferred.reject(new Error('Client is offline.'));\n        }, GET_CONNECT_TIMEOUT);\n      }\n\n      if (this.connected_) {\n        this.sendGet_(index);\n      }\n\n      return deferred.promise;\n    }\n\n    listen(query, currentHashFn, tag, onComplete) {\n      this.initConnection_();\n      const queryId = query._queryIdentifier;\n\n      const pathString = query._path.toString();\n\n      this.log_('Listen called for ' + pathString + ' ' + queryId);\n\n      if (!this.listens.has(pathString)) {\n        this.listens.set(pathString, new Map());\n      }\n\n      assert(query._queryParams.isDefault() || !query._queryParams.loadsAllData(), 'listen() called for non-default but complete query');\n      assert(!this.listens.get(pathString).has(queryId), `listen() called twice for same path/queryId.`);\n      const listenSpec = {\n        onComplete,\n        hashFn: currentHashFn,\n        query,\n        tag\n      };\n      this.listens.get(pathString).set(queryId, listenSpec);\n\n      if (this.connected_) {\n        this.sendListen_(listenSpec);\n      }\n    }\n\n    sendGet_(index) {\n      const get = this.outstandingGets_[index];\n      this.sendRequest('g', get.request, message => {\n        delete this.outstandingGets_[index];\n        this.outstandingGetCount_--;\n\n        if (this.outstandingGetCount_ === 0) {\n          this.outstandingGets_ = [];\n        }\n\n        if (get.onComplete) {\n          get.onComplete(message);\n        }\n      });\n    }\n\n    sendListen_(listenSpec) {\n      const query = listenSpec.query;\n\n      const pathString = query._path.toString();\n\n      const queryId = query._queryIdentifier;\n      this.log_('Listen on ' + pathString + ' for ' + queryId);\n      const req = {\n        /*path*/\n        p: pathString\n      };\n      const action = 'q'; // Only bother to send query if it's non-default.\n\n      if (listenSpec.tag) {\n        req['q'] = query._queryObject;\n        req['t'] = listenSpec.tag;\n      }\n\n      req[\n      /*hash*/\n      'h'] = listenSpec.hashFn();\n      this.sendRequest(action, req, message => {\n        const payload = message[\n        /*data*/\n        'd'];\n        const status = message[\n        /*status*/\n        's']; // print warnings in any case...\n\n        PersistentConnection.warnOnListenWarnings_(payload, query);\n        const currentListenSpec = this.listens.get(pathString) && this.listens.get(pathString).get(queryId); // only trigger actions if the listen hasn't been removed and readded\n\n        if (currentListenSpec === listenSpec) {\n          this.log_('listen response', message);\n\n          if (status !== 'ok') {\n            this.removeListen_(pathString, queryId);\n          }\n\n          if (listenSpec.onComplete) {\n            listenSpec.onComplete(status, payload);\n          }\n        }\n      });\n    }\n\n    static warnOnListenWarnings_(payload, query) {\n      if (payload && typeof payload === 'object' && contains(payload, 'w')) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const warnings = safeGet(payload, 'w');\n\n        if (Array.isArray(warnings) && ~warnings.indexOf('no_index')) {\n          const indexSpec = '\".indexOn\": \"' + query._queryParams.getIndex().toString() + '\"';\n\n          const indexPath = query._path.toString();\n\n          warn(`Using an unspecified index. Your data will be downloaded and ` + `filtered on the client. Consider adding ${indexSpec} at ` + `${indexPath} to your security rules for better performance.`);\n        }\n      }\n    }\n\n    refreshAuthToken(token) {\n      this.authToken_ = token;\n      this.log_('Auth token refreshed');\n\n      if (this.authToken_) {\n        this.tryAuth();\n      } else {\n        //If we're connected we want to let the server know to unauthenticate us. If we're not connected, simply delete\n        //the credential so we dont become authenticated next time we connect.\n        if (this.connected_) {\n          this.sendRequest('unauth', {}, () => {});\n        }\n      }\n\n      this.reduceReconnectDelayIfAdminCredential_(token);\n    }\n\n    reduceReconnectDelayIfAdminCredential_(credential) {\n      // NOTE: This isn't intended to be bulletproof (a malicious developer can always just modify the client).\n      // Additionally, we don't bother resetting the max delay back to the default if auth fails / expires.\n      const isFirebaseSecret = credential && credential.length === 40;\n\n      if (isFirebaseSecret || isAdmin(credential)) {\n        this.log_('Admin auth credential detected.  Reducing max reconnect time.');\n        this.maxReconnectDelay_ = RECONNECT_MAX_DELAY_FOR_ADMINS;\n      }\n    }\n\n    refreshAppCheckToken(token) {\n      this.appCheckToken_ = token;\n      this.log_('App check token refreshed');\n\n      if (this.appCheckToken_) {\n        this.tryAppCheck();\n      } else {\n        //If we're connected we want to let the server know to unauthenticate us.\n        //If we're not connected, simply delete the credential so we dont become\n        // authenticated next time we connect.\n        if (this.connected_) {\n          this.sendRequest('unappeck', {}, () => {});\n        }\n      }\n    }\n    /**\r\n     * Attempts to authenticate with the given credentials. If the authentication attempt fails, it's triggered like\r\n     * a auth revoked (the connection is closed).\r\n     */\n\n\n    tryAuth() {\n      if (this.connected_ && this.authToken_) {\n        const token = this.authToken_;\n        const authMethod = isValidFormat(token) ? 'auth' : 'gauth';\n        const requestData = {\n          cred: token\n        };\n\n        if (this.authOverride_ === null) {\n          requestData['noauth'] = true;\n        } else if (typeof this.authOverride_ === 'object') {\n          requestData['authvar'] = this.authOverride_;\n        }\n\n        this.sendRequest(authMethod, requestData, res => {\n          const status = res[\n          /*status*/\n          's'];\n          const data = res[\n          /*data*/\n          'd'] || 'error';\n\n          if (this.authToken_ === token) {\n            if (status === 'ok') {\n              this.invalidAuthTokenCount_ = 0;\n            } else {\n              // Triggers reconnect and force refresh for auth token\n              this.onAuthRevoked_(status, data);\n            }\n          }\n        });\n      }\n    }\n    /**\r\n     * Attempts to authenticate with the given token. If the authentication\r\n     * attempt fails, it's triggered like the token was revoked (the connection is\r\n     * closed).\r\n     */\n\n\n    tryAppCheck() {\n      if (this.connected_ && this.appCheckToken_) {\n        this.sendRequest('appcheck', {\n          'token': this.appCheckToken_\n        }, res => {\n          const status = res[\n          /*status*/\n          's'];\n          const data = res[\n          /*data*/\n          'd'] || 'error';\n\n          if (status === 'ok') {\n            this.invalidAppCheckTokenCount_ = 0;\n          } else {\n            this.onAppCheckRevoked_(status, data);\n          }\n        });\n      }\n    }\n    /**\r\n     * @inheritDoc\r\n     */\n\n\n    unlisten(query, tag) {\n      const pathString = query._path.toString();\n\n      const queryId = query._queryIdentifier;\n      this.log_('Unlisten called for ' + pathString + ' ' + queryId);\n      assert(query._queryParams.isDefault() || !query._queryParams.loadsAllData(), 'unlisten() called for non-default but complete query');\n      const listen = this.removeListen_(pathString, queryId);\n\n      if (listen && this.connected_) {\n        this.sendUnlisten_(pathString, queryId, query._queryObject, tag);\n      }\n    }\n\n    sendUnlisten_(pathString, queryId, queryObj, tag) {\n      this.log_('Unlisten on ' + pathString + ' for ' + queryId);\n      const req = {\n        /*path*/\n        p: pathString\n      };\n      const action = 'n'; // Only bother sending queryId if it's non-default.\n\n      if (tag) {\n        req['q'] = queryObj;\n        req['t'] = tag;\n      }\n\n      this.sendRequest(action, req);\n    }\n\n    onDisconnectPut(pathString, data, onComplete) {\n      this.initConnection_();\n\n      if (this.connected_) {\n        this.sendOnDisconnect_('o', pathString, data, onComplete);\n      } else {\n        this.onDisconnectRequestQueue_.push({\n          pathString,\n          action: 'o',\n          data,\n          onComplete\n        });\n      }\n    }\n\n    onDisconnectMerge(pathString, data, onComplete) {\n      this.initConnection_();\n\n      if (this.connected_) {\n        this.sendOnDisconnect_('om', pathString, data, onComplete);\n      } else {\n        this.onDisconnectRequestQueue_.push({\n          pathString,\n          action: 'om',\n          data,\n          onComplete\n        });\n      }\n    }\n\n    onDisconnectCancel(pathString, onComplete) {\n      this.initConnection_();\n\n      if (this.connected_) {\n        this.sendOnDisconnect_('oc', pathString, null, onComplete);\n      } else {\n        this.onDisconnectRequestQueue_.push({\n          pathString,\n          action: 'oc',\n          data: null,\n          onComplete\n        });\n      }\n    }\n\n    sendOnDisconnect_(action, pathString, data, onComplete) {\n      const request = {\n        /*path*/\n        p: pathString,\n\n        /*data*/\n        d: data\n      };\n      this.log_('onDisconnect ' + action, request);\n      this.sendRequest(action, request, response => {\n        if (onComplete) {\n          setTimeout(() => {\n            onComplete(response[\n            /*status*/\n            's'], response[\n            /* data */\n            'd']);\n          }, Math.floor(0));\n        }\n      });\n    }\n\n    put(pathString, data, onComplete, hash) {\n      this.putInternal('p', pathString, data, onComplete, hash);\n    }\n\n    merge(pathString, data, onComplete, hash) {\n      this.putInternal('m', pathString, data, onComplete, hash);\n    }\n\n    putInternal(action, pathString, data, onComplete, hash) {\n      this.initConnection_();\n      const request = {\n        /*path*/\n        p: pathString,\n\n        /*data*/\n        d: data\n      };\n\n      if (hash !== undefined) {\n        request[\n        /*hash*/\n        'h'] = hash;\n      } // TODO: Only keep track of the most recent put for a given path?\n\n\n      this.outstandingPuts_.push({\n        action,\n        request,\n        onComplete\n      });\n      this.outstandingPutCount_++;\n      const index = this.outstandingPuts_.length - 1;\n\n      if (this.connected_) {\n        this.sendPut_(index);\n      } else {\n        this.log_('Buffering put: ' + pathString);\n      }\n    }\n\n    sendPut_(index) {\n      const action = this.outstandingPuts_[index].action;\n      const request = this.outstandingPuts_[index].request;\n      const onComplete = this.outstandingPuts_[index].onComplete;\n      this.outstandingPuts_[index].queued = this.connected_;\n      this.sendRequest(action, request, message => {\n        this.log_(action + ' response', message);\n        delete this.outstandingPuts_[index];\n        this.outstandingPutCount_--; // Clean up array occasionally.\n\n        if (this.outstandingPutCount_ === 0) {\n          this.outstandingPuts_ = [];\n        }\n\n        if (onComplete) {\n          onComplete(message[\n          /*status*/\n          's'], message[\n          /* data */\n          'd']);\n        }\n      });\n    }\n\n    reportStats(stats) {\n      // If we're not connected, we just drop the stats.\n      if (this.connected_) {\n        const request = {\n          /*counters*/\n          c: stats\n        };\n        this.log_('reportStats', request);\n        this.sendRequest(\n        /*stats*/\n        's', request, result => {\n          const status = result[\n          /*status*/\n          's'];\n\n          if (status !== 'ok') {\n            const errorReason = result[\n            /* data */\n            'd'];\n            this.log_('reportStats', 'Error sending stats: ' + errorReason);\n          }\n        });\n      }\n    }\n\n    onDataMessage_(message) {\n      if ('r' in message) {\n        // this is a response\n        this.log_('from server: ' + stringify(message));\n        const reqNum = message['r'];\n        const onResponse = this.requestCBHash_[reqNum];\n\n        if (onResponse) {\n          delete this.requestCBHash_[reqNum];\n          onResponse(message[\n          /*body*/\n          'b']);\n        }\n      } else if ('error' in message) {\n        throw 'A server-side error has occurred: ' + message['error'];\n      } else if ('a' in message) {\n        // a and b are action and body, respectively\n        this.onDataPush_(message['a'], message['b']);\n      }\n    }\n\n    onDataPush_(action, body) {\n      this.log_('handleServerMessage', action, body);\n\n      if (action === 'd') {\n        this.onDataUpdate_(body[\n        /*path*/\n        'p'], body[\n        /*data*/\n        'd'],\n        /*isMerge*/\n        false, body['t']);\n      } else if (action === 'm') {\n        this.onDataUpdate_(body[\n        /*path*/\n        'p'], body[\n        /*data*/\n        'd'],\n        /*isMerge=*/\n        true, body['t']);\n      } else if (action === 'c') {\n        this.onListenRevoked_(body[\n        /*path*/\n        'p'], body[\n        /*query*/\n        'q']);\n      } else if (action === 'ac') {\n        this.onAuthRevoked_(body[\n        /*status code*/\n        's'], body[\n        /* explanation */\n        'd']);\n      } else if (action === 'apc') {\n        this.onAppCheckRevoked_(body[\n        /*status code*/\n        's'], body[\n        /* explanation */\n        'd']);\n      } else if (action === 'sd') {\n        this.onSecurityDebugPacket_(body);\n      } else {\n        error('Unrecognized action received from server: ' + stringify(action) + '\\nAre you using the latest client?');\n      }\n    }\n\n    onReady_(timestamp, sessionId) {\n      this.log_('connection ready');\n      this.connected_ = true;\n      this.lastConnectionEstablishedTime_ = new Date().getTime();\n      this.handleTimestamp_(timestamp);\n      this.lastSessionId = sessionId;\n\n      if (this.firstConnection_) {\n        this.sendConnectStats_();\n      }\n\n      this.restoreState_();\n      this.firstConnection_ = false;\n      this.onConnectStatus_(true);\n    }\n\n    scheduleConnect_(timeout) {\n      assert(!this.realtime_, \"Scheduling a connect when we're already connected/ing?\");\n\n      if (this.establishConnectionTimer_) {\n        clearTimeout(this.establishConnectionTimer_);\n      } // NOTE: Even when timeout is 0, it's important to do a setTimeout to work around an infuriating \"Security Error\" in\n      // Firefox when trying to write to our long-polling iframe in some scenarios (e.g. Forge or our unit tests).\n\n\n      this.establishConnectionTimer_ = setTimeout(() => {\n        this.establishConnectionTimer_ = null;\n        this.establishConnection_(); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      }, Math.floor(timeout));\n    }\n\n    initConnection_() {\n      if (!this.realtime_ && this.firstConnection_) {\n        this.scheduleConnect_(0);\n      }\n    }\n\n    onVisible_(visible) {\n      // NOTE: Tabbing away and back to a window will defeat our reconnect backoff, but I think that's fine.\n      if (visible && !this.visible_ && this.reconnectDelay_ === this.maxReconnectDelay_) {\n        this.log_('Window became visible.  Reducing delay.');\n        this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n\n        if (!this.realtime_) {\n          this.scheduleConnect_(0);\n        }\n      }\n\n      this.visible_ = visible;\n    }\n\n    onOnline_(online) {\n      if (online) {\n        this.log_('Browser went online.');\n        this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n\n        if (!this.realtime_) {\n          this.scheduleConnect_(0);\n        }\n      } else {\n        this.log_('Browser went offline.  Killing connection.');\n\n        if (this.realtime_) {\n          this.realtime_.close();\n        }\n      }\n    }\n\n    onRealtimeDisconnect_() {\n      this.log_('data client disconnected');\n      this.connected_ = false;\n      this.realtime_ = null; // Since we don't know if our sent transactions succeeded or not, we need to cancel them.\n\n      this.cancelSentTransactions_(); // Clear out the pending requests.\n\n      this.requestCBHash_ = {};\n\n      if (this.shouldReconnect_()) {\n        if (!this.visible_) {\n          this.log_(\"Window isn't visible.  Delaying reconnect.\");\n          this.reconnectDelay_ = this.maxReconnectDelay_;\n          this.lastConnectionAttemptTime_ = new Date().getTime();\n        } else if (this.lastConnectionEstablishedTime_) {\n          // If we've been connected long enough, reset reconnect delay to minimum.\n          const timeSinceLastConnectSucceeded = new Date().getTime() - this.lastConnectionEstablishedTime_;\n\n          if (timeSinceLastConnectSucceeded > RECONNECT_DELAY_RESET_TIMEOUT) {\n            this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n          }\n\n          this.lastConnectionEstablishedTime_ = null;\n        }\n\n        const timeSinceLastConnectAttempt = new Date().getTime() - this.lastConnectionAttemptTime_;\n        let reconnectDelay = Math.max(0, this.reconnectDelay_ - timeSinceLastConnectAttempt);\n        reconnectDelay = Math.random() * reconnectDelay;\n        this.log_('Trying to reconnect in ' + reconnectDelay + 'ms');\n        this.scheduleConnect_(reconnectDelay); // Adjust reconnect delay for next time.\n\n        this.reconnectDelay_ = Math.min(this.maxReconnectDelay_, this.reconnectDelay_ * RECONNECT_DELAY_MULTIPLIER);\n      }\n\n      this.onConnectStatus_(false);\n    }\n\n    establishConnection_() {\n      var _this = this;\n\n      return _asyncToGenerator(function* () {\n        if (_this.shouldReconnect_()) {\n          _this.log_('Making a connection attempt');\n\n          _this.lastConnectionAttemptTime_ = new Date().getTime();\n          _this.lastConnectionEstablishedTime_ = null;\n\n          const onDataMessage = _this.onDataMessage_.bind(_this);\n\n          const onReady = _this.onReady_.bind(_this);\n\n          const onDisconnect = _this.onRealtimeDisconnect_.bind(_this);\n\n          const connId = _this.id + ':' + PersistentConnection.nextConnectionId_++;\n          const lastSessionId = _this.lastSessionId;\n          let canceled = false;\n          let connection = null;\n\n          const closeFn = function () {\n            if (connection) {\n              connection.close();\n            } else {\n              canceled = true;\n              onDisconnect();\n            }\n          };\n\n          const sendRequestFn = function (msg) {\n            assert(connection, \"sendRequest call when we're not connected not allowed.\");\n            connection.sendRequest(msg);\n          };\n\n          _this.realtime_ = {\n            close: closeFn,\n            sendRequest: sendRequestFn\n          };\n          const forceRefresh = _this.forceTokenRefresh_;\n          _this.forceTokenRefresh_ = false;\n\n          try {\n            // First fetch auth and app check token, and establish connection after\n            // fetching the token was successful\n            const [authToken, appCheckToken] = yield Promise.all([_this.authTokenProvider_.getToken(forceRefresh), _this.appCheckTokenProvider_.getToken(forceRefresh)]);\n\n            if (!canceled) {\n              log('getToken() completed. Creating connection.');\n              _this.authToken_ = authToken && authToken.accessToken;\n              _this.appCheckToken_ = appCheckToken && appCheckToken.token;\n              connection = new Connection(connId, _this.repoInfo_, _this.applicationId_, _this.appCheckToken_, _this.authToken_, onDataMessage, onReady, onDisconnect,\n              /* onKill= */\n              reason => {\n                warn(reason + ' (' + _this.repoInfo_.toString() + ')');\n\n                _this.interrupt(SERVER_KILL_INTERRUPT_REASON);\n              }, lastSessionId);\n            } else {\n              log('getToken() completed but was canceled');\n            }\n          } catch (error) {\n            _this.log_('Failed to get token: ' + error);\n\n            if (!canceled) {\n              if (_this.repoInfo_.nodeAdmin) {\n                // This may be a critical error for the Admin Node.js SDK, so log a warning.\n                // But getToken() may also just have temporarily failed, so we still want to\n                // continue retrying.\n                warn(error);\n              }\n\n              closeFn();\n            }\n          }\n        }\n      })();\n    }\n\n    interrupt(reason) {\n      log('Interrupting connection for reason: ' + reason);\n      this.interruptReasons_[reason] = true;\n\n      if (this.realtime_) {\n        this.realtime_.close();\n      } else {\n        if (this.establishConnectionTimer_) {\n          clearTimeout(this.establishConnectionTimer_);\n          this.establishConnectionTimer_ = null;\n        }\n\n        if (this.connected_) {\n          this.onRealtimeDisconnect_();\n        }\n      }\n    }\n\n    resume(reason) {\n      log('Resuming connection for reason: ' + reason);\n      delete this.interruptReasons_[reason];\n\n      if (isEmpty(this.interruptReasons_)) {\n        this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n\n        if (!this.realtime_) {\n          this.scheduleConnect_(0);\n        }\n      }\n    }\n\n    handleTimestamp_(timestamp) {\n      const delta = timestamp - new Date().getTime();\n      this.onServerInfoUpdate_({\n        serverTimeOffset: delta\n      });\n    }\n\n    cancelSentTransactions_() {\n      for (let i = 0; i < this.outstandingPuts_.length; i++) {\n        const put = this.outstandingPuts_[i];\n\n        if (put &&\n        /*hash*/\n        'h' in put.request && put.queued) {\n          if (put.onComplete) {\n            put.onComplete('disconnect');\n          }\n\n          delete this.outstandingPuts_[i];\n          this.outstandingPutCount_--;\n        }\n      } // Clean up array occasionally.\n\n\n      if (this.outstandingPutCount_ === 0) {\n        this.outstandingPuts_ = [];\n      }\n    }\n\n    onListenRevoked_(pathString, query) {\n      // Remove the listen and manufacture a \"permission_denied\" error for the failed listen.\n      let queryId;\n\n      if (!query) {\n        queryId = 'default';\n      } else {\n        queryId = query.map(q => ObjectToUniqueKey(q)).join('$');\n      }\n\n      const listen = this.removeListen_(pathString, queryId);\n\n      if (listen && listen.onComplete) {\n        listen.onComplete('permission_denied');\n      }\n    }\n\n    removeListen_(pathString, queryId) {\n      const normalizedPathString = new Path(pathString).toString(); // normalize path.\n\n      let listen;\n\n      if (this.listens.has(normalizedPathString)) {\n        const map = this.listens.get(normalizedPathString);\n        listen = map.get(queryId);\n        map.delete(queryId);\n\n        if (map.size === 0) {\n          this.listens.delete(normalizedPathString);\n        }\n      } else {\n        // all listens for this path has already been removed\n        listen = undefined;\n      }\n\n      return listen;\n    }\n\n    onAuthRevoked_(statusCode, explanation) {\n      log('Auth token revoked: ' + statusCode + '/' + explanation);\n      this.authToken_ = null;\n      this.forceTokenRefresh_ = true;\n      this.realtime_.close();\n\n      if (statusCode === 'invalid_token' || statusCode === 'permission_denied') {\n        // We'll wait a couple times before logging the warning / increasing the\n        // retry period since oauth tokens will report as \"invalid\" if they're\n        // just expired. Plus there may be transient issues that resolve themselves.\n        this.invalidAuthTokenCount_++;\n\n        if (this.invalidAuthTokenCount_ >= INVALID_TOKEN_THRESHOLD) {\n          // Set a long reconnect delay because recovery is unlikely\n          this.reconnectDelay_ = RECONNECT_MAX_DELAY_FOR_ADMINS; // Notify the auth token provider that the token is invalid, which will log\n          // a warning\n\n          this.authTokenProvider_.notifyForInvalidToken();\n        }\n      }\n    }\n\n    onAppCheckRevoked_(statusCode, explanation) {\n      log('App check token revoked: ' + statusCode + '/' + explanation);\n      this.appCheckToken_ = null;\n      this.forceTokenRefresh_ = true; // Note: We don't close the connection as the developer may not have\n      // enforcement enabled. The backend closes connections with enforcements.\n\n      if (statusCode === 'invalid_token' || statusCode === 'permission_denied') {\n        // We'll wait a couple times before logging the warning / increasing the\n        // retry period since oauth tokens will report as \"invalid\" if they're\n        // just expired. Plus there may be transient issues that resolve themselves.\n        this.invalidAppCheckTokenCount_++;\n\n        if (this.invalidAppCheckTokenCount_ >= INVALID_TOKEN_THRESHOLD) {\n          this.appCheckTokenProvider_.notifyForInvalidToken();\n        }\n      }\n    }\n\n    onSecurityDebugPacket_(body) {\n      if (this.securityDebugCallback_) {\n        this.securityDebugCallback_(body);\n      } else {\n        if ('msg' in body) {\n          console.log('FIREBASE: ' + body['msg'].replace('\\n', '\\nFIREBASE: '));\n        }\n      }\n    }\n\n    restoreState_() {\n      //Re-authenticate ourselves if we have a credential stored.\n      this.tryAuth();\n      this.tryAppCheck(); // Puts depend on having received the corresponding data update from the server before they complete, so we must\n      // make sure to send listens before puts.\n\n      for (const queries of this.listens.values()) {\n        for (const listenSpec of queries.values()) {\n          this.sendListen_(listenSpec);\n        }\n      }\n\n      for (let i = 0; i < this.outstandingPuts_.length; i++) {\n        if (this.outstandingPuts_[i]) {\n          this.sendPut_(i);\n        }\n      }\n\n      while (this.onDisconnectRequestQueue_.length) {\n        const request = this.onDisconnectRequestQueue_.shift();\n        this.sendOnDisconnect_(request.action, request.pathString, request.data, request.onComplete);\n      }\n\n      for (let i = 0; i < this.outstandingGets_.length; i++) {\n        if (this.outstandingGets_[i]) {\n          this.sendGet_(i);\n        }\n      }\n    }\n    /**\r\n     * Sends client stats for first connection\r\n     */\n\n\n    sendConnectStats_() {\n      const stats = {};\n      let clientName = 'js';\n\n      if (isNodeSdk()) {\n        if (this.repoInfo_.nodeAdmin) {\n          clientName = 'admin_node';\n        } else {\n          clientName = 'node';\n        }\n      }\n\n      stats['sdk.' + clientName + '.' + SDK_VERSION.replace(/\\./g, '-')] = 1;\n\n      if (isMobileCordova()) {\n        stats['framework.cordova'] = 1;\n      } else if (isReactNative()) {\n        stats['framework.reactnative'] = 1;\n      }\n\n      this.reportStats(stats);\n    }\n\n    shouldReconnect_() {\n      const online = OnlineMonitor.getInstance().currentlyOnline();\n      return isEmpty(this.interruptReasons_) && online;\n    }\n\n  }\n\n  PersistentConnection.nextPersistentConnectionId_ = 0;\n  /**\r\n   * Counter for number of connections created. Mainly used for tagging in the logs\r\n   */\n\n  PersistentConnection.nextConnectionId_ = 0;\n  /**\r\n   * @license\r\n   * Copyright 2017 Google LLC\r\n   *\r\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   * you may not use this file except in compliance with the License.\r\n   * You may obtain a copy of the License at\r\n   *\r\n   *   http://www.apache.org/licenses/LICENSE-2.0\r\n   *\r\n   * Unless required by applicable law or agreed to in writing, software\r\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   * See the License for the specific language governing permissions and\r\n   * limitations under the License.\r\n   */\n\n  return PersistentConnection;\n})();\n\nclass NamedNode {\n  constructor(name, node) {\n    this.name = name;\n    this.node = node;\n  }\n\n  static Wrap(name, node) {\n    return new NamedNode(name, node);\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass Index {\n  /**\r\n   * @returns A standalone comparison function for\r\n   * this index\r\n   */\n  getCompare() {\n    return this.compare.bind(this);\n  }\n  /**\r\n   * Given a before and after value for a node, determine if the indexed value has changed. Even if they are different,\r\n   * it's possible that the changes are isolated to parts of the snapshot that are not indexed.\r\n   *\r\n   *\r\n   * @returns True if the portion of the snapshot being indexed changed between oldNode and newNode\r\n   */\n\n\n  indexedValueChanged(oldNode, newNode) {\n    const oldWrapped = new NamedNode(MIN_NAME, oldNode);\n    const newWrapped = new NamedNode(MIN_NAME, newNode);\n    return this.compare(oldWrapped, newWrapped) !== 0;\n  }\n  /**\r\n   * @returns a node wrapper that will sort equal to or less than\r\n   * any other node wrapper, using this index\r\n   */\n\n\n  minPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return NamedNode.MIN;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet __EMPTY_NODE;\n\nclass KeyIndex extends Index {\n  static get __EMPTY_NODE() {\n    return __EMPTY_NODE;\n  }\n\n  static set __EMPTY_NODE(val) {\n    __EMPTY_NODE = val;\n  }\n\n  compare(a, b) {\n    return nameCompare(a.name, b.name);\n  }\n\n  isDefinedOn(node) {\n    // We could probably return true here (since every node has a key), but it's never called\n    // so just leaving unimplemented for now.\n    throw assertionError('KeyIndex.isDefinedOn not expected to be called.');\n  }\n\n  indexedValueChanged(oldNode, newNode) {\n    return false; // The key for a node never changes.\n  }\n\n  minPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return NamedNode.MIN;\n  }\n\n  maxPost() {\n    // TODO: This should really be created once and cached in a static property, but\n    // NamedNode isn't defined yet, so I can't use it in a static.  Bleh.\n    return new NamedNode(MAX_NAME, __EMPTY_NODE);\n  }\n\n  makePost(indexValue, name) {\n    assert(typeof indexValue === 'string', 'KeyIndex indexValue must always be a string.'); // We just use empty node, but it'll never be compared, since our comparator only looks at name.\n\n    return new NamedNode(indexValue, __EMPTY_NODE);\n  }\n  /**\r\n   * @returns String representation for inclusion in a query spec\r\n   */\n\n\n  toString() {\n    return '.key';\n  }\n\n}\n\nconst KEY_INDEX = new KeyIndex();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An iterator over an LLRBNode.\r\n */\n\nclass SortedMapIterator {\n  /**\r\n   * @param node - Node to iterate.\r\n   * @param isReverse_ - Whether or not to iterate in reverse\r\n   */\n  constructor(node, startKey, comparator, isReverse_, resultGenerator_ = null) {\n    this.isReverse_ = isReverse_;\n    this.resultGenerator_ = resultGenerator_;\n    this.nodeStack_ = [];\n    let cmp = 1;\n\n    while (!node.isEmpty()) {\n      node = node;\n      cmp = startKey ? comparator(node.key, startKey) : 1; // flip the comparison if we're going in reverse\n\n      if (isReverse_) {\n        cmp *= -1;\n      }\n\n      if (cmp < 0) {\n        // This node is less than our start key. ignore it\n        if (this.isReverse_) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      } else if (cmp === 0) {\n        // This node is exactly equal to our start key. Push it on the stack, but stop iterating;\n        this.nodeStack_.push(node);\n        break;\n      } else {\n        // This node is greater than our start key, add it to the stack and move to the next one\n        this.nodeStack_.push(node);\n\n        if (this.isReverse_) {\n          node = node.right;\n        } else {\n          node = node.left;\n        }\n      }\n    }\n  }\n\n  getNext() {\n    if (this.nodeStack_.length === 0) {\n      return null;\n    }\n\n    let node = this.nodeStack_.pop();\n    let result;\n\n    if (this.resultGenerator_) {\n      result = this.resultGenerator_(node.key, node.value);\n    } else {\n      result = {\n        key: node.key,\n        value: node.value\n      };\n    }\n\n    if (this.isReverse_) {\n      node = node.left;\n\n      while (!node.isEmpty()) {\n        this.nodeStack_.push(node);\n        node = node.right;\n      }\n    } else {\n      node = node.right;\n\n      while (!node.isEmpty()) {\n        this.nodeStack_.push(node);\n        node = node.left;\n      }\n    }\n\n    return result;\n  }\n\n  hasNext() {\n    return this.nodeStack_.length > 0;\n  }\n\n  peek() {\n    if (this.nodeStack_.length === 0) {\n      return null;\n    }\n\n    const node = this.nodeStack_[this.nodeStack_.length - 1];\n\n    if (this.resultGenerator_) {\n      return this.resultGenerator_(node.key, node.value);\n    } else {\n      return {\n        key: node.key,\n        value: node.value\n      };\n    }\n  }\n\n}\n/**\r\n * Represents a node in a Left-leaning Red-Black tree.\r\n */\n\n\nlet LLRBNode = /*#__PURE__*/(() => {\n  class LLRBNode {\n    /**\r\n     * @param key - Key associated with this node.\r\n     * @param value - Value associated with this node.\r\n     * @param color - Whether this node is red.\r\n     * @param left - Left child.\r\n     * @param right - Right child.\r\n     */\n    constructor(key, value, color, left, right) {\n      this.key = key;\n      this.value = value;\n      this.color = color != null ? color : LLRBNode.RED;\n      this.left = left != null ? left : SortedMap.EMPTY_NODE;\n      this.right = right != null ? right : SortedMap.EMPTY_NODE;\n    }\n    /**\r\n     * Returns a copy of the current node, optionally replacing pieces of it.\r\n     *\r\n     * @param key - New key for the node, or null.\r\n     * @param value - New value for the node, or null.\r\n     * @param color - New color for the node, or null.\r\n     * @param left - New left child for the node, or null.\r\n     * @param right - New right child for the node, or null.\r\n     * @returns The node copy.\r\n     */\n\n\n    copy(key, value, color, left, right) {\n      return new LLRBNode(key != null ? key : this.key, value != null ? value : this.value, color != null ? color : this.color, left != null ? left : this.left, right != null ? right : this.right);\n    }\n    /**\r\n     * @returns The total number of nodes in the tree.\r\n     */\n\n\n    count() {\n      return this.left.count() + 1 + this.right.count();\n    }\n    /**\r\n     * @returns True if the tree is empty.\r\n     */\n\n\n    isEmpty() {\n      return false;\n    }\n    /**\r\n     * Traverses the tree in key order and calls the specified action function\r\n     * for each node.\r\n     *\r\n     * @param action - Callback function to be called for each\r\n     *   node.  If it returns true, traversal is aborted.\r\n     * @returns The first truthy value returned by action, or the last falsey\r\n     *   value returned by action\r\n     */\n\n\n    inorderTraversal(action) {\n      return this.left.inorderTraversal(action) || !!action(this.key, this.value) || this.right.inorderTraversal(action);\n    }\n    /**\r\n     * Traverses the tree in reverse key order and calls the specified action function\r\n     * for each node.\r\n     *\r\n     * @param action - Callback function to be called for each\r\n     * node.  If it returns true, traversal is aborted.\r\n     * @returns True if traversal was aborted.\r\n     */\n\n\n    reverseTraversal(action) {\n      return this.right.reverseTraversal(action) || action(this.key, this.value) || this.left.reverseTraversal(action);\n    }\n    /**\r\n     * @returns The minimum node in the tree.\r\n     */\n\n\n    min_() {\n      if (this.left.isEmpty()) {\n        return this;\n      } else {\n        return this.left.min_();\n      }\n    }\n    /**\r\n     * @returns The maximum key in the tree.\r\n     */\n\n\n    minKey() {\n      return this.min_().key;\n    }\n    /**\r\n     * @returns The maximum key in the tree.\r\n     */\n\n\n    maxKey() {\n      if (this.right.isEmpty()) {\n        return this.key;\n      } else {\n        return this.right.maxKey();\n      }\n    }\n    /**\r\n     * @param key - Key to insert.\r\n     * @param value - Value to insert.\r\n     * @param comparator - Comparator.\r\n     * @returns New tree, with the key/value added.\r\n     */\n\n\n    insert(key, value, comparator) {\n      let n = this;\n      const cmp = comparator(key, n.key);\n\n      if (cmp < 0) {\n        n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\n      } else if (cmp === 0) {\n        n = n.copy(null, value, null, null, null);\n      } else {\n        n = n.copy(null, null, null, null, n.right.insert(key, value, comparator));\n      }\n\n      return n.fixUp_();\n    }\n    /**\r\n     * @returns New tree, with the minimum key removed.\r\n     */\n\n\n    removeMin_() {\n      if (this.left.isEmpty()) {\n        return SortedMap.EMPTY_NODE;\n      }\n\n      let n = this;\n\n      if (!n.left.isRed_() && !n.left.left.isRed_()) {\n        n = n.moveRedLeft_();\n      }\n\n      n = n.copy(null, null, null, n.left.removeMin_(), null);\n      return n.fixUp_();\n    }\n    /**\r\n     * @param key - The key of the item to remove.\r\n     * @param comparator - Comparator.\r\n     * @returns New tree, with the specified item removed.\r\n     */\n\n\n    remove(key, comparator) {\n      let n, smallest;\n      n = this;\n\n      if (comparator(key, n.key) < 0) {\n        if (!n.left.isEmpty() && !n.left.isRed_() && !n.left.left.isRed_()) {\n          n = n.moveRedLeft_();\n        }\n\n        n = n.copy(null, null, null, n.left.remove(key, comparator), null);\n      } else {\n        if (n.left.isRed_()) {\n          n = n.rotateRight_();\n        }\n\n        if (!n.right.isEmpty() && !n.right.isRed_() && !n.right.left.isRed_()) {\n          n = n.moveRedRight_();\n        }\n\n        if (comparator(key, n.key) === 0) {\n          if (n.right.isEmpty()) {\n            return SortedMap.EMPTY_NODE;\n          } else {\n            smallest = n.right.min_();\n            n = n.copy(smallest.key, smallest.value, null, null, n.right.removeMin_());\n          }\n        }\n\n        n = n.copy(null, null, null, null, n.right.remove(key, comparator));\n      }\n\n      return n.fixUp_();\n    }\n    /**\r\n     * @returns Whether this is a RED node.\r\n     */\n\n\n    isRed_() {\n      return this.color;\n    }\n    /**\r\n     * @returns New tree after performing any needed rotations.\r\n     */\n\n\n    fixUp_() {\n      let n = this;\n\n      if (n.right.isRed_() && !n.left.isRed_()) {\n        n = n.rotateLeft_();\n      }\n\n      if (n.left.isRed_() && n.left.left.isRed_()) {\n        n = n.rotateRight_();\n      }\n\n      if (n.left.isRed_() && n.right.isRed_()) {\n        n = n.colorFlip_();\n      }\n\n      return n;\n    }\n    /**\r\n     * @returns New tree, after moveRedLeft.\r\n     */\n\n\n    moveRedLeft_() {\n      let n = this.colorFlip_();\n\n      if (n.right.left.isRed_()) {\n        n = n.copy(null, null, null, null, n.right.rotateRight_());\n        n = n.rotateLeft_();\n        n = n.colorFlip_();\n      }\n\n      return n;\n    }\n    /**\r\n     * @returns New tree, after moveRedRight.\r\n     */\n\n\n    moveRedRight_() {\n      let n = this.colorFlip_();\n\n      if (n.left.left.isRed_()) {\n        n = n.rotateRight_();\n        n = n.colorFlip_();\n      }\n\n      return n;\n    }\n    /**\r\n     * @returns New tree, after rotateLeft.\r\n     */\n\n\n    rotateLeft_() {\n      const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\n      return this.right.copy(null, null, this.color, nl, null);\n    }\n    /**\r\n     * @returns New tree, after rotateRight.\r\n     */\n\n\n    rotateRight_() {\n      const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\n      return this.left.copy(null, null, this.color, null, nr);\n    }\n    /**\r\n     * @returns Newt ree, after colorFlip.\r\n     */\n\n\n    colorFlip_() {\n      const left = this.left.copy(null, null, !this.left.color, null, null);\n      const right = this.right.copy(null, null, !this.right.color, null, null);\n      return this.copy(null, null, !this.color, left, right);\n    }\n    /**\r\n     * For testing.\r\n     *\r\n     * @returns True if all is well.\r\n     */\n\n\n    checkMaxDepth_() {\n      const blackDepth = this.check_();\n      return Math.pow(2.0, blackDepth) <= this.count() + 1;\n    }\n\n    check_() {\n      if (this.isRed_() && this.left.isRed_()) {\n        throw new Error('Red node has red child(' + this.key + ',' + this.value + ')');\n      }\n\n      if (this.right.isRed_()) {\n        throw new Error('Right child of (' + this.key + ',' + this.value + ') is red');\n      }\n\n      const blackDepth = this.left.check_();\n\n      if (blackDepth !== this.right.check_()) {\n        throw new Error('Black depths differ');\n      } else {\n        return blackDepth + (this.isRed_() ? 0 : 1);\n      }\n    }\n\n  }\n\n  LLRBNode.RED = true;\n  LLRBNode.BLACK = false;\n  /**\r\n   * Represents an empty node (a leaf node in the Red-Black Tree).\r\n   */\n\n  return LLRBNode;\n})();\n\nclass LLRBEmptyNode {\n  /**\r\n   * Returns a copy of the current node.\r\n   *\r\n   * @returns The node copy.\r\n   */\n  copy(key, value, color, left, right) {\n    return this;\n  }\n  /**\r\n   * Returns a copy of the tree, with the specified key/value added.\r\n   *\r\n   * @param key - Key to be added.\r\n   * @param value - Value to be added.\r\n   * @param comparator - Comparator.\r\n   * @returns New tree, with item added.\r\n   */\n\n\n  insert(key, value, comparator) {\n    return new LLRBNode(key, value, null);\n  }\n  /**\r\n   * Returns a copy of the tree, with the specified key removed.\r\n   *\r\n   * @param key - The key to remove.\r\n   * @param comparator - Comparator.\r\n   * @returns New tree, with item removed.\r\n   */\n\n\n  remove(key, comparator) {\n    return this;\n  }\n  /**\r\n   * @returns The total number of nodes in the tree.\r\n   */\n\n\n  count() {\n    return 0;\n  }\n  /**\r\n   * @returns True if the tree is empty.\r\n   */\n\n\n  isEmpty() {\n    return true;\n  }\n  /**\r\n   * Traverses the tree in key order and calls the specified action function\r\n   * for each node.\r\n   *\r\n   * @param action - Callback function to be called for each\r\n   * node.  If it returns true, traversal is aborted.\r\n   * @returns True if traversal was aborted.\r\n   */\n\n\n  inorderTraversal(action) {\n    return false;\n  }\n  /**\r\n   * Traverses the tree in reverse key order and calls the specified action function\r\n   * for each node.\r\n   *\r\n   * @param action - Callback function to be called for each\r\n   * node.  If it returns true, traversal is aborted.\r\n   * @returns True if traversal was aborted.\r\n   */\n\n\n  reverseTraversal(action) {\n    return false;\n  }\n\n  minKey() {\n    return null;\n  }\n\n  maxKey() {\n    return null;\n  }\n\n  check_() {\n    return 0;\n  }\n  /**\r\n   * @returns Whether this node is red.\r\n   */\n\n\n  isRed_() {\n    return false;\n  }\n\n}\n/**\r\n * An immutable sorted map implementation, based on a Left-leaning Red-Black\r\n * tree.\r\n */\n\n\nclass SortedMap {\n  /**\r\n   * @param comparator_ - Key comparator.\r\n   * @param root_ - Optional root node for the map.\r\n   */\n  constructor(comparator_, root_ = SortedMap.EMPTY_NODE) {\n    this.comparator_ = comparator_;\n    this.root_ = root_;\n  }\n  /**\r\n   * Returns a copy of the map, with the specified key/value added or replaced.\r\n   * (TODO: We should perhaps rename this method to 'put')\r\n   *\r\n   * @param key - Key to be added.\r\n   * @param value - Value to be added.\r\n   * @returns New map, with item added.\r\n   */\n\n\n  insert(key, value) {\n    return new SortedMap(this.comparator_, this.root_.insert(key, value, this.comparator_).copy(null, null, LLRBNode.BLACK, null, null));\n  }\n  /**\r\n   * Returns a copy of the map, with the specified key removed.\r\n   *\r\n   * @param key - The key to remove.\r\n   * @returns New map, with item removed.\r\n   */\n\n\n  remove(key) {\n    return new SortedMap(this.comparator_, this.root_.remove(key, this.comparator_).copy(null, null, LLRBNode.BLACK, null, null));\n  }\n  /**\r\n   * Returns the value of the node with the given key, or null.\r\n   *\r\n   * @param key - The key to look up.\r\n   * @returns The value of the node with the given key, or null if the\r\n   * key doesn't exist.\r\n   */\n\n\n  get(key) {\n    let cmp;\n    let node = this.root_;\n\n    while (!node.isEmpty()) {\n      cmp = this.comparator_(key, node.key);\n\n      if (cmp === 0) {\n        return node.value;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        node = node.right;\n      }\n    }\n\n    return null;\n  }\n  /**\r\n   * Returns the key of the item *before* the specified key, or null if key is the first item.\r\n   * @param key - The key to find the predecessor of\r\n   * @returns The predecessor key.\r\n   */\n\n\n  getPredecessorKey(key) {\n    let cmp,\n        node = this.root_,\n        rightParent = null;\n\n    while (!node.isEmpty()) {\n      cmp = this.comparator_(key, node.key);\n\n      if (cmp === 0) {\n        if (!node.left.isEmpty()) {\n          node = node.left;\n\n          while (!node.right.isEmpty()) {\n            node = node.right;\n          }\n\n          return node.key;\n        } else if (rightParent) {\n          return rightParent.key;\n        } else {\n          return null; // first item.\n        }\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        rightParent = node;\n        node = node.right;\n      }\n    }\n\n    throw new Error('Attempted to find predecessor key for a nonexistent key.  What gives?');\n  }\n  /**\r\n   * @returns True if the map is empty.\r\n   */\n\n\n  isEmpty() {\n    return this.root_.isEmpty();\n  }\n  /**\r\n   * @returns The total number of nodes in the map.\r\n   */\n\n\n  count() {\n    return this.root_.count();\n  }\n  /**\r\n   * @returns The minimum key in the map.\r\n   */\n\n\n  minKey() {\n    return this.root_.minKey();\n  }\n  /**\r\n   * @returns The maximum key in the map.\r\n   */\n\n\n  maxKey() {\n    return this.root_.maxKey();\n  }\n  /**\r\n   * Traverses the map in key order and calls the specified action function\r\n   * for each key/value pair.\r\n   *\r\n   * @param action - Callback function to be called\r\n   * for each key/value pair.  If action returns true, traversal is aborted.\r\n   * @returns The first truthy value returned by action, or the last falsey\r\n   *   value returned by action\r\n   */\n\n\n  inorderTraversal(action) {\n    return this.root_.inorderTraversal(action);\n  }\n  /**\r\n   * Traverses the map in reverse key order and calls the specified action function\r\n   * for each key/value pair.\r\n   *\r\n   * @param action - Callback function to be called\r\n   * for each key/value pair.  If action returns true, traversal is aborted.\r\n   * @returns True if the traversal was aborted.\r\n   */\n\n\n  reverseTraversal(action) {\n    return this.root_.reverseTraversal(action);\n  }\n  /**\r\n   * Returns an iterator over the SortedMap.\r\n   * @returns The iterator.\r\n   */\n\n\n  getIterator(resultGenerator) {\n    return new SortedMapIterator(this.root_, null, this.comparator_, false, resultGenerator);\n  }\n\n  getIteratorFrom(key, resultGenerator) {\n    return new SortedMapIterator(this.root_, key, this.comparator_, false, resultGenerator);\n  }\n\n  getReverseIteratorFrom(key, resultGenerator) {\n    return new SortedMapIterator(this.root_, key, this.comparator_, true, resultGenerator);\n  }\n\n  getReverseIterator(resultGenerator) {\n    return new SortedMapIterator(this.root_, null, this.comparator_, true, resultGenerator);\n  }\n\n}\n/**\r\n * Always use the same empty node, to reduce memory.\r\n */\n\n\nSortedMap.EMPTY_NODE = new LLRBEmptyNode();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nfunction NAME_ONLY_COMPARATOR(left, right) {\n  return nameCompare(left.name, right.name);\n}\n\nfunction NAME_COMPARATOR(left, right) {\n  return nameCompare(left, right);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet MAX_NODE$2;\n\nfunction setMaxNode$1(val) {\n  MAX_NODE$2 = val;\n}\n\nconst priorityHashText = function (priority) {\n  if (typeof priority === 'number') {\n    return 'number:' + doubleToIEEE754String(priority);\n  } else {\n    return 'string:' + priority;\n  }\n};\n/**\r\n * Validates that a priority snapshot Node is valid.\r\n */\n\n\nconst validatePriorityNode = function (priorityNode) {\n  if (priorityNode.isLeafNode()) {\n    const val = priorityNode.val();\n    assert(typeof val === 'string' || typeof val === 'number' || typeof val === 'object' && contains(val, '.sv'), 'Priority must be a string or number.');\n  } else {\n    assert(priorityNode === MAX_NODE$2 || priorityNode.isEmpty(), 'priority of unexpected type.');\n  } // Don't call getPriority() on MAX_NODE to avoid hitting assertion.\n\n\n  assert(priorityNode === MAX_NODE$2 || priorityNode.getPriority().isEmpty(), \"Priority nodes can't have a priority of their own.\");\n};\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet __childrenNodeConstructor;\n/**\r\n * LeafNode is a class for storing leaf nodes in a DataSnapshot.  It\r\n * implements Node and stores the value of the node (a string,\r\n * number, or boolean) accessible via getValue().\r\n */\n\n\nlet LeafNode = /*#__PURE__*/(() => {\n  class LeafNode {\n    /**\r\n     * @param value_ - The value to store in this leaf node. The object type is\r\n     * possible in the event of a deferred value\r\n     * @param priorityNode_ - The priority of this node.\r\n     */\n    constructor(value_, priorityNode_ = LeafNode.__childrenNodeConstructor.EMPTY_NODE) {\n      this.value_ = value_;\n      this.priorityNode_ = priorityNode_;\n      this.lazyHash_ = null;\n      assert(this.value_ !== undefined && this.value_ !== null, \"LeafNode shouldn't be created with null/undefined value.\");\n      validatePriorityNode(this.priorityNode_);\n    }\n\n    static set __childrenNodeConstructor(val) {\n      __childrenNodeConstructor = val;\n    }\n\n    static get __childrenNodeConstructor() {\n      return __childrenNodeConstructor;\n    }\n    /** @inheritDoc */\n\n\n    isLeafNode() {\n      return true;\n    }\n    /** @inheritDoc */\n\n\n    getPriority() {\n      return this.priorityNode_;\n    }\n    /** @inheritDoc */\n\n\n    updatePriority(newPriorityNode) {\n      return new LeafNode(this.value_, newPriorityNode);\n    }\n    /** @inheritDoc */\n\n\n    getImmediateChild(childName) {\n      // Hack to treat priority as a regular child\n      if (childName === '.priority') {\n        return this.priorityNode_;\n      } else {\n        return LeafNode.__childrenNodeConstructor.EMPTY_NODE;\n      }\n    }\n    /** @inheritDoc */\n\n\n    getChild(path) {\n      if (pathIsEmpty(path)) {\n        return this;\n      } else if (pathGetFront(path) === '.priority') {\n        return this.priorityNode_;\n      } else {\n        return LeafNode.__childrenNodeConstructor.EMPTY_NODE;\n      }\n    }\n\n    hasChild() {\n      return false;\n    }\n    /** @inheritDoc */\n\n\n    getPredecessorChildName(childName, childNode) {\n      return null;\n    }\n    /** @inheritDoc */\n\n\n    updateImmediateChild(childName, newChildNode) {\n      if (childName === '.priority') {\n        return this.updatePriority(newChildNode);\n      } else if (newChildNode.isEmpty() && childName !== '.priority') {\n        return this;\n      } else {\n        return LeafNode.__childrenNodeConstructor.EMPTY_NODE.updateImmediateChild(childName, newChildNode).updatePriority(this.priorityNode_);\n      }\n    }\n    /** @inheritDoc */\n\n\n    updateChild(path, newChildNode) {\n      const front = pathGetFront(path);\n\n      if (front === null) {\n        return newChildNode;\n      } else if (newChildNode.isEmpty() && front !== '.priority') {\n        return this;\n      } else {\n        assert(front !== '.priority' || pathGetLength(path) === 1, '.priority must be the last token in a path');\n        return this.updateImmediateChild(front, LeafNode.__childrenNodeConstructor.EMPTY_NODE.updateChild(pathPopFront(path), newChildNode));\n      }\n    }\n    /** @inheritDoc */\n\n\n    isEmpty() {\n      return false;\n    }\n    /** @inheritDoc */\n\n\n    numChildren() {\n      return 0;\n    }\n    /** @inheritDoc */\n\n\n    forEachChild(index, action) {\n      return false;\n    }\n\n    val(exportFormat) {\n      if (exportFormat && !this.getPriority().isEmpty()) {\n        return {\n          '.value': this.getValue(),\n          '.priority': this.getPriority().val()\n        };\n      } else {\n        return this.getValue();\n      }\n    }\n    /** @inheritDoc */\n\n\n    hash() {\n      if (this.lazyHash_ === null) {\n        let toHash = '';\n\n        if (!this.priorityNode_.isEmpty()) {\n          toHash += 'priority:' + priorityHashText(this.priorityNode_.val()) + ':';\n        }\n\n        const type = typeof this.value_;\n        toHash += type + ':';\n\n        if (type === 'number') {\n          toHash += doubleToIEEE754String(this.value_);\n        } else {\n          toHash += this.value_;\n        }\n\n        this.lazyHash_ = sha1(toHash);\n      }\n\n      return this.lazyHash_;\n    }\n    /**\r\n     * Returns the value of the leaf node.\r\n     * @returns The value of the node.\r\n     */\n\n\n    getValue() {\n      return this.value_;\n    }\n\n    compareTo(other) {\n      if (other === LeafNode.__childrenNodeConstructor.EMPTY_NODE) {\n        return 1;\n      } else if (other instanceof LeafNode.__childrenNodeConstructor) {\n        return -1;\n      } else {\n        assert(other.isLeafNode(), 'Unknown node type');\n        return this.compareToLeafNode_(other);\n      }\n    }\n    /**\r\n     * Comparison specifically for two leaf nodes\r\n     */\n\n\n    compareToLeafNode_(otherLeaf) {\n      const otherLeafType = typeof otherLeaf.value_;\n      const thisLeafType = typeof this.value_;\n      const otherIndex = LeafNode.VALUE_TYPE_ORDER.indexOf(otherLeafType);\n      const thisIndex = LeafNode.VALUE_TYPE_ORDER.indexOf(thisLeafType);\n      assert(otherIndex >= 0, 'Unknown leaf type: ' + otherLeafType);\n      assert(thisIndex >= 0, 'Unknown leaf type: ' + thisLeafType);\n\n      if (otherIndex === thisIndex) {\n        // Same type, compare values\n        if (thisLeafType === 'object') {\n          // Deferred value nodes are all equal, but we should also never get to this point...\n          return 0;\n        } else {\n          // Note that this works because true > false, all others are number or string comparisons\n          if (this.value_ < otherLeaf.value_) {\n            return -1;\n          } else if (this.value_ === otherLeaf.value_) {\n            return 0;\n          } else {\n            return 1;\n          }\n        }\n      } else {\n        return thisIndex - otherIndex;\n      }\n    }\n\n    withIndex() {\n      return this;\n    }\n\n    isIndexed() {\n      return true;\n    }\n\n    equals(other) {\n      if (other === this) {\n        return true;\n      } else if (other.isLeafNode()) {\n        const otherLeaf = other;\n        return this.value_ === otherLeaf.value_ && this.priorityNode_.equals(otherLeaf.priorityNode_);\n      } else {\n        return false;\n      }\n    }\n\n  }\n\n  /**\r\n   * The sort order for comparing leaf nodes of different types. If two leaf nodes have\r\n   * the same type, the comparison falls back to their value\r\n   */\n  LeafNode.VALUE_TYPE_ORDER = ['object', 'boolean', 'number', 'string'];\n  /**\r\n   * @license\r\n   * Copyright 2017 Google LLC\r\n   *\r\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   * you may not use this file except in compliance with the License.\r\n   * You may obtain a copy of the License at\r\n   *\r\n   *   http://www.apache.org/licenses/LICENSE-2.0\r\n   *\r\n   * Unless required by applicable law or agreed to in writing, software\r\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   * See the License for the specific language governing permissions and\r\n   * limitations under the License.\r\n   */\n\n  return LeafNode;\n})();\nlet nodeFromJSON$1;\nlet MAX_NODE$1;\n\nfunction setNodeFromJSON(val) {\n  nodeFromJSON$1 = val;\n}\n\nfunction setMaxNode(val) {\n  MAX_NODE$1 = val;\n}\n\nclass PriorityIndex extends Index {\n  compare(a, b) {\n    const aPriority = a.node.getPriority();\n    const bPriority = b.node.getPriority();\n    const indexCmp = aPriority.compareTo(bPriority);\n\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n\n  isDefinedOn(node) {\n    return !node.getPriority().isEmpty();\n  }\n\n  indexedValueChanged(oldNode, newNode) {\n    return !oldNode.getPriority().equals(newNode.getPriority());\n  }\n\n  minPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return NamedNode.MIN;\n  }\n\n  maxPost() {\n    return new NamedNode(MAX_NAME, new LeafNode('[PRIORITY-POST]', MAX_NODE$1));\n  }\n\n  makePost(indexValue, name) {\n    const priorityNode = nodeFromJSON$1(indexValue);\n    return new NamedNode(name, new LeafNode('[PRIORITY-POST]', priorityNode));\n  }\n  /**\r\n   * @returns String representation for inclusion in a query spec\r\n   */\n\n\n  toString() {\n    return '.priority';\n  }\n\n}\n\nconst PRIORITY_INDEX = new PriorityIndex();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nconst LOG_2 = Math.log(2);\n\nclass Base12Num {\n  constructor(length) {\n    const logBase2 = num => // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    parseInt(Math.log(num) / LOG_2, 10);\n\n    const bitMask = bits => parseInt(Array(bits + 1).join('1'), 2);\n\n    this.count = logBase2(length + 1);\n    this.current_ = this.count - 1;\n    const mask = bitMask(this.count);\n    this.bits_ = length + 1 & mask;\n  }\n\n  nextBitIsOne() {\n    //noinspection JSBitwiseOperatorUsage\n    const result = !(this.bits_ & 0x1 << this.current_);\n    this.current_--;\n    return result;\n  }\n\n}\n/**\r\n * Takes a list of child nodes and constructs a SortedSet using the given comparison\r\n * function\r\n *\r\n * Uses the algorithm described in the paper linked here:\r\n * http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.1458\r\n *\r\n * @param childList - Unsorted list of children\r\n * @param cmp - The comparison method to be used\r\n * @param keyFn - An optional function to extract K from a node wrapper, if K's\r\n * type is not NamedNode\r\n * @param mapSortFn - An optional override for comparator used by the generated sorted map\r\n */\n\n\nconst buildChildSet = function (childList, cmp, keyFn, mapSortFn) {\n  childList.sort(cmp);\n\n  const buildBalancedTree = function (low, high) {\n    const length = high - low;\n    let namedNode;\n    let key;\n\n    if (length === 0) {\n      return null;\n    } else if (length === 1) {\n      namedNode = childList[low];\n      key = keyFn ? keyFn(namedNode) : namedNode;\n      return new LLRBNode(key, namedNode.node, LLRBNode.BLACK, null, null);\n    } else {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const middle = parseInt(length / 2, 10) + low;\n      const left = buildBalancedTree(low, middle);\n      const right = buildBalancedTree(middle + 1, high);\n      namedNode = childList[middle];\n      key = keyFn ? keyFn(namedNode) : namedNode;\n      return new LLRBNode(key, namedNode.node, LLRBNode.BLACK, left, right);\n    }\n  };\n\n  const buildFrom12Array = function (base12) {\n    let node = null;\n    let root = null;\n    let index = childList.length;\n\n    const buildPennant = function (chunkSize, color) {\n      const low = index - chunkSize;\n      const high = index;\n      index -= chunkSize;\n      const childTree = buildBalancedTree(low + 1, high);\n      const namedNode = childList[low];\n      const key = keyFn ? keyFn(namedNode) : namedNode;\n      attachPennant(new LLRBNode(key, namedNode.node, color, null, childTree));\n    };\n\n    const attachPennant = function (pennant) {\n      if (node) {\n        node.left = pennant;\n        node = pennant;\n      } else {\n        root = pennant;\n        node = pennant;\n      }\n    };\n\n    for (let i = 0; i < base12.count; ++i) {\n      const isOne = base12.nextBitIsOne(); // The number of nodes taken in each slice is 2^(arr.length - (i + 1))\n\n      const chunkSize = Math.pow(2, base12.count - (i + 1));\n\n      if (isOne) {\n        buildPennant(chunkSize, LLRBNode.BLACK);\n      } else {\n        // current == 2\n        buildPennant(chunkSize, LLRBNode.BLACK);\n        buildPennant(chunkSize, LLRBNode.RED);\n      }\n    }\n\n    return root;\n  };\n\n  const base12 = new Base12Num(childList.length);\n  const root = buildFrom12Array(base12); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n  return new SortedMap(mapSortFn || cmp, root);\n};\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet _defaultIndexMap;\n\nconst fallbackObject = {};\n\nclass IndexMap {\n  constructor(indexes_, indexSet_) {\n    this.indexes_ = indexes_;\n    this.indexSet_ = indexSet_;\n  }\n  /**\r\n   * The default IndexMap for nodes without a priority\r\n   */\n\n\n  static get Default() {\n    assert(fallbackObject && PRIORITY_INDEX, 'ChildrenNode.ts has not been loaded');\n    _defaultIndexMap = _defaultIndexMap || new IndexMap({\n      '.priority': fallbackObject\n    }, {\n      '.priority': PRIORITY_INDEX\n    });\n    return _defaultIndexMap;\n  }\n\n  get(indexKey) {\n    const sortedMap = safeGet(this.indexes_, indexKey);\n\n    if (!sortedMap) {\n      throw new Error('No index defined for ' + indexKey);\n    }\n\n    if (sortedMap instanceof SortedMap) {\n      return sortedMap;\n    } else {\n      // The index exists, but it falls back to just name comparison. Return null so that the calling code uses the\n      // regular child map\n      return null;\n    }\n  }\n\n  hasIndex(indexDefinition) {\n    return contains(this.indexSet_, indexDefinition.toString());\n  }\n\n  addIndex(indexDefinition, existingChildren) {\n    assert(indexDefinition !== KEY_INDEX, \"KeyIndex always exists and isn't meant to be added to the IndexMap.\");\n    const childList = [];\n    let sawIndexedValue = false;\n    const iter = existingChildren.getIterator(NamedNode.Wrap);\n    let next = iter.getNext();\n\n    while (next) {\n      sawIndexedValue = sawIndexedValue || indexDefinition.isDefinedOn(next.node);\n      childList.push(next);\n      next = iter.getNext();\n    }\n\n    let newIndex;\n\n    if (sawIndexedValue) {\n      newIndex = buildChildSet(childList, indexDefinition.getCompare());\n    } else {\n      newIndex = fallbackObject;\n    }\n\n    const indexName = indexDefinition.toString();\n    const newIndexSet = Object.assign({}, this.indexSet_);\n    newIndexSet[indexName] = indexDefinition;\n    const newIndexes = Object.assign({}, this.indexes_);\n    newIndexes[indexName] = newIndex;\n    return new IndexMap(newIndexes, newIndexSet);\n  }\n  /**\r\n   * Ensure that this node is properly tracked in any indexes that we're maintaining\r\n   */\n\n\n  addToIndexes(namedNode, existingChildren) {\n    const newIndexes = map(this.indexes_, (indexedChildren, indexName) => {\n      const index = safeGet(this.indexSet_, indexName);\n      assert(index, 'Missing index implementation for ' + indexName);\n\n      if (indexedChildren === fallbackObject) {\n        // Check to see if we need to index everything\n        if (index.isDefinedOn(namedNode.node)) {\n          // We need to build this index\n          const childList = [];\n          const iter = existingChildren.getIterator(NamedNode.Wrap);\n          let next = iter.getNext();\n\n          while (next) {\n            if (next.name !== namedNode.name) {\n              childList.push(next);\n            }\n\n            next = iter.getNext();\n          }\n\n          childList.push(namedNode);\n          return buildChildSet(childList, index.getCompare());\n        } else {\n          // No change, this remains a fallback\n          return fallbackObject;\n        }\n      } else {\n        const existingSnap = existingChildren.get(namedNode.name);\n        let newChildren = indexedChildren;\n\n        if (existingSnap) {\n          newChildren = newChildren.remove(new NamedNode(namedNode.name, existingSnap));\n        }\n\n        return newChildren.insert(namedNode, namedNode.node);\n      }\n    });\n    return new IndexMap(newIndexes, this.indexSet_);\n  }\n  /**\r\n   * Create a new IndexMap instance with the given value removed\r\n   */\n\n\n  removeFromIndexes(namedNode, existingChildren) {\n    const newIndexes = map(this.indexes_, indexedChildren => {\n      if (indexedChildren === fallbackObject) {\n        // This is the fallback. Just return it, nothing to do in this case\n        return indexedChildren;\n      } else {\n        const existingSnap = existingChildren.get(namedNode.name);\n\n        if (existingSnap) {\n          return indexedChildren.remove(new NamedNode(namedNode.name, existingSnap));\n        } else {\n          // No record of this child\n          return indexedChildren;\n        }\n      }\n    });\n    return new IndexMap(newIndexes, this.indexSet_);\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// TODO: For memory savings, don't store priorityNode_ if it's empty.\n\n\nlet EMPTY_NODE;\n/**\r\n * ChildrenNode is a class for storing internal nodes in a DataSnapshot\r\n * (i.e. nodes with children).  It implements Node and stores the\r\n * list of children in the children property, sorted by child name.\r\n */\n\nlet ChildrenNode = /*#__PURE__*/(() => {\n  class ChildrenNode {\n    /**\r\n     * @param children_ - List of children of this node..\r\n     * @param priorityNode_ - The priority of this node (as a snapshot node).\r\n     */\n    constructor(children_, priorityNode_, indexMap_) {\n      this.children_ = children_;\n      this.priorityNode_ = priorityNode_;\n      this.indexMap_ = indexMap_;\n      this.lazyHash_ = null;\n      /**\r\n       * Note: The only reason we allow null priority is for EMPTY_NODE, since we can't use\r\n       * EMPTY_NODE as the priority of EMPTY_NODE.  We might want to consider making EMPTY_NODE its own\r\n       * class instead of an empty ChildrenNode.\r\n       */\n\n      if (this.priorityNode_) {\n        validatePriorityNode(this.priorityNode_);\n      }\n\n      if (this.children_.isEmpty()) {\n        assert(!this.priorityNode_ || this.priorityNode_.isEmpty(), 'An empty node cannot have a priority');\n      }\n    }\n\n    static get EMPTY_NODE() {\n      return EMPTY_NODE || (EMPTY_NODE = new ChildrenNode(new SortedMap(NAME_COMPARATOR), null, IndexMap.Default));\n    }\n    /** @inheritDoc */\n\n\n    isLeafNode() {\n      return false;\n    }\n    /** @inheritDoc */\n\n\n    getPriority() {\n      return this.priorityNode_ || EMPTY_NODE;\n    }\n    /** @inheritDoc */\n\n\n    updatePriority(newPriorityNode) {\n      if (this.children_.isEmpty()) {\n        // Don't allow priorities on empty nodes\n        return this;\n      } else {\n        return new ChildrenNode(this.children_, newPriorityNode, this.indexMap_);\n      }\n    }\n    /** @inheritDoc */\n\n\n    getImmediateChild(childName) {\n      // Hack to treat priority as a regular child\n      if (childName === '.priority') {\n        return this.getPriority();\n      } else {\n        const child = this.children_.get(childName);\n        return child === null ? EMPTY_NODE : child;\n      }\n    }\n    /** @inheritDoc */\n\n\n    getChild(path) {\n      const front = pathGetFront(path);\n\n      if (front === null) {\n        return this;\n      }\n\n      return this.getImmediateChild(front).getChild(pathPopFront(path));\n    }\n    /** @inheritDoc */\n\n\n    hasChild(childName) {\n      return this.children_.get(childName) !== null;\n    }\n    /** @inheritDoc */\n\n\n    updateImmediateChild(childName, newChildNode) {\n      assert(newChildNode, 'We should always be passing snapshot nodes');\n\n      if (childName === '.priority') {\n        return this.updatePriority(newChildNode);\n      } else {\n        const namedNode = new NamedNode(childName, newChildNode);\n        let newChildren, newIndexMap;\n\n        if (newChildNode.isEmpty()) {\n          newChildren = this.children_.remove(childName);\n          newIndexMap = this.indexMap_.removeFromIndexes(namedNode, this.children_);\n        } else {\n          newChildren = this.children_.insert(childName, newChildNode);\n          newIndexMap = this.indexMap_.addToIndexes(namedNode, this.children_);\n        }\n\n        const newPriority = newChildren.isEmpty() ? EMPTY_NODE : this.priorityNode_;\n        return new ChildrenNode(newChildren, newPriority, newIndexMap);\n      }\n    }\n    /** @inheritDoc */\n\n\n    updateChild(path, newChildNode) {\n      const front = pathGetFront(path);\n\n      if (front === null) {\n        return newChildNode;\n      } else {\n        assert(pathGetFront(path) !== '.priority' || pathGetLength(path) === 1, '.priority must be the last token in a path');\n        const newImmediateChild = this.getImmediateChild(front).updateChild(pathPopFront(path), newChildNode);\n        return this.updateImmediateChild(front, newImmediateChild);\n      }\n    }\n    /** @inheritDoc */\n\n\n    isEmpty() {\n      return this.children_.isEmpty();\n    }\n    /** @inheritDoc */\n\n\n    numChildren() {\n      return this.children_.count();\n    }\n    /** @inheritDoc */\n\n\n    val(exportFormat) {\n      if (this.isEmpty()) {\n        return null;\n      }\n\n      const obj = {};\n      let numKeys = 0,\n          maxKey = 0,\n          allIntegerKeys = true;\n      this.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n        obj[key] = childNode.val(exportFormat);\n        numKeys++;\n\n        if (allIntegerKeys && ChildrenNode.INTEGER_REGEXP_.test(key)) {\n          maxKey = Math.max(maxKey, Number(key));\n        } else {\n          allIntegerKeys = false;\n        }\n      });\n\n      if (!exportFormat && allIntegerKeys && maxKey < 2 * numKeys) {\n        // convert to array.\n        const array = []; // eslint-disable-next-line guard-for-in\n\n        for (const key in obj) {\n          array[key] = obj[key];\n        }\n\n        return array;\n      } else {\n        if (exportFormat && !this.getPriority().isEmpty()) {\n          obj['.priority'] = this.getPriority().val();\n        }\n\n        return obj;\n      }\n    }\n    /** @inheritDoc */\n\n\n    hash() {\n      if (this.lazyHash_ === null) {\n        let toHash = '';\n\n        if (!this.getPriority().isEmpty()) {\n          toHash += 'priority:' + priorityHashText(this.getPriority().val()) + ':';\n        }\n\n        this.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n          const childHash = childNode.hash();\n\n          if (childHash !== '') {\n            toHash += ':' + key + ':' + childHash;\n          }\n        });\n        this.lazyHash_ = toHash === '' ? '' : sha1(toHash);\n      }\n\n      return this.lazyHash_;\n    }\n    /** @inheritDoc */\n\n\n    getPredecessorChildName(childName, childNode, index) {\n      const idx = this.resolveIndex_(index);\n\n      if (idx) {\n        const predecessor = idx.getPredecessorKey(new NamedNode(childName, childNode));\n        return predecessor ? predecessor.name : null;\n      } else {\n        return this.children_.getPredecessorKey(childName);\n      }\n    }\n\n    getFirstChildName(indexDefinition) {\n      const idx = this.resolveIndex_(indexDefinition);\n\n      if (idx) {\n        const minKey = idx.minKey();\n        return minKey && minKey.name;\n      } else {\n        return this.children_.minKey();\n      }\n    }\n\n    getFirstChild(indexDefinition) {\n      const minKey = this.getFirstChildName(indexDefinition);\n\n      if (minKey) {\n        return new NamedNode(minKey, this.children_.get(minKey));\n      } else {\n        return null;\n      }\n    }\n    /**\r\n     * Given an index, return the key name of the largest value we have, according to that index\r\n     */\n\n\n    getLastChildName(indexDefinition) {\n      const idx = this.resolveIndex_(indexDefinition);\n\n      if (idx) {\n        const maxKey = idx.maxKey();\n        return maxKey && maxKey.name;\n      } else {\n        return this.children_.maxKey();\n      }\n    }\n\n    getLastChild(indexDefinition) {\n      const maxKey = this.getLastChildName(indexDefinition);\n\n      if (maxKey) {\n        return new NamedNode(maxKey, this.children_.get(maxKey));\n      } else {\n        return null;\n      }\n    }\n\n    forEachChild(index, action) {\n      const idx = this.resolveIndex_(index);\n\n      if (idx) {\n        return idx.inorderTraversal(wrappedNode => {\n          return action(wrappedNode.name, wrappedNode.node);\n        });\n      } else {\n        return this.children_.inorderTraversal(action);\n      }\n    }\n\n    getIterator(indexDefinition) {\n      return this.getIteratorFrom(indexDefinition.minPost(), indexDefinition);\n    }\n\n    getIteratorFrom(startPost, indexDefinition) {\n      const idx = this.resolveIndex_(indexDefinition);\n\n      if (idx) {\n        return idx.getIteratorFrom(startPost, key => key);\n      } else {\n        const iterator = this.children_.getIteratorFrom(startPost.name, NamedNode.Wrap);\n        let next = iterator.peek();\n\n        while (next != null && indexDefinition.compare(next, startPost) < 0) {\n          iterator.getNext();\n          next = iterator.peek();\n        }\n\n        return iterator;\n      }\n    }\n\n    getReverseIterator(indexDefinition) {\n      return this.getReverseIteratorFrom(indexDefinition.maxPost(), indexDefinition);\n    }\n\n    getReverseIteratorFrom(endPost, indexDefinition) {\n      const idx = this.resolveIndex_(indexDefinition);\n\n      if (idx) {\n        return idx.getReverseIteratorFrom(endPost, key => {\n          return key;\n        });\n      } else {\n        const iterator = this.children_.getReverseIteratorFrom(endPost.name, NamedNode.Wrap);\n        let next = iterator.peek();\n\n        while (next != null && indexDefinition.compare(next, endPost) > 0) {\n          iterator.getNext();\n          next = iterator.peek();\n        }\n\n        return iterator;\n      }\n    }\n\n    compareTo(other) {\n      if (this.isEmpty()) {\n        if (other.isEmpty()) {\n          return 0;\n        } else {\n          return -1;\n        }\n      } else if (other.isLeafNode() || other.isEmpty()) {\n        return 1;\n      } else if (other === MAX_NODE) {\n        return -1;\n      } else {\n        // Must be another node with children.\n        return 0;\n      }\n    }\n\n    withIndex(indexDefinition) {\n      if (indexDefinition === KEY_INDEX || this.indexMap_.hasIndex(indexDefinition)) {\n        return this;\n      } else {\n        const newIndexMap = this.indexMap_.addIndex(indexDefinition, this.children_);\n        return new ChildrenNode(this.children_, this.priorityNode_, newIndexMap);\n      }\n    }\n\n    isIndexed(index) {\n      return index === KEY_INDEX || this.indexMap_.hasIndex(index);\n    }\n\n    equals(other) {\n      if (other === this) {\n        return true;\n      } else if (other.isLeafNode()) {\n        return false;\n      } else {\n        const otherChildrenNode = other;\n\n        if (!this.getPriority().equals(otherChildrenNode.getPriority())) {\n          return false;\n        } else if (this.children_.count() === otherChildrenNode.children_.count()) {\n          const thisIter = this.getIterator(PRIORITY_INDEX);\n          const otherIter = otherChildrenNode.getIterator(PRIORITY_INDEX);\n          let thisCurrent = thisIter.getNext();\n          let otherCurrent = otherIter.getNext();\n\n          while (thisCurrent && otherCurrent) {\n            if (thisCurrent.name !== otherCurrent.name || !thisCurrent.node.equals(otherCurrent.node)) {\n              return false;\n            }\n\n            thisCurrent = thisIter.getNext();\n            otherCurrent = otherIter.getNext();\n          }\n\n          return thisCurrent === null && otherCurrent === null;\n        } else {\n          return false;\n        }\n      }\n    }\n    /**\r\n     * Returns a SortedMap ordered by index, or null if the default (by-key) ordering can be used\r\n     * instead.\r\n     *\r\n     */\n\n\n    resolveIndex_(indexDefinition) {\n      if (indexDefinition === KEY_INDEX) {\n        return null;\n      } else {\n        return this.indexMap_.get(indexDefinition.toString());\n      }\n    }\n\n  }\n\n  ChildrenNode.INTEGER_REGEXP_ = /^(0|[1-9]\\d*)$/;\n  return ChildrenNode;\n})();\n\nclass MaxNode extends ChildrenNode {\n  constructor() {\n    super(new SortedMap(NAME_COMPARATOR), ChildrenNode.EMPTY_NODE, IndexMap.Default);\n  }\n\n  compareTo(other) {\n    if (other === this) {\n      return 0;\n    } else {\n      return 1;\n    }\n  }\n\n  equals(other) {\n    // Not that we every compare it, but MAX_NODE is only ever equal to itself\n    return other === this;\n  }\n\n  getPriority() {\n    return this;\n  }\n\n  getImmediateChild(childName) {\n    return ChildrenNode.EMPTY_NODE;\n  }\n\n  isEmpty() {\n    return false;\n  }\n\n}\n/**\r\n * Marker that will sort higher than any other snapshot.\r\n */\n\n\nconst MAX_NODE = new MaxNode();\nObject.defineProperties(NamedNode, {\n  MIN: {\n    value: new NamedNode(MIN_NAME, ChildrenNode.EMPTY_NODE)\n  },\n  MAX: {\n    value: new NamedNode(MAX_NAME, MAX_NODE)\n  }\n});\n/**\r\n * Reference Extensions\r\n */\n\nKeyIndex.__EMPTY_NODE = ChildrenNode.EMPTY_NODE;\nLeafNode.__childrenNodeConstructor = ChildrenNode;\nsetMaxNode$1(MAX_NODE);\nsetMaxNode(MAX_NODE);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nconst USE_HINZE = true;\n/**\r\n * Constructs a snapshot node representing the passed JSON and returns it.\r\n * @param json - JSON to create a node for.\r\n * @param priority - Optional priority to use.  This will be ignored if the\r\n * passed JSON contains a .priority property.\r\n */\n\nfunction nodeFromJSON(json, priority = null) {\n  if (json === null) {\n    return ChildrenNode.EMPTY_NODE;\n  }\n\n  if (typeof json === 'object' && '.priority' in json) {\n    priority = json['.priority'];\n  }\n\n  assert(priority === null || typeof priority === 'string' || typeof priority === 'number' || typeof priority === 'object' && '.sv' in priority, 'Invalid priority type found: ' + typeof priority);\n\n  if (typeof json === 'object' && '.value' in json && json['.value'] !== null) {\n    json = json['.value'];\n  } // Valid leaf nodes include non-objects or server-value wrapper objects\n\n\n  if (typeof json !== 'object' || '.sv' in json) {\n    const jsonLeaf = json;\n    return new LeafNode(jsonLeaf, nodeFromJSON(priority));\n  }\n\n  if (!(json instanceof Array) && USE_HINZE) {\n    const children = [];\n    let childrenHavePriority = false;\n    const hinzeJsonObj = json;\n    each(hinzeJsonObj, (key, child) => {\n      if (key.substring(0, 1) !== '.') {\n        // Ignore metadata nodes\n        const childNode = nodeFromJSON(child);\n\n        if (!childNode.isEmpty()) {\n          childrenHavePriority = childrenHavePriority || !childNode.getPriority().isEmpty();\n          children.push(new NamedNode(key, childNode));\n        }\n      }\n    });\n\n    if (children.length === 0) {\n      return ChildrenNode.EMPTY_NODE;\n    }\n\n    const childSet = buildChildSet(children, NAME_ONLY_COMPARATOR, namedNode => namedNode.name, NAME_COMPARATOR);\n\n    if (childrenHavePriority) {\n      const sortedChildSet = buildChildSet(children, PRIORITY_INDEX.getCompare());\n      return new ChildrenNode(childSet, nodeFromJSON(priority), new IndexMap({\n        '.priority': sortedChildSet\n      }, {\n        '.priority': PRIORITY_INDEX\n      }));\n    } else {\n      return new ChildrenNode(childSet, nodeFromJSON(priority), IndexMap.Default);\n    }\n  } else {\n    let node = ChildrenNode.EMPTY_NODE;\n    each(json, (key, childData) => {\n      if (contains(json, key)) {\n        if (key.substring(0, 1) !== '.') {\n          // ignore metadata nodes.\n          const childNode = nodeFromJSON(childData);\n\n          if (childNode.isLeafNode() || !childNode.isEmpty()) {\n            node = node.updateImmediateChild(key, childNode);\n          }\n        }\n      }\n    });\n    return node.updatePriority(nodeFromJSON(priority));\n  }\n}\n\nsetNodeFromJSON(nodeFromJSON);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nclass PathIndex extends Index {\n  constructor(indexPath_) {\n    super();\n    this.indexPath_ = indexPath_;\n    assert(!pathIsEmpty(indexPath_) && pathGetFront(indexPath_) !== '.priority', \"Can't create PathIndex with empty path or .priority key\");\n  }\n\n  extractChild(snap) {\n    return snap.getChild(this.indexPath_);\n  }\n\n  isDefinedOn(node) {\n    return !node.getChild(this.indexPath_).isEmpty();\n  }\n\n  compare(a, b) {\n    const aChild = this.extractChild(a.node);\n    const bChild = this.extractChild(b.node);\n    const indexCmp = aChild.compareTo(bChild);\n\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n\n  makePost(indexValue, name) {\n    const valueNode = nodeFromJSON(indexValue);\n    const node = ChildrenNode.EMPTY_NODE.updateChild(this.indexPath_, valueNode);\n    return new NamedNode(name, node);\n  }\n\n  maxPost() {\n    const node = ChildrenNode.EMPTY_NODE.updateChild(this.indexPath_, MAX_NODE);\n    return new NamedNode(MAX_NAME, node);\n  }\n\n  toString() {\n    return pathSlice(this.indexPath_, 0).join('/');\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass ValueIndex extends Index {\n  compare(a, b) {\n    const indexCmp = a.node.compareTo(b.node);\n\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n\n  isDefinedOn(node) {\n    return true;\n  }\n\n  indexedValueChanged(oldNode, newNode) {\n    return !oldNode.equals(newNode);\n  }\n\n  minPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return NamedNode.MIN;\n  }\n\n  maxPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return NamedNode.MAX;\n  }\n\n  makePost(indexValue, name) {\n    const valueNode = nodeFromJSON(indexValue);\n    return new NamedNode(name, valueNode);\n  }\n  /**\r\n   * @returns String representation for inclusion in a query spec\r\n   */\n\n\n  toString() {\n    return '.value';\n  }\n\n}\n\nconst VALUE_INDEX = new ValueIndex();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// Modeled after base64 web-safe chars, but ordered by ASCII.\n\nconst PUSH_CHARS = '-0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz';\nconst MIN_PUSH_CHAR = '-';\nconst MAX_PUSH_CHAR = 'z';\nconst MAX_KEY_LEN = 786;\n/**\r\n * Fancy ID generator that creates 20-character string identifiers with the\r\n * following properties:\r\n *\r\n * 1. They're based on timestamp so that they sort *after* any existing ids.\r\n * 2. They contain 72-bits of random data after the timestamp so that IDs won't\r\n *    collide with other clients' IDs.\r\n * 3. They sort *lexicographically* (so the timestamp is converted to characters\r\n *    that will sort properly).\r\n * 4. They're monotonically increasing. Even if you generate more than one in\r\n *    the same timestamp, the latter ones will sort after the former ones. We do\r\n *    this by using the previous random bits but \"incrementing\" them by 1 (only\r\n *    in the case of a timestamp collision).\r\n */\n\nconst nextPushId = function () {\n  // Timestamp of last push, used to prevent local collisions if you push twice\n  // in one ms.\n  let lastPushTime = 0; // We generate 72-bits of randomness which get turned into 12 characters and\n  // appended to the timestamp to prevent collisions with other clients. We\n  // store the last characters we generated because in the event of a collision,\n  // we'll use those same characters except \"incremented\" by one.\n\n  const lastRandChars = [];\n  return function (now) {\n    const duplicateTime = now === lastPushTime;\n    lastPushTime = now;\n    let i;\n    const timeStampChars = new Array(8);\n\n    for (i = 7; i >= 0; i--) {\n      timeStampChars[i] = PUSH_CHARS.charAt(now % 64); // NOTE: Can't use << here because javascript will convert to int and lose\n      // the upper bits.\n\n      now = Math.floor(now / 64);\n    }\n\n    assert(now === 0, 'Cannot push at time == 0');\n    let id = timeStampChars.join('');\n\n    if (!duplicateTime) {\n      for (i = 0; i < 12; i++) {\n        lastRandChars[i] = Math.floor(Math.random() * 64);\n      }\n    } else {\n      // If the timestamp hasn't changed since last push, use the same random\n      // number, except incremented by 1.\n      for (i = 11; i >= 0 && lastRandChars[i] === 63; i--) {\n        lastRandChars[i] = 0;\n      }\n\n      lastRandChars[i]++;\n    }\n\n    for (i = 0; i < 12; i++) {\n      id += PUSH_CHARS.charAt(lastRandChars[i]);\n    }\n\n    assert(id.length === 20, 'nextPushId: Length should be 20.');\n    return id;\n  };\n}();\n\nconst successor = function (key) {\n  if (key === '' + INTEGER_32_MAX) {\n    // See https://firebase.google.com/docs/database/web/lists-of-data#data-order\n    return MIN_PUSH_CHAR;\n  }\n\n  const keyAsInt = tryParseInt(key);\n\n  if (keyAsInt != null) {\n    return '' + (keyAsInt + 1);\n  }\n\n  const next = new Array(key.length);\n\n  for (let i = 0; i < next.length; i++) {\n    next[i] = key.charAt(i);\n  }\n\n  if (next.length < MAX_KEY_LEN) {\n    next.push(MIN_PUSH_CHAR);\n    return next.join('');\n  }\n\n  let i = next.length - 1;\n\n  while (i >= 0 && next[i] === MAX_PUSH_CHAR) {\n    i--;\n  } // `successor` was called on the largest possible key, so return the\n  // MAX_NAME, which sorts larger than all keys.\n\n\n  if (i === -1) {\n    return MAX_NAME;\n  }\n\n  const source = next[i];\n  const sourcePlusOne = PUSH_CHARS.charAt(PUSH_CHARS.indexOf(source) + 1);\n  next[i] = sourcePlusOne;\n  return next.slice(0, i + 1).join('');\n}; // `key` is assumed to be non-empty.\n\n\nconst predecessor = function (key) {\n  if (key === '' + INTEGER_32_MIN) {\n    return MIN_NAME;\n  }\n\n  const keyAsInt = tryParseInt(key);\n\n  if (keyAsInt != null) {\n    return '' + (keyAsInt - 1);\n  }\n\n  const next = new Array(key.length);\n\n  for (let i = 0; i < next.length; i++) {\n    next[i] = key.charAt(i);\n  } // If `key` ends in `MIN_PUSH_CHAR`, the largest key lexicographically\n  // smaller than `key`, is `key[0:key.length - 1]`. The next key smaller\n  // than that, `predecessor(predecessor(key))`, is\n  //\n  // `key[0:key.length - 2] + (key[key.length - 1] - 1) + \\\n  //   { MAX_PUSH_CHAR repeated MAX_KEY_LEN - (key.length - 1) times }\n  //\n  // analogous to increment/decrement for base-10 integers.\n  //\n  // This works because lexigographic comparison works character-by-character,\n  // using length as a tie-breaker if one key is a prefix of the other.\n\n\n  if (next[next.length - 1] === MIN_PUSH_CHAR) {\n    if (next.length === 1) {\n      // See https://firebase.google.com/docs/database/web/lists-of-data#orderbykey\n      return '' + INTEGER_32_MAX;\n    }\n\n    delete next[next.length - 1];\n    return next.join('');\n  } // Replace the last character with it's immediate predecessor, and\n  // fill the suffix of the key with MAX_PUSH_CHAR. This is the\n  // lexicographically largest possible key smaller than `key`.\n\n\n  next[next.length - 1] = PUSH_CHARS.charAt(PUSH_CHARS.indexOf(next[next.length - 1]) - 1);\n  return next.join('') + MAX_PUSH_CHAR.repeat(MAX_KEY_LEN - next.length);\n};\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction changeValue(snapshotNode) {\n  return {\n    type: \"value\"\n    /* VALUE */\n    ,\n    snapshotNode\n  };\n}\n\nfunction changeChildAdded(childName, snapshotNode) {\n  return {\n    type: \"child_added\"\n    /* CHILD_ADDED */\n    ,\n    snapshotNode,\n    childName\n  };\n}\n\nfunction changeChildRemoved(childName, snapshotNode) {\n  return {\n    type: \"child_removed\"\n    /* CHILD_REMOVED */\n    ,\n    snapshotNode,\n    childName\n  };\n}\n\nfunction changeChildChanged(childName, snapshotNode, oldSnap) {\n  return {\n    type: \"child_changed\"\n    /* CHILD_CHANGED */\n    ,\n    snapshotNode,\n    childName,\n    oldSnap\n  };\n}\n\nfunction changeChildMoved(childName, snapshotNode) {\n  return {\n    type: \"child_moved\"\n    /* CHILD_MOVED */\n    ,\n    snapshotNode,\n    childName\n  };\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Doesn't really filter nodes but applies an index to the node and keeps track of any changes\r\n */\n\n\nclass IndexedFilter {\n  constructor(index_) {\n    this.index_ = index_;\n  }\n\n  updateChild(snap, key, newChild, affectedPath, source, optChangeAccumulator) {\n    assert(snap.isIndexed(this.index_), 'A node must be indexed if only a child is updated');\n    const oldChild = snap.getImmediateChild(key); // Check if anything actually changed.\n\n    if (oldChild.getChild(affectedPath).equals(newChild.getChild(affectedPath))) {\n      // There's an edge case where a child can enter or leave the view because affectedPath was set to null.\n      // In this case, affectedPath will appear null in both the old and new snapshots.  So we need\n      // to avoid treating these cases as \"nothing changed.\"\n      if (oldChild.isEmpty() === newChild.isEmpty()) {\n        // Nothing changed.\n        // This assert should be valid, but it's expensive (can dominate perf testing) so don't actually do it.\n        //assert(oldChild.equals(newChild), 'Old and new snapshots should be equal.');\n        return snap;\n      }\n    }\n\n    if (optChangeAccumulator != null) {\n      if (newChild.isEmpty()) {\n        if (snap.hasChild(key)) {\n          optChangeAccumulator.trackChildChange(changeChildRemoved(key, oldChild));\n        } else {\n          assert(snap.isLeafNode(), 'A child remove without an old child only makes sense on a leaf node');\n        }\n      } else if (oldChild.isEmpty()) {\n        optChangeAccumulator.trackChildChange(changeChildAdded(key, newChild));\n      } else {\n        optChangeAccumulator.trackChildChange(changeChildChanged(key, newChild, oldChild));\n      }\n    }\n\n    if (snap.isLeafNode() && newChild.isEmpty()) {\n      return snap;\n    } else {\n      // Make sure the node is indexed\n      return snap.updateImmediateChild(key, newChild).withIndex(this.index_);\n    }\n  }\n\n  updateFullNode(oldSnap, newSnap, optChangeAccumulator) {\n    if (optChangeAccumulator != null) {\n      if (!oldSnap.isLeafNode()) {\n        oldSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n          if (!newSnap.hasChild(key)) {\n            optChangeAccumulator.trackChildChange(changeChildRemoved(key, childNode));\n          }\n        });\n      }\n\n      if (!newSnap.isLeafNode()) {\n        newSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n          if (oldSnap.hasChild(key)) {\n            const oldChild = oldSnap.getImmediateChild(key);\n\n            if (!oldChild.equals(childNode)) {\n              optChangeAccumulator.trackChildChange(changeChildChanged(key, childNode, oldChild));\n            }\n          } else {\n            optChangeAccumulator.trackChildChange(changeChildAdded(key, childNode));\n          }\n        });\n      }\n    }\n\n    return newSnap.withIndex(this.index_);\n  }\n\n  updatePriority(oldSnap, newPriority) {\n    if (oldSnap.isEmpty()) {\n      return ChildrenNode.EMPTY_NODE;\n    } else {\n      return oldSnap.updatePriority(newPriority);\n    }\n  }\n\n  filtersNodes() {\n    return false;\n  }\n\n  getIndexedFilter() {\n    return this;\n  }\n\n  getIndex() {\n    return this.index_;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Filters nodes by range and uses an IndexFilter to track any changes after filtering the node\r\n */\n\n\nclass RangedFilter {\n  constructor(params) {\n    this.indexedFilter_ = new IndexedFilter(params.getIndex());\n    this.index_ = params.getIndex();\n    this.startPost_ = RangedFilter.getStartPost_(params);\n    this.endPost_ = RangedFilter.getEndPost_(params);\n  }\n\n  getStartPost() {\n    return this.startPost_;\n  }\n\n  getEndPost() {\n    return this.endPost_;\n  }\n\n  matches(node) {\n    return this.index_.compare(this.getStartPost(), node) <= 0 && this.index_.compare(node, this.getEndPost()) <= 0;\n  }\n\n  updateChild(snap, key, newChild, affectedPath, source, optChangeAccumulator) {\n    if (!this.matches(new NamedNode(key, newChild))) {\n      newChild = ChildrenNode.EMPTY_NODE;\n    }\n\n    return this.indexedFilter_.updateChild(snap, key, newChild, affectedPath, source, optChangeAccumulator);\n  }\n\n  updateFullNode(oldSnap, newSnap, optChangeAccumulator) {\n    if (newSnap.isLeafNode()) {\n      // Make sure we have a children node with the correct index, not a leaf node;\n      newSnap = ChildrenNode.EMPTY_NODE;\n    }\n\n    let filtered = newSnap.withIndex(this.index_); // Don't support priorities on queries\n\n    filtered = filtered.updatePriority(ChildrenNode.EMPTY_NODE);\n    const self = this;\n    newSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n      if (!self.matches(new NamedNode(key, childNode))) {\n        filtered = filtered.updateImmediateChild(key, ChildrenNode.EMPTY_NODE);\n      }\n    });\n    return this.indexedFilter_.updateFullNode(oldSnap, filtered, optChangeAccumulator);\n  }\n\n  updatePriority(oldSnap, newPriority) {\n    // Don't support priorities on queries\n    return oldSnap;\n  }\n\n  filtersNodes() {\n    return true;\n  }\n\n  getIndexedFilter() {\n    return this.indexedFilter_;\n  }\n\n  getIndex() {\n    return this.index_;\n  }\n\n  static getStartPost_(params) {\n    if (params.hasStart()) {\n      const startName = params.getIndexStartName();\n      return params.getIndex().makePost(params.getIndexStartValue(), startName);\n    } else {\n      return params.getIndex().minPost();\n    }\n  }\n\n  static getEndPost_(params) {\n    if (params.hasEnd()) {\n      const endName = params.getIndexEndName();\n      return params.getIndex().makePost(params.getIndexEndValue(), endName);\n    } else {\n      return params.getIndex().maxPost();\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Applies a limit and a range to a node and uses RangedFilter to do the heavy lifting where possible\r\n */\n\n\nclass LimitedFilter {\n  constructor(params) {\n    this.rangedFilter_ = new RangedFilter(params);\n    this.index_ = params.getIndex();\n    this.limit_ = params.getLimit();\n    this.reverse_ = !params.isViewFromLeft();\n  }\n\n  updateChild(snap, key, newChild, affectedPath, source, optChangeAccumulator) {\n    if (!this.rangedFilter_.matches(new NamedNode(key, newChild))) {\n      newChild = ChildrenNode.EMPTY_NODE;\n    }\n\n    if (snap.getImmediateChild(key).equals(newChild)) {\n      // No change\n      return snap;\n    } else if (snap.numChildren() < this.limit_) {\n      return this.rangedFilter_.getIndexedFilter().updateChild(snap, key, newChild, affectedPath, source, optChangeAccumulator);\n    } else {\n      return this.fullLimitUpdateChild_(snap, key, newChild, source, optChangeAccumulator);\n    }\n  }\n\n  updateFullNode(oldSnap, newSnap, optChangeAccumulator) {\n    let filtered;\n\n    if (newSnap.isLeafNode() || newSnap.isEmpty()) {\n      // Make sure we have a children node with the correct index, not a leaf node;\n      filtered = ChildrenNode.EMPTY_NODE.withIndex(this.index_);\n    } else {\n      if (this.limit_ * 2 < newSnap.numChildren() && newSnap.isIndexed(this.index_)) {\n        // Easier to build up a snapshot, since what we're given has more than twice the elements we want\n        filtered = ChildrenNode.EMPTY_NODE.withIndex(this.index_); // anchor to the startPost, endPost, or last element as appropriate\n\n        let iterator;\n\n        if (this.reverse_) {\n          iterator = newSnap.getReverseIteratorFrom(this.rangedFilter_.getEndPost(), this.index_);\n        } else {\n          iterator = newSnap.getIteratorFrom(this.rangedFilter_.getStartPost(), this.index_);\n        }\n\n        let count = 0;\n\n        while (iterator.hasNext() && count < this.limit_) {\n          const next = iterator.getNext();\n          let inRange;\n\n          if (this.reverse_) {\n            inRange = this.index_.compare(this.rangedFilter_.getStartPost(), next) <= 0;\n          } else {\n            inRange = this.index_.compare(next, this.rangedFilter_.getEndPost()) <= 0;\n          }\n\n          if (inRange) {\n            filtered = filtered.updateImmediateChild(next.name, next.node);\n            count++;\n          } else {\n            // if we have reached the end post, we cannot keep adding elemments\n            break;\n          }\n        }\n      } else {\n        // The snap contains less than twice the limit. Faster to delete from the snap than build up a new one\n        filtered = newSnap.withIndex(this.index_); // Don't support priorities on queries\n\n        filtered = filtered.updatePriority(ChildrenNode.EMPTY_NODE);\n        let startPost;\n        let endPost;\n        let cmp;\n        let iterator;\n\n        if (this.reverse_) {\n          iterator = filtered.getReverseIterator(this.index_);\n          startPost = this.rangedFilter_.getEndPost();\n          endPost = this.rangedFilter_.getStartPost();\n          const indexCompare = this.index_.getCompare();\n\n          cmp = (a, b) => indexCompare(b, a);\n        } else {\n          iterator = filtered.getIterator(this.index_);\n          startPost = this.rangedFilter_.getStartPost();\n          endPost = this.rangedFilter_.getEndPost();\n          cmp = this.index_.getCompare();\n        }\n\n        let count = 0;\n        let foundStartPost = false;\n\n        while (iterator.hasNext()) {\n          const next = iterator.getNext();\n\n          if (!foundStartPost && cmp(startPost, next) <= 0) {\n            // start adding\n            foundStartPost = true;\n          }\n\n          const inRange = foundStartPost && count < this.limit_ && cmp(next, endPost) <= 0;\n\n          if (inRange) {\n            count++;\n          } else {\n            filtered = filtered.updateImmediateChild(next.name, ChildrenNode.EMPTY_NODE);\n          }\n        }\n      }\n    }\n\n    return this.rangedFilter_.getIndexedFilter().updateFullNode(oldSnap, filtered, optChangeAccumulator);\n  }\n\n  updatePriority(oldSnap, newPriority) {\n    // Don't support priorities on queries\n    return oldSnap;\n  }\n\n  filtersNodes() {\n    return true;\n  }\n\n  getIndexedFilter() {\n    return this.rangedFilter_.getIndexedFilter();\n  }\n\n  getIndex() {\n    return this.index_;\n  }\n\n  fullLimitUpdateChild_(snap, childKey, childSnap, source, changeAccumulator) {\n    // TODO: rename all cache stuff etc to general snap terminology\n    let cmp;\n\n    if (this.reverse_) {\n      const indexCmp = this.index_.getCompare();\n\n      cmp = (a, b) => indexCmp(b, a);\n    } else {\n      cmp = this.index_.getCompare();\n    }\n\n    const oldEventCache = snap;\n    assert(oldEventCache.numChildren() === this.limit_, '');\n    const newChildNamedNode = new NamedNode(childKey, childSnap);\n    const windowBoundary = this.reverse_ ? oldEventCache.getFirstChild(this.index_) : oldEventCache.getLastChild(this.index_);\n    const inRange = this.rangedFilter_.matches(newChildNamedNode);\n\n    if (oldEventCache.hasChild(childKey)) {\n      const oldChildSnap = oldEventCache.getImmediateChild(childKey);\n      let nextChild = source.getChildAfterChild(this.index_, windowBoundary, this.reverse_);\n\n      while (nextChild != null && (nextChild.name === childKey || oldEventCache.hasChild(nextChild.name))) {\n        // There is a weird edge case where a node is updated as part of a merge in the write tree, but hasn't\n        // been applied to the limited filter yet. Ignore this next child which will be updated later in\n        // the limited filter...\n        nextChild = source.getChildAfterChild(this.index_, nextChild, this.reverse_);\n      }\n\n      const compareNext = nextChild == null ? 1 : cmp(nextChild, newChildNamedNode);\n      const remainsInWindow = inRange && !childSnap.isEmpty() && compareNext >= 0;\n\n      if (remainsInWindow) {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(changeChildChanged(childKey, childSnap, oldChildSnap));\n        }\n\n        return oldEventCache.updateImmediateChild(childKey, childSnap);\n      } else {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(changeChildRemoved(childKey, oldChildSnap));\n        }\n\n        const newEventCache = oldEventCache.updateImmediateChild(childKey, ChildrenNode.EMPTY_NODE);\n        const nextChildInRange = nextChild != null && this.rangedFilter_.matches(nextChild);\n\n        if (nextChildInRange) {\n          if (changeAccumulator != null) {\n            changeAccumulator.trackChildChange(changeChildAdded(nextChild.name, nextChild.node));\n          }\n\n          return newEventCache.updateImmediateChild(nextChild.name, nextChild.node);\n        } else {\n          return newEventCache;\n        }\n      }\n    } else if (childSnap.isEmpty()) {\n      // we're deleting a node, but it was not in the window, so ignore it\n      return snap;\n    } else if (inRange) {\n      if (cmp(windowBoundary, newChildNamedNode) >= 0) {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(changeChildRemoved(windowBoundary.name, windowBoundary.node));\n          changeAccumulator.trackChildChange(changeChildAdded(childKey, childSnap));\n        }\n\n        return oldEventCache.updateImmediateChild(childKey, childSnap).updateImmediateChild(windowBoundary.name, ChildrenNode.EMPTY_NODE);\n      } else {\n        return snap;\n      }\n    } else {\n      return snap;\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * This class is an immutable-from-the-public-api struct containing a set of query parameters defining a\r\n * range to be returned for a particular location. It is assumed that validation of parameters is done at the\r\n * user-facing API level, so it is not done here.\r\n *\r\n * @internal\r\n */\n\n\nclass QueryParams {\n  constructor() {\n    this.limitSet_ = false;\n    this.startSet_ = false;\n    this.startNameSet_ = false;\n    this.startAfterSet_ = false;\n    this.endSet_ = false;\n    this.endNameSet_ = false;\n    this.endBeforeSet_ = false;\n    this.limit_ = 0;\n    this.viewFrom_ = '';\n    this.indexStartValue_ = null;\n    this.indexStartName_ = '';\n    this.indexEndValue_ = null;\n    this.indexEndName_ = '';\n    this.index_ = PRIORITY_INDEX;\n  }\n\n  hasStart() {\n    return this.startSet_;\n  }\n\n  hasStartAfter() {\n    return this.startAfterSet_;\n  }\n\n  hasEndBefore() {\n    return this.endBeforeSet_;\n  }\n  /**\r\n   * @returns True if it would return from left.\r\n   */\n\n\n  isViewFromLeft() {\n    if (this.viewFrom_ === '') {\n      // limit(), rather than limitToFirst or limitToLast was called.\n      // This means that only one of startSet_ and endSet_ is true. Use them\n      // to calculate which side of the view to anchor to. If neither is set,\n      // anchor to the end.\n      return this.startSet_;\n    } else {\n      return this.viewFrom_ === \"l\"\n      /* VIEW_FROM_LEFT */\n      ;\n    }\n  }\n  /**\r\n   * Only valid to call if hasStart() returns true\r\n   */\n\n\n  getIndexStartValue() {\n    assert(this.startSet_, 'Only valid if start has been set');\n    return this.indexStartValue_;\n  }\n  /**\r\n   * Only valid to call if hasStart() returns true.\r\n   * Returns the starting key name for the range defined by these query parameters\r\n   */\n\n\n  getIndexStartName() {\n    assert(this.startSet_, 'Only valid if start has been set');\n\n    if (this.startNameSet_) {\n      return this.indexStartName_;\n    } else {\n      return MIN_NAME;\n    }\n  }\n\n  hasEnd() {\n    return this.endSet_;\n  }\n  /**\r\n   * Only valid to call if hasEnd() returns true.\r\n   */\n\n\n  getIndexEndValue() {\n    assert(this.endSet_, 'Only valid if end has been set');\n    return this.indexEndValue_;\n  }\n  /**\r\n   * Only valid to call if hasEnd() returns true.\r\n   * Returns the end key name for the range defined by these query parameters\r\n   */\n\n\n  getIndexEndName() {\n    assert(this.endSet_, 'Only valid if end has been set');\n\n    if (this.endNameSet_) {\n      return this.indexEndName_;\n    } else {\n      return MAX_NAME;\n    }\n  }\n\n  hasLimit() {\n    return this.limitSet_;\n  }\n  /**\r\n   * @returns True if a limit has been set and it has been explicitly anchored\r\n   */\n\n\n  hasAnchoredLimit() {\n    return this.limitSet_ && this.viewFrom_ !== '';\n  }\n  /**\r\n   * Only valid to call if hasLimit() returns true\r\n   */\n\n\n  getLimit() {\n    assert(this.limitSet_, 'Only valid if limit has been set');\n    return this.limit_;\n  }\n\n  getIndex() {\n    return this.index_;\n  }\n\n  loadsAllData() {\n    return !(this.startSet_ || this.endSet_ || this.limitSet_);\n  }\n\n  isDefault() {\n    return this.loadsAllData() && this.index_ === PRIORITY_INDEX;\n  }\n\n  copy() {\n    const copy = new QueryParams();\n    copy.limitSet_ = this.limitSet_;\n    copy.limit_ = this.limit_;\n    copy.startSet_ = this.startSet_;\n    copy.indexStartValue_ = this.indexStartValue_;\n    copy.startNameSet_ = this.startNameSet_;\n    copy.indexStartName_ = this.indexStartName_;\n    copy.endSet_ = this.endSet_;\n    copy.indexEndValue_ = this.indexEndValue_;\n    copy.endNameSet_ = this.endNameSet_;\n    copy.indexEndName_ = this.indexEndName_;\n    copy.index_ = this.index_;\n    copy.viewFrom_ = this.viewFrom_;\n    return copy;\n  }\n\n}\n\nfunction queryParamsGetNodeFilter(queryParams) {\n  if (queryParams.loadsAllData()) {\n    return new IndexedFilter(queryParams.getIndex());\n  } else if (queryParams.hasLimit()) {\n    return new LimitedFilter(queryParams);\n  } else {\n    return new RangedFilter(queryParams);\n  }\n}\n\nfunction queryParamsLimitToFirst(queryParams, newLimit) {\n  const newParams = queryParams.copy();\n  newParams.limitSet_ = true;\n  newParams.limit_ = newLimit;\n  newParams.viewFrom_ = \"l\"\n  /* VIEW_FROM_LEFT */\n  ;\n  return newParams;\n}\n\nfunction queryParamsLimitToLast(queryParams, newLimit) {\n  const newParams = queryParams.copy();\n  newParams.limitSet_ = true;\n  newParams.limit_ = newLimit;\n  newParams.viewFrom_ = \"r\"\n  /* VIEW_FROM_RIGHT */\n  ;\n  return newParams;\n}\n\nfunction queryParamsStartAt(queryParams, indexValue, key) {\n  const newParams = queryParams.copy();\n  newParams.startSet_ = true;\n\n  if (indexValue === undefined) {\n    indexValue = null;\n  }\n\n  newParams.indexStartValue_ = indexValue;\n\n  if (key != null) {\n    newParams.startNameSet_ = true;\n    newParams.indexStartName_ = key;\n  } else {\n    newParams.startNameSet_ = false;\n    newParams.indexStartName_ = '';\n  }\n\n  return newParams;\n}\n\nfunction queryParamsStartAfter(queryParams, indexValue, key) {\n  let params;\n\n  if (queryParams.index_ === KEY_INDEX) {\n    if (typeof indexValue === 'string') {\n      indexValue = successor(indexValue);\n    }\n\n    params = queryParamsStartAt(queryParams, indexValue, key);\n  } else {\n    let childKey;\n\n    if (key == null) {\n      childKey = MAX_NAME;\n    } else {\n      childKey = successor(key);\n    }\n\n    params = queryParamsStartAt(queryParams, indexValue, childKey);\n  }\n\n  params.startAfterSet_ = true;\n  return params;\n}\n\nfunction queryParamsEndAt(queryParams, indexValue, key) {\n  const newParams = queryParams.copy();\n  newParams.endSet_ = true;\n\n  if (indexValue === undefined) {\n    indexValue = null;\n  }\n\n  newParams.indexEndValue_ = indexValue;\n\n  if (key !== undefined) {\n    newParams.endNameSet_ = true;\n    newParams.indexEndName_ = key;\n  } else {\n    newParams.endNameSet_ = false;\n    newParams.indexEndName_ = '';\n  }\n\n  return newParams;\n}\n\nfunction queryParamsEndBefore(queryParams, indexValue, key) {\n  let childKey;\n  let params;\n\n  if (queryParams.index_ === KEY_INDEX) {\n    if (typeof indexValue === 'string') {\n      indexValue = predecessor(indexValue);\n    }\n\n    params = queryParamsEndAt(queryParams, indexValue, key);\n  } else {\n    if (key == null) {\n      childKey = MIN_NAME;\n    } else {\n      childKey = predecessor(key);\n    }\n\n    params = queryParamsEndAt(queryParams, indexValue, childKey);\n  }\n\n  params.endBeforeSet_ = true;\n  return params;\n}\n\nfunction queryParamsOrderBy(queryParams, index) {\n  const newParams = queryParams.copy();\n  newParams.index_ = index;\n  return newParams;\n}\n/**\r\n * Returns a set of REST query string parameters representing this query.\r\n *\r\n * @returns query string parameters\r\n */\n\n\nfunction queryParamsToRestQueryStringParameters(queryParams) {\n  const qs = {};\n\n  if (queryParams.isDefault()) {\n    return qs;\n  }\n\n  let orderBy;\n\n  if (queryParams.index_ === PRIORITY_INDEX) {\n    orderBy = \"$priority\"\n    /* PRIORITY_INDEX */\n    ;\n  } else if (queryParams.index_ === VALUE_INDEX) {\n    orderBy = \"$value\"\n    /* VALUE_INDEX */\n    ;\n  } else if (queryParams.index_ === KEY_INDEX) {\n    orderBy = \"$key\"\n    /* KEY_INDEX */\n    ;\n  } else {\n    assert(queryParams.index_ instanceof PathIndex, 'Unrecognized index type!');\n    orderBy = queryParams.index_.toString();\n  }\n\n  qs[\"orderBy\"\n  /* ORDER_BY */\n  ] = stringify(orderBy);\n\n  if (queryParams.startSet_) {\n    qs[\"startAt\"\n    /* START_AT */\n    ] = stringify(queryParams.indexStartValue_);\n\n    if (queryParams.startNameSet_) {\n      qs[\"startAt\"\n      /* START_AT */\n      ] += ',' + stringify(queryParams.indexStartName_);\n    }\n  }\n\n  if (queryParams.endSet_) {\n    qs[\"endAt\"\n    /* END_AT */\n    ] = stringify(queryParams.indexEndValue_);\n\n    if (queryParams.endNameSet_) {\n      qs[\"endAt\"\n      /* END_AT */\n      ] += ',' + stringify(queryParams.indexEndName_);\n    }\n  }\n\n  if (queryParams.limitSet_) {\n    if (queryParams.isViewFromLeft()) {\n      qs[\"limitToFirst\"\n      /* LIMIT_TO_FIRST */\n      ] = queryParams.limit_;\n    } else {\n      qs[\"limitToLast\"\n      /* LIMIT_TO_LAST */\n      ] = queryParams.limit_;\n    }\n  }\n\n  return qs;\n}\n\nfunction queryParamsGetQueryObject(queryParams) {\n  const obj = {};\n\n  if (queryParams.startSet_) {\n    obj[\"sp\"\n    /* INDEX_START_VALUE */\n    ] = queryParams.indexStartValue_;\n\n    if (queryParams.startNameSet_) {\n      obj[\"sn\"\n      /* INDEX_START_NAME */\n      ] = queryParams.indexStartName_;\n    }\n  }\n\n  if (queryParams.endSet_) {\n    obj[\"ep\"\n    /* INDEX_END_VALUE */\n    ] = queryParams.indexEndValue_;\n\n    if (queryParams.endNameSet_) {\n      obj[\"en\"\n      /* INDEX_END_NAME */\n      ] = queryParams.indexEndName_;\n    }\n  }\n\n  if (queryParams.limitSet_) {\n    obj[\"l\"\n    /* LIMIT */\n    ] = queryParams.limit_;\n    let viewFrom = queryParams.viewFrom_;\n\n    if (viewFrom === '') {\n      if (queryParams.isViewFromLeft()) {\n        viewFrom = \"l\"\n        /* VIEW_FROM_LEFT */\n        ;\n      } else {\n        viewFrom = \"r\"\n        /* VIEW_FROM_RIGHT */\n        ;\n      }\n    }\n\n    obj[\"vf\"\n    /* VIEW_FROM */\n    ] = viewFrom;\n  } // For now, priority index is the default, so we only specify if it's some other index\n\n\n  if (queryParams.index_ !== PRIORITY_INDEX) {\n    obj[\"i\"\n    /* INDEX */\n    ] = queryParams.index_.toString();\n  }\n\n  return obj;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An implementation of ServerActions that communicates with the server via REST requests.\r\n * This is mostly useful for compatibility with crawlers, where we don't want to spin up a full\r\n * persistent connection (using WebSockets or long-polling)\r\n */\n\n\nclass ReadonlyRestClient extends ServerActions {\n  /**\r\n   * @param repoInfo_ - Data about the namespace we are connecting to\r\n   * @param onDataUpdate_ - A callback for new data from the server\r\n   */\n  constructor(repoInfo_, onDataUpdate_, authTokenProvider_, appCheckTokenProvider_) {\n    super();\n    this.repoInfo_ = repoInfo_;\n    this.onDataUpdate_ = onDataUpdate_;\n    this.authTokenProvider_ = authTokenProvider_;\n    this.appCheckTokenProvider_ = appCheckTokenProvider_;\n    /** @private {function(...[*])} */\n\n    this.log_ = logWrapper('p:rest:');\n    /**\r\n     * We don't actually need to track listens, except to prevent us calling an onComplete for a listen\r\n     * that's been removed. :-/\r\n     */\n\n    this.listens_ = {};\n  }\n\n  reportStats(stats) {\n    throw new Error('Method not implemented.');\n  }\n\n  static getListenId_(query, tag) {\n    if (tag !== undefined) {\n      return 'tag$' + tag;\n    } else {\n      assert(query._queryParams.isDefault(), \"should have a tag if it's not a default query.\");\n      return query._path.toString();\n    }\n  }\n  /** @inheritDoc */\n\n\n  listen(query, currentHashFn, tag, onComplete) {\n    const pathString = query._path.toString();\n\n    this.log_('Listen called for ' + pathString + ' ' + query._queryIdentifier); // Mark this listener so we can tell if it's removed.\n\n    const listenId = ReadonlyRestClient.getListenId_(query, tag);\n    const thisListen = {};\n    this.listens_[listenId] = thisListen;\n    const queryStringParameters = queryParamsToRestQueryStringParameters(query._queryParams);\n    this.restRequest_(pathString + '.json', queryStringParameters, (error, result) => {\n      let data = result;\n\n      if (error === 404) {\n        data = null;\n        error = null;\n      }\n\n      if (error === null) {\n        this.onDataUpdate_(pathString, data,\n        /*isMerge=*/\n        false, tag);\n      }\n\n      if (safeGet(this.listens_, listenId) === thisListen) {\n        let status;\n\n        if (!error) {\n          status = 'ok';\n        } else if (error === 401) {\n          status = 'permission_denied';\n        } else {\n          status = 'rest_error:' + error;\n        }\n\n        onComplete(status, null);\n      }\n    });\n  }\n  /** @inheritDoc */\n\n\n  unlisten(query, tag) {\n    const listenId = ReadonlyRestClient.getListenId_(query, tag);\n    delete this.listens_[listenId];\n  }\n\n  get(query) {\n    const queryStringParameters = queryParamsToRestQueryStringParameters(query._queryParams);\n\n    const pathString = query._path.toString();\n\n    const deferred = new Deferred();\n    this.restRequest_(pathString + '.json', queryStringParameters, (error, result) => {\n      let data = result;\n\n      if (error === 404) {\n        data = null;\n        error = null;\n      }\n\n      if (error === null) {\n        this.onDataUpdate_(pathString, data,\n        /*isMerge=*/\n        false,\n        /*tag=*/\n        null);\n        deferred.resolve(data);\n      } else {\n        deferred.reject(new Error(data));\n      }\n    });\n    return deferred.promise;\n  }\n  /** @inheritDoc */\n\n\n  refreshAuthToken(token) {// no-op since we just always call getToken.\n  }\n  /**\r\n   * Performs a REST request to the given path, with the provided query string parameters,\r\n   * and any auth credentials we have.\r\n   */\n\n\n  restRequest_(pathString, queryStringParameters = {}, callback) {\n    queryStringParameters['format'] = 'export';\n    return Promise.all([this.authTokenProvider_.getToken(\n    /*forceRefresh=*/\n    false), this.appCheckTokenProvider_.getToken(\n    /*forceRefresh=*/\n    false)]).then(([authToken, appCheckToken]) => {\n      if (authToken && authToken.accessToken) {\n        queryStringParameters['auth'] = authToken.accessToken;\n      }\n\n      if (appCheckToken && appCheckToken.token) {\n        queryStringParameters['ac'] = appCheckToken.token;\n      }\n\n      const url = (this.repoInfo_.secure ? 'https://' : 'http://') + this.repoInfo_.host + pathString + '?' + 'ns=' + this.repoInfo_.namespace + querystring(queryStringParameters);\n      this.log_('Sending REST request for ' + url);\n      const xhr = new XMLHttpRequest();\n\n      xhr.onreadystatechange = () => {\n        if (callback && xhr.readyState === 4) {\n          this.log_('REST Response for ' + url + ' received. status:', xhr.status, 'response:', xhr.responseText);\n          let res = null;\n\n          if (xhr.status >= 200 && xhr.status < 300) {\n            try {\n              res = jsonEval(xhr.responseText);\n            } catch (e) {\n              warn('Failed to parse JSON response for ' + url + ': ' + xhr.responseText);\n            }\n\n            callback(null, res);\n          } else {\n            // 401 and 404 are expected.\n            if (xhr.status !== 401 && xhr.status !== 404) {\n              warn('Got unsuccessful REST response for ' + url + ' Status: ' + xhr.status);\n            }\n\n            callback(xhr.status);\n          }\n\n          callback = null;\n        }\n      };\n\n      xhr.open('GET', url,\n      /*asynchronous=*/\n      true);\n      xhr.send();\n    });\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Mutable object which basically just stores a reference to the \"latest\" immutable snapshot.\r\n */\n\n\nclass SnapshotHolder {\n  constructor() {\n    this.rootNode_ = ChildrenNode.EMPTY_NODE;\n  }\n\n  getNode(path) {\n    return this.rootNode_.getChild(path);\n  }\n\n  updateSnapshot(path, newSnapshotNode) {\n    this.rootNode_ = this.rootNode_.updateChild(path, newSnapshotNode);\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction newSparseSnapshotTree() {\n  return {\n    value: null,\n    children: new Map()\n  };\n}\n/**\r\n * Stores the given node at the specified path. If there is already a node\r\n * at a shallower path, it merges the new data into that snapshot node.\r\n *\r\n * @param path - Path to look up snapshot for.\r\n * @param data - The new data, or null.\r\n */\n\n\nfunction sparseSnapshotTreeRemember(sparseSnapshotTree, path, data) {\n  if (pathIsEmpty(path)) {\n    sparseSnapshotTree.value = data;\n    sparseSnapshotTree.children.clear();\n  } else if (sparseSnapshotTree.value !== null) {\n    sparseSnapshotTree.value = sparseSnapshotTree.value.updateChild(path, data);\n  } else {\n    const childKey = pathGetFront(path);\n\n    if (!sparseSnapshotTree.children.has(childKey)) {\n      sparseSnapshotTree.children.set(childKey, newSparseSnapshotTree());\n    }\n\n    const child = sparseSnapshotTree.children.get(childKey);\n    path = pathPopFront(path);\n    sparseSnapshotTreeRemember(child, path, data);\n  }\n}\n/**\r\n * Purge the data at path from the cache.\r\n *\r\n * @param path - Path to look up snapshot for.\r\n * @returns True if this node should now be removed.\r\n */\n\n\nfunction sparseSnapshotTreeForget(sparseSnapshotTree, path) {\n  if (pathIsEmpty(path)) {\n    sparseSnapshotTree.value = null;\n    sparseSnapshotTree.children.clear();\n    return true;\n  } else {\n    if (sparseSnapshotTree.value !== null) {\n      if (sparseSnapshotTree.value.isLeafNode()) {\n        // We're trying to forget a node that doesn't exist\n        return false;\n      } else {\n        const value = sparseSnapshotTree.value;\n        sparseSnapshotTree.value = null;\n        value.forEachChild(PRIORITY_INDEX, (key, tree) => {\n          sparseSnapshotTreeRemember(sparseSnapshotTree, new Path(key), tree);\n        });\n        return sparseSnapshotTreeForget(sparseSnapshotTree, path);\n      }\n    } else if (sparseSnapshotTree.children.size > 0) {\n      const childKey = pathGetFront(path);\n      path = pathPopFront(path);\n\n      if (sparseSnapshotTree.children.has(childKey)) {\n        const safeToRemove = sparseSnapshotTreeForget(sparseSnapshotTree.children.get(childKey), path);\n\n        if (safeToRemove) {\n          sparseSnapshotTree.children.delete(childKey);\n        }\n      }\n\n      return sparseSnapshotTree.children.size === 0;\n    } else {\n      return true;\n    }\n  }\n}\n/**\r\n * Recursively iterates through all of the stored tree and calls the\r\n * callback on each one.\r\n *\r\n * @param prefixPath - Path to look up node for.\r\n * @param func - The function to invoke for each tree.\r\n */\n\n\nfunction sparseSnapshotTreeForEachTree(sparseSnapshotTree, prefixPath, func) {\n  if (sparseSnapshotTree.value !== null) {\n    func(prefixPath, sparseSnapshotTree.value);\n  } else {\n    sparseSnapshotTreeForEachChild(sparseSnapshotTree, (key, tree) => {\n      const path = new Path(prefixPath.toString() + '/' + key);\n      sparseSnapshotTreeForEachTree(tree, path, func);\n    });\n  }\n}\n/**\r\n * Iterates through each immediate child and triggers the callback.\r\n * Only seems to be used in tests.\r\n *\r\n * @param func - The function to invoke for each child.\r\n */\n\n\nfunction sparseSnapshotTreeForEachChild(sparseSnapshotTree, func) {\n  sparseSnapshotTree.children.forEach((tree, key) => {\n    func(key, tree);\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Returns the delta from the previous call to get stats.\r\n *\r\n * @param collection_ - The collection to \"listen\" to.\r\n */\n\n\nclass StatsListener {\n  constructor(collection_) {\n    this.collection_ = collection_;\n    this.last_ = null;\n  }\n\n  get() {\n    const newStats = this.collection_.get();\n    const delta = Object.assign({}, newStats);\n\n    if (this.last_) {\n      each(this.last_, (stat, value) => {\n        delta[stat] = delta[stat] - value;\n      });\n    }\n\n    this.last_ = newStats;\n    return delta;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// Assuming some apps may have a short amount of time on page, and a bulk of firebase operations probably\n// happen on page load, we try to report our first set of stats pretty quickly, but we wait at least 10\n// seconds to try to ensure the Firebase connection is established / settled.\n\n\nconst FIRST_STATS_MIN_TIME = 10 * 1000;\nconst FIRST_STATS_MAX_TIME = 30 * 1000; // We'll continue to report stats on average every 5 minutes.\n\nconst REPORT_STATS_INTERVAL = 5 * 60 * 1000;\n\nclass StatsReporter {\n  constructor(collection, server_) {\n    this.server_ = server_;\n    this.statsToReport_ = {};\n    this.statsListener_ = new StatsListener(collection);\n    const timeout = FIRST_STATS_MIN_TIME + (FIRST_STATS_MAX_TIME - FIRST_STATS_MIN_TIME) * Math.random();\n    setTimeoutNonBlocking(this.reportStats_.bind(this), Math.floor(timeout));\n  }\n\n  reportStats_() {\n    const stats = this.statsListener_.get();\n    const reportedStats = {};\n    let haveStatsToReport = false;\n    each(stats, (stat, value) => {\n      if (value > 0 && contains(this.statsToReport_, stat)) {\n        reportedStats[stat] = value;\n        haveStatsToReport = true;\n      }\n    });\n\n    if (haveStatsToReport) {\n      this.server_.reportStats(reportedStats);\n    } // queue our next run.\n\n\n    setTimeoutNonBlocking(this.reportStats_.bind(this), Math.floor(Math.random() * 2 * REPORT_STATS_INTERVAL));\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n *\r\n * @enum\r\n */\n\n\nvar OperationType = /*#__PURE__*/(() => {\n  (function (OperationType) {\n    OperationType[OperationType[\"OVERWRITE\"] = 0] = \"OVERWRITE\";\n    OperationType[OperationType[\"MERGE\"] = 1] = \"MERGE\";\n    OperationType[OperationType[\"ACK_USER_WRITE\"] = 2] = \"ACK_USER_WRITE\";\n    OperationType[OperationType[\"LISTEN_COMPLETE\"] = 3] = \"LISTEN_COMPLETE\";\n  })(OperationType || (OperationType = {}));\n\n  return OperationType;\n})();\n\nfunction newOperationSourceUser() {\n  return {\n    fromUser: true,\n    fromServer: false,\n    queryId: null,\n    tagged: false\n  };\n}\n\nfunction newOperationSourceServer() {\n  return {\n    fromUser: false,\n    fromServer: true,\n    queryId: null,\n    tagged: false\n  };\n}\n\nfunction newOperationSourceServerTaggedQuery(queryId) {\n  return {\n    fromUser: false,\n    fromServer: true,\n    queryId,\n    tagged: true\n  };\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass AckUserWrite {\n  /**\r\n   * @param affectedTree - A tree containing true for each affected path. Affected paths can't overlap.\r\n   */\n  constructor(\n  /** @inheritDoc */\n  path,\n  /** @inheritDoc */\n  affectedTree,\n  /** @inheritDoc */\n  revert) {\n    this.path = path;\n    this.affectedTree = affectedTree;\n    this.revert = revert;\n    /** @inheritDoc */\n\n    this.type = OperationType.ACK_USER_WRITE;\n    /** @inheritDoc */\n\n    this.source = newOperationSourceUser();\n  }\n\n  operationForChild(childName) {\n    if (!pathIsEmpty(this.path)) {\n      assert(pathGetFront(this.path) === childName, 'operationForChild called for unrelated child.');\n      return new AckUserWrite(pathPopFront(this.path), this.affectedTree, this.revert);\n    } else if (this.affectedTree.value != null) {\n      assert(this.affectedTree.children.isEmpty(), 'affectedTree should not have overlapping affected paths.'); // All child locations are affected as well; just return same operation.\n\n      return this;\n    } else {\n      const childTree = this.affectedTree.subtree(new Path(childName));\n      return new AckUserWrite(newEmptyPath(), childTree, this.revert);\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass ListenComplete {\n  constructor(source, path) {\n    this.source = source;\n    this.path = path;\n    /** @inheritDoc */\n\n    this.type = OperationType.LISTEN_COMPLETE;\n  }\n\n  operationForChild(childName) {\n    if (pathIsEmpty(this.path)) {\n      return new ListenComplete(this.source, newEmptyPath());\n    } else {\n      return new ListenComplete(this.source, pathPopFront(this.path));\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass Overwrite {\n  constructor(source, path, snap) {\n    this.source = source;\n    this.path = path;\n    this.snap = snap;\n    /** @inheritDoc */\n\n    this.type = OperationType.OVERWRITE;\n  }\n\n  operationForChild(childName) {\n    if (pathIsEmpty(this.path)) {\n      return new Overwrite(this.source, newEmptyPath(), this.snap.getImmediateChild(childName));\n    } else {\n      return new Overwrite(this.source, pathPopFront(this.path), this.snap);\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass Merge {\n  constructor(\n  /** @inheritDoc */\n  source,\n  /** @inheritDoc */\n  path,\n  /** @inheritDoc */\n  children) {\n    this.source = source;\n    this.path = path;\n    this.children = children;\n    /** @inheritDoc */\n\n    this.type = OperationType.MERGE;\n  }\n\n  operationForChild(childName) {\n    if (pathIsEmpty(this.path)) {\n      const childTree = this.children.subtree(new Path(childName));\n\n      if (childTree.isEmpty()) {\n        // This child is unaffected\n        return null;\n      } else if (childTree.value) {\n        // We have a snapshot for the child in question.  This becomes an overwrite of the child.\n        return new Overwrite(this.source, newEmptyPath(), childTree.value);\n      } else {\n        // This is a merge at a deeper level\n        return new Merge(this.source, newEmptyPath(), childTree);\n      }\n    } else {\n      assert(pathGetFront(this.path) === childName, \"Can't get a merge for a child not on the path of the operation\");\n      return new Merge(this.source, pathPopFront(this.path), this.children);\n    }\n  }\n\n  toString() {\n    return 'Operation(' + this.path + ': ' + this.source.toString() + ' merge: ' + this.children.toString() + ')';\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A cache node only stores complete children. Additionally it holds a flag whether the node can be considered fully\r\n * initialized in the sense that we know at one point in time this represented a valid state of the world, e.g.\r\n * initialized with data from the server, or a complete overwrite by the client. The filtered flag also tracks\r\n * whether a node potentially had children removed due to a filter.\r\n */\n\n\nclass CacheNode {\n  constructor(node_, fullyInitialized_, filtered_) {\n    this.node_ = node_;\n    this.fullyInitialized_ = fullyInitialized_;\n    this.filtered_ = filtered_;\n  }\n  /**\r\n   * Returns whether this node was fully initialized with either server data or a complete overwrite by the client\r\n   */\n\n\n  isFullyInitialized() {\n    return this.fullyInitialized_;\n  }\n  /**\r\n   * Returns whether this node is potentially missing children due to a filter applied to the node\r\n   */\n\n\n  isFiltered() {\n    return this.filtered_;\n  }\n\n  isCompleteForPath(path) {\n    if (pathIsEmpty(path)) {\n      return this.isFullyInitialized() && !this.filtered_;\n    }\n\n    const childKey = pathGetFront(path);\n    return this.isCompleteForChild(childKey);\n  }\n\n  isCompleteForChild(key) {\n    return this.isFullyInitialized() && !this.filtered_ || this.node_.hasChild(key);\n  }\n\n  getNode() {\n    return this.node_;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An EventGenerator is used to convert \"raw\" changes (Change) as computed by the\r\n * CacheDiffer into actual events (Event) that can be raised.  See generateEventsForChanges()\r\n * for details.\r\n *\r\n */\n\n\nclass EventGenerator {\n  constructor(query_) {\n    this.query_ = query_;\n    this.index_ = this.query_._queryParams.getIndex();\n  }\n\n}\n/**\r\n * Given a set of raw changes (no moved events and prevName not specified yet), and a set of\r\n * EventRegistrations that should be notified of these changes, generate the actual events to be raised.\r\n *\r\n * Notes:\r\n *  - child_moved events will be synthesized at this time for any child_changed events that affect\r\n *    our index.\r\n *  - prevName will be calculated based on the index ordering.\r\n */\n\n\nfunction eventGeneratorGenerateEventsForChanges(eventGenerator, changes, eventCache, eventRegistrations) {\n  const events = [];\n  const moves = [];\n  changes.forEach(change => {\n    if (change.type === \"child_changed\"\n    /* CHILD_CHANGED */\n    && eventGenerator.index_.indexedValueChanged(change.oldSnap, change.snapshotNode)) {\n      moves.push(changeChildMoved(change.childName, change.snapshotNode));\n    }\n  });\n  eventGeneratorGenerateEventsForType(eventGenerator, events, \"child_removed\"\n  /* CHILD_REMOVED */\n  , changes, eventRegistrations, eventCache);\n  eventGeneratorGenerateEventsForType(eventGenerator, events, \"child_added\"\n  /* CHILD_ADDED */\n  , changes, eventRegistrations, eventCache);\n  eventGeneratorGenerateEventsForType(eventGenerator, events, \"child_moved\"\n  /* CHILD_MOVED */\n  , moves, eventRegistrations, eventCache);\n  eventGeneratorGenerateEventsForType(eventGenerator, events, \"child_changed\"\n  /* CHILD_CHANGED */\n  , changes, eventRegistrations, eventCache);\n  eventGeneratorGenerateEventsForType(eventGenerator, events, \"value\"\n  /* VALUE */\n  , changes, eventRegistrations, eventCache);\n  return events;\n}\n/**\r\n * Given changes of a single change type, generate the corresponding events.\r\n */\n\n\nfunction eventGeneratorGenerateEventsForType(eventGenerator, events, eventType, changes, registrations, eventCache) {\n  const filteredChanges = changes.filter(change => change.type === eventType);\n  filteredChanges.sort((a, b) => eventGeneratorCompareChanges(eventGenerator, a, b));\n  filteredChanges.forEach(change => {\n    const materializedChange = eventGeneratorMaterializeSingleChange(eventGenerator, change, eventCache);\n    registrations.forEach(registration => {\n      if (registration.respondsTo(change.type)) {\n        events.push(registration.createEvent(materializedChange, eventGenerator.query_));\n      }\n    });\n  });\n}\n\nfunction eventGeneratorMaterializeSingleChange(eventGenerator, change, eventCache) {\n  if (change.type === 'value' || change.type === 'child_removed') {\n    return change;\n  } else {\n    change.prevName = eventCache.getPredecessorChildName(change.childName, change.snapshotNode, eventGenerator.index_);\n    return change;\n  }\n}\n\nfunction eventGeneratorCompareChanges(eventGenerator, a, b) {\n  if (a.childName == null || b.childName == null) {\n    throw assertionError('Should only compare child_ events.');\n  }\n\n  const aWrapped = new NamedNode(a.childName, a.snapshotNode);\n  const bWrapped = new NamedNode(b.childName, b.snapshotNode);\n  return eventGenerator.index_.compare(aWrapped, bWrapped);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction newViewCache(eventCache, serverCache) {\n  return {\n    eventCache,\n    serverCache\n  };\n}\n\nfunction viewCacheUpdateEventSnap(viewCache, eventSnap, complete, filtered) {\n  return newViewCache(new CacheNode(eventSnap, complete, filtered), viewCache.serverCache);\n}\n\nfunction viewCacheUpdateServerSnap(viewCache, serverSnap, complete, filtered) {\n  return newViewCache(viewCache.eventCache, new CacheNode(serverSnap, complete, filtered));\n}\n\nfunction viewCacheGetCompleteEventSnap(viewCache) {\n  return viewCache.eventCache.isFullyInitialized() ? viewCache.eventCache.getNode() : null;\n}\n\nfunction viewCacheGetCompleteServerSnap(viewCache) {\n  return viewCache.serverCache.isFullyInitialized() ? viewCache.serverCache.getNode() : null;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet emptyChildrenSingleton;\n/**\r\n * Singleton empty children collection.\r\n *\r\n */\n\nconst EmptyChildren = () => {\n  if (!emptyChildrenSingleton) {\n    emptyChildrenSingleton = new SortedMap(stringCompare);\n  }\n\n  return emptyChildrenSingleton;\n};\n/**\r\n * A tree with immutable elements.\r\n */\n\n\nclass ImmutableTree {\n  constructor(value, children = EmptyChildren()) {\n    this.value = value;\n    this.children = children;\n  }\n\n  static fromObject(obj) {\n    let tree = new ImmutableTree(null);\n    each(obj, (childPath, childSnap) => {\n      tree = tree.set(new Path(childPath), childSnap);\n    });\n    return tree;\n  }\n  /**\r\n   * True if the value is empty and there are no children\r\n   */\n\n\n  isEmpty() {\n    return this.value === null && this.children.isEmpty();\n  }\n  /**\r\n   * Given a path and predicate, return the first node and the path to that node\r\n   * where the predicate returns true.\r\n   *\r\n   * TODO Do a perf test -- If we're creating a bunch of `{path: value:}`\r\n   * objects on the way back out, it may be better to pass down a pathSoFar obj.\r\n   *\r\n   * @param relativePath - The remainder of the path\r\n   * @param predicate - The predicate to satisfy to return a node\r\n   */\n\n\n  findRootMostMatchingPathAndValue(relativePath, predicate) {\n    if (this.value != null && predicate(this.value)) {\n      return {\n        path: newEmptyPath(),\n        value: this.value\n      };\n    } else {\n      if (pathIsEmpty(relativePath)) {\n        return null;\n      } else {\n        const front = pathGetFront(relativePath);\n        const child = this.children.get(front);\n\n        if (child !== null) {\n          const childExistingPathAndValue = child.findRootMostMatchingPathAndValue(pathPopFront(relativePath), predicate);\n\n          if (childExistingPathAndValue != null) {\n            const fullPath = pathChild(new Path(front), childExistingPathAndValue.path);\n            return {\n              path: fullPath,\n              value: childExistingPathAndValue.value\n            };\n          } else {\n            return null;\n          }\n        } else {\n          return null;\n        }\n      }\n    }\n  }\n  /**\r\n   * Find, if it exists, the shortest subpath of the given path that points a defined\r\n   * value in the tree\r\n   */\n\n\n  findRootMostValueAndPath(relativePath) {\n    return this.findRootMostMatchingPathAndValue(relativePath, () => true);\n  }\n  /**\r\n   * @returns The subtree at the given path\r\n   */\n\n\n  subtree(relativePath) {\n    if (pathIsEmpty(relativePath)) {\n      return this;\n    } else {\n      const front = pathGetFront(relativePath);\n      const childTree = this.children.get(front);\n\n      if (childTree !== null) {\n        return childTree.subtree(pathPopFront(relativePath));\n      } else {\n        return new ImmutableTree(null);\n      }\n    }\n  }\n  /**\r\n   * Sets a value at the specified path.\r\n   *\r\n   * @param relativePath - Path to set value at.\r\n   * @param toSet - Value to set.\r\n   * @returns Resulting tree.\r\n   */\n\n\n  set(relativePath, toSet) {\n    if (pathIsEmpty(relativePath)) {\n      return new ImmutableTree(toSet, this.children);\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front) || new ImmutableTree(null);\n      const newChild = child.set(pathPopFront(relativePath), toSet);\n      const newChildren = this.children.insert(front, newChild);\n      return new ImmutableTree(this.value, newChildren);\n    }\n  }\n  /**\r\n   * Removes the value at the specified path.\r\n   *\r\n   * @param relativePath - Path to value to remove.\r\n   * @returns Resulting tree.\r\n   */\n\n\n  remove(relativePath) {\n    if (pathIsEmpty(relativePath)) {\n      if (this.children.isEmpty()) {\n        return new ImmutableTree(null);\n      } else {\n        return new ImmutableTree(null, this.children);\n      }\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front);\n\n      if (child) {\n        const newChild = child.remove(pathPopFront(relativePath));\n        let newChildren;\n\n        if (newChild.isEmpty()) {\n          newChildren = this.children.remove(front);\n        } else {\n          newChildren = this.children.insert(front, newChild);\n        }\n\n        if (this.value === null && newChildren.isEmpty()) {\n          return new ImmutableTree(null);\n        } else {\n          return new ImmutableTree(this.value, newChildren);\n        }\n      } else {\n        return this;\n      }\n    }\n  }\n  /**\r\n   * Gets a value from the tree.\r\n   *\r\n   * @param relativePath - Path to get value for.\r\n   * @returns Value at path, or null.\r\n   */\n\n\n  get(relativePath) {\n    if (pathIsEmpty(relativePath)) {\n      return this.value;\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front);\n\n      if (child) {\n        return child.get(pathPopFront(relativePath));\n      } else {\n        return null;\n      }\n    }\n  }\n  /**\r\n   * Replace the subtree at the specified path with the given new tree.\r\n   *\r\n   * @param relativePath - Path to replace subtree for.\r\n   * @param newTree - New tree.\r\n   * @returns Resulting tree.\r\n   */\n\n\n  setTree(relativePath, newTree) {\n    if (pathIsEmpty(relativePath)) {\n      return newTree;\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front) || new ImmutableTree(null);\n      const newChild = child.setTree(pathPopFront(relativePath), newTree);\n      let newChildren;\n\n      if (newChild.isEmpty()) {\n        newChildren = this.children.remove(front);\n      } else {\n        newChildren = this.children.insert(front, newChild);\n      }\n\n      return new ImmutableTree(this.value, newChildren);\n    }\n  }\n  /**\r\n   * Performs a depth first fold on this tree. Transforms a tree into a single\r\n   * value, given a function that operates on the path to a node, an optional\r\n   * current value, and a map of child names to folded subtrees\r\n   */\n\n\n  fold(fn) {\n    return this.fold_(newEmptyPath(), fn);\n  }\n  /**\r\n   * Recursive helper for public-facing fold() method\r\n   */\n\n\n  fold_(pathSoFar, fn) {\n    const accum = {};\n    this.children.inorderTraversal((childKey, childTree) => {\n      accum[childKey] = childTree.fold_(pathChild(pathSoFar, childKey), fn);\n    });\n    return fn(pathSoFar, this.value, accum);\n  }\n  /**\r\n   * Find the first matching value on the given path. Return the result of applying f to it.\r\n   */\n\n\n  findOnPath(path, f) {\n    return this.findOnPath_(path, newEmptyPath(), f);\n  }\n\n  findOnPath_(pathToFollow, pathSoFar, f) {\n    const result = this.value ? f(pathSoFar, this.value) : false;\n\n    if (result) {\n      return result;\n    } else {\n      if (pathIsEmpty(pathToFollow)) {\n        return null;\n      } else {\n        const front = pathGetFront(pathToFollow);\n        const nextChild = this.children.get(front);\n\n        if (nextChild) {\n          return nextChild.findOnPath_(pathPopFront(pathToFollow), pathChild(pathSoFar, front), f);\n        } else {\n          return null;\n        }\n      }\n    }\n  }\n\n  foreachOnPath(path, f) {\n    return this.foreachOnPath_(path, newEmptyPath(), f);\n  }\n\n  foreachOnPath_(pathToFollow, currentRelativePath, f) {\n    if (pathIsEmpty(pathToFollow)) {\n      return this;\n    } else {\n      if (this.value) {\n        f(currentRelativePath, this.value);\n      }\n\n      const front = pathGetFront(pathToFollow);\n      const nextChild = this.children.get(front);\n\n      if (nextChild) {\n        return nextChild.foreachOnPath_(pathPopFront(pathToFollow), pathChild(currentRelativePath, front), f);\n      } else {\n        return new ImmutableTree(null);\n      }\n    }\n  }\n  /**\r\n   * Calls the given function for each node in the tree that has a value.\r\n   *\r\n   * @param f - A function to be called with the path from the root of the tree to\r\n   * a node, and the value at that node. Called in depth-first order.\r\n   */\n\n\n  foreach(f) {\n    this.foreach_(newEmptyPath(), f);\n  }\n\n  foreach_(currentRelativePath, f) {\n    this.children.inorderTraversal((childName, childTree) => {\n      childTree.foreach_(pathChild(currentRelativePath, childName), f);\n    });\n\n    if (this.value) {\n      f(currentRelativePath, this.value);\n    }\n  }\n\n  foreachChild(f) {\n    this.children.inorderTraversal((childName, childTree) => {\n      if (childTree.value) {\n        f(childName, childTree.value);\n      }\n    });\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * This class holds a collection of writes that can be applied to nodes in unison. It abstracts away the logic with\r\n * dealing with priority writes and multiple nested writes. At any given path there is only allowed to be one write\r\n * modifying that path. Any write to an existing path or shadowing an existing path will modify that existing write\r\n * to reflect the write added.\r\n */\n\n\nclass CompoundWrite {\n  constructor(writeTree_) {\n    this.writeTree_ = writeTree_;\n  }\n\n  static empty() {\n    return new CompoundWrite(new ImmutableTree(null));\n  }\n\n}\n\nfunction compoundWriteAddWrite(compoundWrite, path, node) {\n  if (pathIsEmpty(path)) {\n    return new CompoundWrite(new ImmutableTree(node));\n  } else {\n    const rootmost = compoundWrite.writeTree_.findRootMostValueAndPath(path);\n\n    if (rootmost != null) {\n      const rootMostPath = rootmost.path;\n      let value = rootmost.value;\n      const relativePath = newRelativePath(rootMostPath, path);\n      value = value.updateChild(relativePath, node);\n      return new CompoundWrite(compoundWrite.writeTree_.set(rootMostPath, value));\n    } else {\n      const subtree = new ImmutableTree(node);\n      const newWriteTree = compoundWrite.writeTree_.setTree(path, subtree);\n      return new CompoundWrite(newWriteTree);\n    }\n  }\n}\n\nfunction compoundWriteAddWrites(compoundWrite, path, updates) {\n  let newWrite = compoundWrite;\n  each(updates, (childKey, node) => {\n    newWrite = compoundWriteAddWrite(newWrite, pathChild(path, childKey), node);\n  });\n  return newWrite;\n}\n/**\r\n * Will remove a write at the given path and deeper paths. This will <em>not</em> modify a write at a higher\r\n * location, which must be removed by calling this method with that path.\r\n *\r\n * @param compoundWrite - The CompoundWrite to remove.\r\n * @param path - The path at which a write and all deeper writes should be removed\r\n * @returns The new CompoundWrite with the removed path\r\n */\n\n\nfunction compoundWriteRemoveWrite(compoundWrite, path) {\n  if (pathIsEmpty(path)) {\n    return CompoundWrite.empty();\n  } else {\n    const newWriteTree = compoundWrite.writeTree_.setTree(path, new ImmutableTree(null));\n    return new CompoundWrite(newWriteTree);\n  }\n}\n/**\r\n * Returns whether this CompoundWrite will fully overwrite a node at a given location and can therefore be\r\n * considered \"complete\".\r\n *\r\n * @param compoundWrite - The CompoundWrite to check.\r\n * @param path - The path to check for\r\n * @returns Whether there is a complete write at that path\r\n */\n\n\nfunction compoundWriteHasCompleteWrite(compoundWrite, path) {\n  return compoundWriteGetCompleteNode(compoundWrite, path) != null;\n}\n/**\r\n * Returns a node for a path if and only if the node is a \"complete\" overwrite at that path. This will not aggregate\r\n * writes from deeper paths, but will return child nodes from a more shallow path.\r\n *\r\n * @param compoundWrite - The CompoundWrite to get the node from.\r\n * @param path - The path to get a complete write\r\n * @returns The node if complete at that path, or null otherwise.\r\n */\n\n\nfunction compoundWriteGetCompleteNode(compoundWrite, path) {\n  const rootmost = compoundWrite.writeTree_.findRootMostValueAndPath(path);\n\n  if (rootmost != null) {\n    return compoundWrite.writeTree_.get(rootmost.path).getChild(newRelativePath(rootmost.path, path));\n  } else {\n    return null;\n  }\n}\n/**\r\n * Returns all children that are guaranteed to be a complete overwrite.\r\n *\r\n * @param compoundWrite - The CompoundWrite to get children from.\r\n * @returns A list of all complete children.\r\n */\n\n\nfunction compoundWriteGetCompleteChildren(compoundWrite) {\n  const children = [];\n  const node = compoundWrite.writeTree_.value;\n\n  if (node != null) {\n    // If it's a leaf node, it has no children; so nothing to do.\n    if (!node.isLeafNode()) {\n      node.forEachChild(PRIORITY_INDEX, (childName, childNode) => {\n        children.push(new NamedNode(childName, childNode));\n      });\n    }\n  } else {\n    compoundWrite.writeTree_.children.inorderTraversal((childName, childTree) => {\n      if (childTree.value != null) {\n        children.push(new NamedNode(childName, childTree.value));\n      }\n    });\n  }\n\n  return children;\n}\n\nfunction compoundWriteChildCompoundWrite(compoundWrite, path) {\n  if (pathIsEmpty(path)) {\n    return compoundWrite;\n  } else {\n    const shadowingNode = compoundWriteGetCompleteNode(compoundWrite, path);\n\n    if (shadowingNode != null) {\n      return new CompoundWrite(new ImmutableTree(shadowingNode));\n    } else {\n      return new CompoundWrite(compoundWrite.writeTree_.subtree(path));\n    }\n  }\n}\n/**\r\n * Returns true if this CompoundWrite is empty and therefore does not modify any nodes.\r\n * @returns Whether this CompoundWrite is empty\r\n */\n\n\nfunction compoundWriteIsEmpty(compoundWrite) {\n  return compoundWrite.writeTree_.isEmpty();\n}\n/**\r\n * Applies this CompoundWrite to a node. The node is returned with all writes from this CompoundWrite applied to the\r\n * node\r\n * @param node - The node to apply this CompoundWrite to\r\n * @returns The node with all writes applied\r\n */\n\n\nfunction compoundWriteApply(compoundWrite, node) {\n  return applySubtreeWrite(newEmptyPath(), compoundWrite.writeTree_, node);\n}\n\nfunction applySubtreeWrite(relativePath, writeTree, node) {\n  if (writeTree.value != null) {\n    // Since there a write is always a leaf, we're done here\n    return node.updateChild(relativePath, writeTree.value);\n  } else {\n    let priorityWrite = null;\n    writeTree.children.inorderTraversal((childKey, childTree) => {\n      if (childKey === '.priority') {\n        // Apply priorities at the end so we don't update priorities for either empty nodes or forget\n        // to apply priorities to empty nodes that are later filled\n        assert(childTree.value !== null, 'Priority writes must always be leaf nodes');\n        priorityWrite = childTree.value;\n      } else {\n        node = applySubtreeWrite(pathChild(relativePath, childKey), childTree, node);\n      }\n    }); // If there was a priority write, we only apply it if the node is not empty\n\n    if (!node.getChild(relativePath).isEmpty() && priorityWrite !== null) {\n      node = node.updateChild(pathChild(relativePath, '.priority'), priorityWrite);\n    }\n\n    return node;\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Create a new WriteTreeRef for the given path. For use with a new sync point at the given path.\r\n *\r\n */\n\n\nfunction writeTreeChildWrites(writeTree, path) {\n  return newWriteTreeRef(path, writeTree);\n}\n/**\r\n * Record a new overwrite from user code.\r\n *\r\n * @param visible - This is set to false by some transactions. It should be excluded from event caches\r\n */\n\n\nfunction writeTreeAddOverwrite(writeTree, path, snap, writeId, visible) {\n  assert(writeId > writeTree.lastWriteId, 'Stacking an older write on top of newer ones');\n\n  if (visible === undefined) {\n    visible = true;\n  }\n\n  writeTree.allWrites.push({\n    path,\n    snap,\n    writeId,\n    visible\n  });\n\n  if (visible) {\n    writeTree.visibleWrites = compoundWriteAddWrite(writeTree.visibleWrites, path, snap);\n  }\n\n  writeTree.lastWriteId = writeId;\n}\n/**\r\n * Record a new merge from user code.\r\n */\n\n\nfunction writeTreeAddMerge(writeTree, path, changedChildren, writeId) {\n  assert(writeId > writeTree.lastWriteId, 'Stacking an older merge on top of newer ones');\n  writeTree.allWrites.push({\n    path,\n    children: changedChildren,\n    writeId,\n    visible: true\n  });\n  writeTree.visibleWrites = compoundWriteAddWrites(writeTree.visibleWrites, path, changedChildren);\n  writeTree.lastWriteId = writeId;\n}\n\nfunction writeTreeGetWrite(writeTree, writeId) {\n  for (let i = 0; i < writeTree.allWrites.length; i++) {\n    const record = writeTree.allWrites[i];\n\n    if (record.writeId === writeId) {\n      return record;\n    }\n  }\n\n  return null;\n}\n/**\r\n * Remove a write (either an overwrite or merge) that has been successfully acknowledge by the server. Recalculates\r\n * the tree if necessary.  We return true if it may have been visible, meaning views need to reevaluate.\r\n *\r\n * @returns true if the write may have been visible (meaning we'll need to reevaluate / raise\r\n * events as a result).\r\n */\n\n\nfunction writeTreeRemoveWrite(writeTree, writeId) {\n  // Note: disabling this check. It could be a transaction that preempted another transaction, and thus was applied\n  // out of order.\n  //const validClear = revert || this.allWrites_.length === 0 || writeId <= this.allWrites_[0].writeId;\n  //assert(validClear, \"Either we don't have this write, or it's the first one in the queue\");\n  const idx = writeTree.allWrites.findIndex(s => {\n    return s.writeId === writeId;\n  });\n  assert(idx >= 0, 'removeWrite called with nonexistent writeId.');\n  const writeToRemove = writeTree.allWrites[idx];\n  writeTree.allWrites.splice(idx, 1);\n  let removedWriteWasVisible = writeToRemove.visible;\n  let removedWriteOverlapsWithOtherWrites = false;\n  let i = writeTree.allWrites.length - 1;\n\n  while (removedWriteWasVisible && i >= 0) {\n    const currentWrite = writeTree.allWrites[i];\n\n    if (currentWrite.visible) {\n      if (i >= idx && writeTreeRecordContainsPath_(currentWrite, writeToRemove.path)) {\n        // The removed write was completely shadowed by a subsequent write.\n        removedWriteWasVisible = false;\n      } else if (pathContains(writeToRemove.path, currentWrite.path)) {\n        // Either we're covering some writes or they're covering part of us (depending on which came first).\n        removedWriteOverlapsWithOtherWrites = true;\n      }\n    }\n\n    i--;\n  }\n\n  if (!removedWriteWasVisible) {\n    return false;\n  } else if (removedWriteOverlapsWithOtherWrites) {\n    // There's some shadowing going on. Just rebuild the visible writes from scratch.\n    writeTreeResetTree_(writeTree);\n    return true;\n  } else {\n    // There's no shadowing.  We can safely just remove the write(s) from visibleWrites.\n    if (writeToRemove.snap) {\n      writeTree.visibleWrites = compoundWriteRemoveWrite(writeTree.visibleWrites, writeToRemove.path);\n    } else {\n      const children = writeToRemove.children;\n      each(children, childName => {\n        writeTree.visibleWrites = compoundWriteRemoveWrite(writeTree.visibleWrites, pathChild(writeToRemove.path, childName));\n      });\n    }\n\n    return true;\n  }\n}\n\nfunction writeTreeRecordContainsPath_(writeRecord, path) {\n  if (writeRecord.snap) {\n    return pathContains(writeRecord.path, path);\n  } else {\n    for (const childName in writeRecord.children) {\n      if (writeRecord.children.hasOwnProperty(childName) && pathContains(pathChild(writeRecord.path, childName), path)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n}\n/**\r\n * Re-layer the writes and merges into a tree so we can efficiently calculate event snapshots\r\n */\n\n\nfunction writeTreeResetTree_(writeTree) {\n  writeTree.visibleWrites = writeTreeLayerTree_(writeTree.allWrites, writeTreeDefaultFilter_, newEmptyPath());\n\n  if (writeTree.allWrites.length > 0) {\n    writeTree.lastWriteId = writeTree.allWrites[writeTree.allWrites.length - 1].writeId;\n  } else {\n    writeTree.lastWriteId = -1;\n  }\n}\n/**\r\n * The default filter used when constructing the tree. Keep everything that's visible.\r\n */\n\n\nfunction writeTreeDefaultFilter_(write) {\n  return write.visible;\n}\n/**\r\n * Static method. Given an array of WriteRecords, a filter for which ones to include, and a path, construct the tree of\r\n * event data at that path.\r\n */\n\n\nfunction writeTreeLayerTree_(writes, filter, treeRoot) {\n  let compoundWrite = CompoundWrite.empty();\n\n  for (let i = 0; i < writes.length; ++i) {\n    const write = writes[i]; // Theory, a later set will either:\n    // a) abort a relevant transaction, so no need to worry about excluding it from calculating that transaction\n    // b) not be relevant to a transaction (separate branch), so again will not affect the data for that transaction\n\n    if (filter(write)) {\n      const writePath = write.path;\n      let relativePath;\n\n      if (write.snap) {\n        if (pathContains(treeRoot, writePath)) {\n          relativePath = newRelativePath(treeRoot, writePath);\n          compoundWrite = compoundWriteAddWrite(compoundWrite, relativePath, write.snap);\n        } else if (pathContains(writePath, treeRoot)) {\n          relativePath = newRelativePath(writePath, treeRoot);\n          compoundWrite = compoundWriteAddWrite(compoundWrite, newEmptyPath(), write.snap.getChild(relativePath));\n        } else ;\n      } else if (write.children) {\n        if (pathContains(treeRoot, writePath)) {\n          relativePath = newRelativePath(treeRoot, writePath);\n          compoundWrite = compoundWriteAddWrites(compoundWrite, relativePath, write.children);\n        } else if (pathContains(writePath, treeRoot)) {\n          relativePath = newRelativePath(writePath, treeRoot);\n\n          if (pathIsEmpty(relativePath)) {\n            compoundWrite = compoundWriteAddWrites(compoundWrite, newEmptyPath(), write.children);\n          } else {\n            const child = safeGet(write.children, pathGetFront(relativePath));\n\n            if (child) {\n              // There exists a child in this node that matches the root path\n              const deepNode = child.getChild(pathPopFront(relativePath));\n              compoundWrite = compoundWriteAddWrite(compoundWrite, newEmptyPath(), deepNode);\n            }\n          }\n        } else ;\n      } else {\n        throw assertionError('WriteRecord should have .snap or .children');\n      }\n    }\n  }\n\n  return compoundWrite;\n}\n/**\r\n * Given optional, underlying server data, and an optional set of constraints (exclude some sets, include hidden\r\n * writes), attempt to calculate a complete snapshot for the given path\r\n *\r\n * @param writeIdsToExclude - An optional set to be excluded\r\n * @param includeHiddenWrites - Defaults to false, whether or not to layer on writes with visible set to false\r\n */\n\n\nfunction writeTreeCalcCompleteEventCache(writeTree, treePath, completeServerCache, writeIdsToExclude, includeHiddenWrites) {\n  if (!writeIdsToExclude && !includeHiddenWrites) {\n    const shadowingNode = compoundWriteGetCompleteNode(writeTree.visibleWrites, treePath);\n\n    if (shadowingNode != null) {\n      return shadowingNode;\n    } else {\n      const subMerge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, treePath);\n\n      if (compoundWriteIsEmpty(subMerge)) {\n        return completeServerCache;\n      } else if (completeServerCache == null && !compoundWriteHasCompleteWrite(subMerge, newEmptyPath())) {\n        // We wouldn't have a complete snapshot, since there's no underlying data and no complete shadow\n        return null;\n      } else {\n        const layeredCache = completeServerCache || ChildrenNode.EMPTY_NODE;\n        return compoundWriteApply(subMerge, layeredCache);\n      }\n    }\n  } else {\n    const merge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, treePath);\n\n    if (!includeHiddenWrites && compoundWriteIsEmpty(merge)) {\n      return completeServerCache;\n    } else {\n      // If the server cache is null, and we don't have a complete cache, we need to return null\n      if (!includeHiddenWrites && completeServerCache == null && !compoundWriteHasCompleteWrite(merge, newEmptyPath())) {\n        return null;\n      } else {\n        const filter = function (write) {\n          return (write.visible || includeHiddenWrites) && (!writeIdsToExclude || !~writeIdsToExclude.indexOf(write.writeId)) && (pathContains(write.path, treePath) || pathContains(treePath, write.path));\n        };\n\n        const mergeAtPath = writeTreeLayerTree_(writeTree.allWrites, filter, treePath);\n        const layeredCache = completeServerCache || ChildrenNode.EMPTY_NODE;\n        return compoundWriteApply(mergeAtPath, layeredCache);\n      }\n    }\n  }\n}\n/**\r\n * With optional, underlying server data, attempt to return a children node of children that we have complete data for.\r\n * Used when creating new views, to pre-fill their complete event children snapshot.\r\n */\n\n\nfunction writeTreeCalcCompleteEventChildren(writeTree, treePath, completeServerChildren) {\n  let completeChildren = ChildrenNode.EMPTY_NODE;\n  const topLevelSet = compoundWriteGetCompleteNode(writeTree.visibleWrites, treePath);\n\n  if (topLevelSet) {\n    if (!topLevelSet.isLeafNode()) {\n      // we're shadowing everything. Return the children.\n      topLevelSet.forEachChild(PRIORITY_INDEX, (childName, childSnap) => {\n        completeChildren = completeChildren.updateImmediateChild(childName, childSnap);\n      });\n    }\n\n    return completeChildren;\n  } else if (completeServerChildren) {\n    // Layer any children we have on top of this\n    // We know we don't have a top-level set, so just enumerate existing children\n    const merge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, treePath);\n    completeServerChildren.forEachChild(PRIORITY_INDEX, (childName, childNode) => {\n      const node = compoundWriteApply(compoundWriteChildCompoundWrite(merge, new Path(childName)), childNode);\n      completeChildren = completeChildren.updateImmediateChild(childName, node);\n    }); // Add any complete children we have from the set\n\n    compoundWriteGetCompleteChildren(merge).forEach(namedNode => {\n      completeChildren = completeChildren.updateImmediateChild(namedNode.name, namedNode.node);\n    });\n    return completeChildren;\n  } else {\n    // We don't have anything to layer on top of. Layer on any children we have\n    // Note that we can return an empty snap if we have a defined delete\n    const merge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, treePath);\n    compoundWriteGetCompleteChildren(merge).forEach(namedNode => {\n      completeChildren = completeChildren.updateImmediateChild(namedNode.name, namedNode.node);\n    });\n    return completeChildren;\n  }\n}\n/**\r\n * Given that the underlying server data has updated, determine what, if anything, needs to be\r\n * applied to the event cache.\r\n *\r\n * Possibilities:\r\n *\r\n * 1. No writes are shadowing. Events should be raised, the snap to be applied comes from the server data\r\n *\r\n * 2. Some write is completely shadowing. No events to be raised\r\n *\r\n * 3. Is partially shadowed. Events\r\n *\r\n * Either existingEventSnap or existingServerSnap must exist\r\n */\n\n\nfunction writeTreeCalcEventCacheAfterServerOverwrite(writeTree, treePath, childPath, existingEventSnap, existingServerSnap) {\n  assert(existingEventSnap || existingServerSnap, 'Either existingEventSnap or existingServerSnap must exist');\n  const path = pathChild(treePath, childPath);\n\n  if (compoundWriteHasCompleteWrite(writeTree.visibleWrites, path)) {\n    // At this point we can probably guarantee that we're in case 2, meaning no events\n    // May need to check visibility while doing the findRootMostValueAndPath call\n    return null;\n  } else {\n    // No complete shadowing. We're either partially shadowing or not shadowing at all.\n    const childMerge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, path);\n\n    if (compoundWriteIsEmpty(childMerge)) {\n      // We're not shadowing at all. Case 1\n      return existingServerSnap.getChild(childPath);\n    } else {\n      // This could be more efficient if the serverNode + updates doesn't change the eventSnap\n      // However this is tricky to find out, since user updates don't necessary change the server\n      // snap, e.g. priority updates on empty nodes, or deep deletes. Another special case is if the server\n      // adds nodes, but doesn't change any existing writes. It is therefore not enough to\n      // only check if the updates change the serverNode.\n      // Maybe check if the merge tree contains these special cases and only do a full overwrite in that case?\n      return compoundWriteApply(childMerge, existingServerSnap.getChild(childPath));\n    }\n  }\n}\n/**\r\n * Returns a complete child for a given server snap after applying all user writes or null if there is no\r\n * complete child for this ChildKey.\r\n */\n\n\nfunction writeTreeCalcCompleteChild(writeTree, treePath, childKey, existingServerSnap) {\n  const path = pathChild(treePath, childKey);\n  const shadowingNode = compoundWriteGetCompleteNode(writeTree.visibleWrites, path);\n\n  if (shadowingNode != null) {\n    return shadowingNode;\n  } else {\n    if (existingServerSnap.isCompleteForChild(childKey)) {\n      const childMerge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, path);\n      return compoundWriteApply(childMerge, existingServerSnap.getNode().getImmediateChild(childKey));\n    } else {\n      return null;\n    }\n  }\n}\n/**\r\n * Returns a node if there is a complete overwrite for this path. More specifically, if there is a write at\r\n * a higher path, this will return the child of that write relative to the write and this path.\r\n * Returns null if there is no write at this path.\r\n */\n\n\nfunction writeTreeShadowingWrite(writeTree, path) {\n  return compoundWriteGetCompleteNode(writeTree.visibleWrites, path);\n}\n/**\r\n * This method is used when processing child remove events on a query. If we can, we pull in children that were outside\r\n * the window, but may now be in the window.\r\n */\n\n\nfunction writeTreeCalcIndexedSlice(writeTree, treePath, completeServerData, startPost, count, reverse, index) {\n  let toIterate;\n  const merge = compoundWriteChildCompoundWrite(writeTree.visibleWrites, treePath);\n  const shadowingNode = compoundWriteGetCompleteNode(merge, newEmptyPath());\n\n  if (shadowingNode != null) {\n    toIterate = shadowingNode;\n  } else if (completeServerData != null) {\n    toIterate = compoundWriteApply(merge, completeServerData);\n  } else {\n    // no children to iterate on\n    return [];\n  }\n\n  toIterate = toIterate.withIndex(index);\n\n  if (!toIterate.isEmpty() && !toIterate.isLeafNode()) {\n    const nodes = [];\n    const cmp = index.getCompare();\n    const iter = reverse ? toIterate.getReverseIteratorFrom(startPost, index) : toIterate.getIteratorFrom(startPost, index);\n    let next = iter.getNext();\n\n    while (next && nodes.length < count) {\n      if (cmp(next, startPost) !== 0) {\n        nodes.push(next);\n      }\n\n      next = iter.getNext();\n    }\n\n    return nodes;\n  } else {\n    return [];\n  }\n}\n\nfunction newWriteTree() {\n  return {\n    visibleWrites: CompoundWrite.empty(),\n    allWrites: [],\n    lastWriteId: -1\n  };\n}\n/**\r\n * If possible, returns a complete event cache, using the underlying server data if possible. In addition, can be used\r\n * to get a cache that includes hidden writes, and excludes arbitrary writes. Note that customizing the returned node\r\n * can lead to a more expensive calculation.\r\n *\r\n * @param writeIdsToExclude - Optional writes to exclude.\r\n * @param includeHiddenWrites - Defaults to false, whether or not to layer on writes with visible set to false\r\n */\n\n\nfunction writeTreeRefCalcCompleteEventCache(writeTreeRef, completeServerCache, writeIdsToExclude, includeHiddenWrites) {\n  return writeTreeCalcCompleteEventCache(writeTreeRef.writeTree, writeTreeRef.treePath, completeServerCache, writeIdsToExclude, includeHiddenWrites);\n}\n/**\r\n * If possible, returns a children node containing all of the complete children we have data for. The returned data is a\r\n * mix of the given server data and write data.\r\n *\r\n */\n\n\nfunction writeTreeRefCalcCompleteEventChildren(writeTreeRef, completeServerChildren) {\n  return writeTreeCalcCompleteEventChildren(writeTreeRef.writeTree, writeTreeRef.treePath, completeServerChildren);\n}\n/**\r\n * Given that either the underlying server data has updated or the outstanding writes have updated, determine what,\r\n * if anything, needs to be applied to the event cache.\r\n *\r\n * Possibilities:\r\n *\r\n * 1. No writes are shadowing. Events should be raised, the snap to be applied comes from the server data\r\n *\r\n * 2. Some write is completely shadowing. No events to be raised\r\n *\r\n * 3. Is partially shadowed. Events should be raised\r\n *\r\n * Either existingEventSnap or existingServerSnap must exist, this is validated via an assert\r\n *\r\n *\r\n */\n\n\nfunction writeTreeRefCalcEventCacheAfterServerOverwrite(writeTreeRef, path, existingEventSnap, existingServerSnap) {\n  return writeTreeCalcEventCacheAfterServerOverwrite(writeTreeRef.writeTree, writeTreeRef.treePath, path, existingEventSnap, existingServerSnap);\n}\n/**\r\n * Returns a node if there is a complete overwrite for this path. More specifically, if there is a write at\r\n * a higher path, this will return the child of that write relative to the write and this path.\r\n * Returns null if there is no write at this path.\r\n *\r\n */\n\n\nfunction writeTreeRefShadowingWrite(writeTreeRef, path) {\n  return writeTreeShadowingWrite(writeTreeRef.writeTree, pathChild(writeTreeRef.treePath, path));\n}\n/**\r\n * This method is used when processing child remove events on a query. If we can, we pull in children that were outside\r\n * the window, but may now be in the window\r\n */\n\n\nfunction writeTreeRefCalcIndexedSlice(writeTreeRef, completeServerData, startPost, count, reverse, index) {\n  return writeTreeCalcIndexedSlice(writeTreeRef.writeTree, writeTreeRef.treePath, completeServerData, startPost, count, reverse, index);\n}\n/**\r\n * Returns a complete child for a given server snap after applying all user writes or null if there is no\r\n * complete child for this ChildKey.\r\n */\n\n\nfunction writeTreeRefCalcCompleteChild(writeTreeRef, childKey, existingServerCache) {\n  return writeTreeCalcCompleteChild(writeTreeRef.writeTree, writeTreeRef.treePath, childKey, existingServerCache);\n}\n/**\r\n * Return a WriteTreeRef for a child.\r\n */\n\n\nfunction writeTreeRefChild(writeTreeRef, childName) {\n  return newWriteTreeRef(pathChild(writeTreeRef.treePath, childName), writeTreeRef.writeTree);\n}\n\nfunction newWriteTreeRef(path, writeTree) {\n  return {\n    treePath: path,\n    writeTree\n  };\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass ChildChangeAccumulator {\n  constructor() {\n    this.changeMap = new Map();\n  }\n\n  trackChildChange(change) {\n    const type = change.type;\n    const childKey = change.childName;\n    assert(type === \"child_added\"\n    /* CHILD_ADDED */\n    || type === \"child_changed\"\n    /* CHILD_CHANGED */\n    || type === \"child_removed\"\n    /* CHILD_REMOVED */\n    , 'Only child changes supported for tracking');\n    assert(childKey !== '.priority', 'Only non-priority child changes can be tracked.');\n    const oldChange = this.changeMap.get(childKey);\n\n    if (oldChange) {\n      const oldType = oldChange.type;\n\n      if (type === \"child_added\"\n      /* CHILD_ADDED */\n      && oldType === \"child_removed\"\n      /* CHILD_REMOVED */\n      ) {\n        this.changeMap.set(childKey, changeChildChanged(childKey, change.snapshotNode, oldChange.snapshotNode));\n      } else if (type === \"child_removed\"\n      /* CHILD_REMOVED */\n      && oldType === \"child_added\"\n      /* CHILD_ADDED */\n      ) {\n        this.changeMap.delete(childKey);\n      } else if (type === \"child_removed\"\n      /* CHILD_REMOVED */\n      && oldType === \"child_changed\"\n      /* CHILD_CHANGED */\n      ) {\n        this.changeMap.set(childKey, changeChildRemoved(childKey, oldChange.oldSnap));\n      } else if (type === \"child_changed\"\n      /* CHILD_CHANGED */\n      && oldType === \"child_added\"\n      /* CHILD_ADDED */\n      ) {\n        this.changeMap.set(childKey, changeChildAdded(childKey, change.snapshotNode));\n      } else if (type === \"child_changed\"\n      /* CHILD_CHANGED */\n      && oldType === \"child_changed\"\n      /* CHILD_CHANGED */\n      ) {\n        this.changeMap.set(childKey, changeChildChanged(childKey, change.snapshotNode, oldChange.oldSnap));\n      } else {\n        throw assertionError('Illegal combination of changes: ' + change + ' occurred after ' + oldChange);\n      }\n    } else {\n      this.changeMap.set(childKey, change);\n    }\n  }\n\n  getChanges() {\n    return Array.from(this.changeMap.values());\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An implementation of CompleteChildSource that never returns any additional children\r\n */\n// eslint-disable-next-line @typescript-eslint/naming-convention\n\n\nclass NoCompleteChildSource_ {\n  getCompleteChild(childKey) {\n    return null;\n  }\n\n  getChildAfterChild(index, child, reverse) {\n    return null;\n  }\n\n}\n/**\r\n * Singleton instance.\r\n */\n\n\nconst NO_COMPLETE_CHILD_SOURCE = new NoCompleteChildSource_();\n/**\r\n * An implementation of CompleteChildSource that uses a WriteTree in addition to any other server data or\r\n * old event caches available to calculate complete children.\r\n */\n\nclass WriteTreeCompleteChildSource {\n  constructor(writes_, viewCache_, optCompleteServerCache_ = null) {\n    this.writes_ = writes_;\n    this.viewCache_ = viewCache_;\n    this.optCompleteServerCache_ = optCompleteServerCache_;\n  }\n\n  getCompleteChild(childKey) {\n    const node = this.viewCache_.eventCache;\n\n    if (node.isCompleteForChild(childKey)) {\n      return node.getNode().getImmediateChild(childKey);\n    } else {\n      const serverNode = this.optCompleteServerCache_ != null ? new CacheNode(this.optCompleteServerCache_, true, false) : this.viewCache_.serverCache;\n      return writeTreeRefCalcCompleteChild(this.writes_, childKey, serverNode);\n    }\n  }\n\n  getChildAfterChild(index, child, reverse) {\n    const completeServerData = this.optCompleteServerCache_ != null ? this.optCompleteServerCache_ : viewCacheGetCompleteServerSnap(this.viewCache_);\n    const nodes = writeTreeRefCalcIndexedSlice(this.writes_, completeServerData, child, 1, reverse, index);\n\n    if (nodes.length === 0) {\n      return null;\n    } else {\n      return nodes[0];\n    }\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction newViewProcessor(filter) {\n  return {\n    filter\n  };\n}\n\nfunction viewProcessorAssertIndexed(viewProcessor, viewCache) {\n  assert(viewCache.eventCache.getNode().isIndexed(viewProcessor.filter.getIndex()), 'Event snap not indexed');\n  assert(viewCache.serverCache.getNode().isIndexed(viewProcessor.filter.getIndex()), 'Server snap not indexed');\n}\n\nfunction viewProcessorApplyOperation(viewProcessor, oldViewCache, operation, writesCache, completeCache) {\n  const accumulator = new ChildChangeAccumulator();\n  let newViewCache, filterServerNode;\n\n  if (operation.type === OperationType.OVERWRITE) {\n    const overwrite = operation;\n\n    if (overwrite.source.fromUser) {\n      newViewCache = viewProcessorApplyUserOverwrite(viewProcessor, oldViewCache, overwrite.path, overwrite.snap, writesCache, completeCache, accumulator);\n    } else {\n      assert(overwrite.source.fromServer, 'Unknown source.'); // We filter the node if it's a tagged update or the node has been previously filtered  and the\n      // update is not at the root in which case it is ok (and necessary) to mark the node unfiltered\n      // again\n\n      filterServerNode = overwrite.source.tagged || oldViewCache.serverCache.isFiltered() && !pathIsEmpty(overwrite.path);\n      newViewCache = viewProcessorApplyServerOverwrite(viewProcessor, oldViewCache, overwrite.path, overwrite.snap, writesCache, completeCache, filterServerNode, accumulator);\n    }\n  } else if (operation.type === OperationType.MERGE) {\n    const merge = operation;\n\n    if (merge.source.fromUser) {\n      newViewCache = viewProcessorApplyUserMerge(viewProcessor, oldViewCache, merge.path, merge.children, writesCache, completeCache, accumulator);\n    } else {\n      assert(merge.source.fromServer, 'Unknown source.'); // We filter the node if it's a tagged update or the node has been previously filtered\n\n      filterServerNode = merge.source.tagged || oldViewCache.serverCache.isFiltered();\n      newViewCache = viewProcessorApplyServerMerge(viewProcessor, oldViewCache, merge.path, merge.children, writesCache, completeCache, filterServerNode, accumulator);\n    }\n  } else if (operation.type === OperationType.ACK_USER_WRITE) {\n    const ackUserWrite = operation;\n\n    if (!ackUserWrite.revert) {\n      newViewCache = viewProcessorAckUserWrite(viewProcessor, oldViewCache, ackUserWrite.path, ackUserWrite.affectedTree, writesCache, completeCache, accumulator);\n    } else {\n      newViewCache = viewProcessorRevertUserWrite(viewProcessor, oldViewCache, ackUserWrite.path, writesCache, completeCache, accumulator);\n    }\n  } else if (operation.type === OperationType.LISTEN_COMPLETE) {\n    newViewCache = viewProcessorListenComplete(viewProcessor, oldViewCache, operation.path, writesCache, accumulator);\n  } else {\n    throw assertionError('Unknown operation type: ' + operation.type);\n  }\n\n  const changes = accumulator.getChanges();\n  viewProcessorMaybeAddValueEvent(oldViewCache, newViewCache, changes);\n  return {\n    viewCache: newViewCache,\n    changes\n  };\n}\n\nfunction viewProcessorMaybeAddValueEvent(oldViewCache, newViewCache, accumulator) {\n  const eventSnap = newViewCache.eventCache;\n\n  if (eventSnap.isFullyInitialized()) {\n    const isLeafOrEmpty = eventSnap.getNode().isLeafNode() || eventSnap.getNode().isEmpty();\n    const oldCompleteSnap = viewCacheGetCompleteEventSnap(oldViewCache);\n\n    if (accumulator.length > 0 || !oldViewCache.eventCache.isFullyInitialized() || isLeafOrEmpty && !eventSnap.getNode().equals(oldCompleteSnap) || !eventSnap.getNode().getPriority().equals(oldCompleteSnap.getPriority())) {\n      accumulator.push(changeValue(viewCacheGetCompleteEventSnap(newViewCache)));\n    }\n  }\n}\n\nfunction viewProcessorGenerateEventCacheAfterServerEvent(viewProcessor, viewCache, changePath, writesCache, source, accumulator) {\n  const oldEventSnap = viewCache.eventCache;\n\n  if (writeTreeRefShadowingWrite(writesCache, changePath) != null) {\n    // we have a shadowing write, ignore changes\n    return viewCache;\n  } else {\n    let newEventCache, serverNode;\n\n    if (pathIsEmpty(changePath)) {\n      // TODO: figure out how this plays with \"sliding ack windows\"\n      assert(viewCache.serverCache.isFullyInitialized(), 'If change path is empty, we must have complete server data');\n\n      if (viewCache.serverCache.isFiltered()) {\n        // We need to special case this, because we need to only apply writes to complete children, or\n        // we might end up raising events for incomplete children. If the server data is filtered deep\n        // writes cannot be guaranteed to be complete\n        const serverCache = viewCacheGetCompleteServerSnap(viewCache);\n        const completeChildren = serverCache instanceof ChildrenNode ? serverCache : ChildrenNode.EMPTY_NODE;\n        const completeEventChildren = writeTreeRefCalcCompleteEventChildren(writesCache, completeChildren);\n        newEventCache = viewProcessor.filter.updateFullNode(viewCache.eventCache.getNode(), completeEventChildren, accumulator);\n      } else {\n        const completeNode = writeTreeRefCalcCompleteEventCache(writesCache, viewCacheGetCompleteServerSnap(viewCache));\n        newEventCache = viewProcessor.filter.updateFullNode(viewCache.eventCache.getNode(), completeNode, accumulator);\n      }\n    } else {\n      const childKey = pathGetFront(changePath);\n\n      if (childKey === '.priority') {\n        assert(pathGetLength(changePath) === 1, \"Can't have a priority with additional path components\");\n        const oldEventNode = oldEventSnap.getNode();\n        serverNode = viewCache.serverCache.getNode(); // we might have overwrites for this priority\n\n        const updatedPriority = writeTreeRefCalcEventCacheAfterServerOverwrite(writesCache, changePath, oldEventNode, serverNode);\n\n        if (updatedPriority != null) {\n          newEventCache = viewProcessor.filter.updatePriority(oldEventNode, updatedPriority);\n        } else {\n          // priority didn't change, keep old node\n          newEventCache = oldEventSnap.getNode();\n        }\n      } else {\n        const childChangePath = pathPopFront(changePath); // update child\n\n        let newEventChild;\n\n        if (oldEventSnap.isCompleteForChild(childKey)) {\n          serverNode = viewCache.serverCache.getNode();\n          const eventChildUpdate = writeTreeRefCalcEventCacheAfterServerOverwrite(writesCache, changePath, oldEventSnap.getNode(), serverNode);\n\n          if (eventChildUpdate != null) {\n            newEventChild = oldEventSnap.getNode().getImmediateChild(childKey).updateChild(childChangePath, eventChildUpdate);\n          } else {\n            // Nothing changed, just keep the old child\n            newEventChild = oldEventSnap.getNode().getImmediateChild(childKey);\n          }\n        } else {\n          newEventChild = writeTreeRefCalcCompleteChild(writesCache, childKey, viewCache.serverCache);\n        }\n\n        if (newEventChild != null) {\n          newEventCache = viewProcessor.filter.updateChild(oldEventSnap.getNode(), childKey, newEventChild, childChangePath, source, accumulator);\n        } else {\n          // no complete child available or no change\n          newEventCache = oldEventSnap.getNode();\n        }\n      }\n    }\n\n    return viewCacheUpdateEventSnap(viewCache, newEventCache, oldEventSnap.isFullyInitialized() || pathIsEmpty(changePath), viewProcessor.filter.filtersNodes());\n  }\n}\n\nfunction viewProcessorApplyServerOverwrite(viewProcessor, oldViewCache, changePath, changedSnap, writesCache, completeCache, filterServerNode, accumulator) {\n  const oldServerSnap = oldViewCache.serverCache;\n  let newServerCache;\n  const serverFilter = filterServerNode ? viewProcessor.filter : viewProcessor.filter.getIndexedFilter();\n\n  if (pathIsEmpty(changePath)) {\n    newServerCache = serverFilter.updateFullNode(oldServerSnap.getNode(), changedSnap, null);\n  } else if (serverFilter.filtersNodes() && !oldServerSnap.isFiltered()) {\n    // we want to filter the server node, but we didn't filter the server node yet, so simulate a full update\n    const newServerNode = oldServerSnap.getNode().updateChild(changePath, changedSnap);\n    newServerCache = serverFilter.updateFullNode(oldServerSnap.getNode(), newServerNode, null);\n  } else {\n    const childKey = pathGetFront(changePath);\n\n    if (!oldServerSnap.isCompleteForPath(changePath) && pathGetLength(changePath) > 1) {\n      // We don't update incomplete nodes with updates intended for other listeners\n      return oldViewCache;\n    }\n\n    const childChangePath = pathPopFront(changePath);\n    const childNode = oldServerSnap.getNode().getImmediateChild(childKey);\n    const newChildNode = childNode.updateChild(childChangePath, changedSnap);\n\n    if (childKey === '.priority') {\n      newServerCache = serverFilter.updatePriority(oldServerSnap.getNode(), newChildNode);\n    } else {\n      newServerCache = serverFilter.updateChild(oldServerSnap.getNode(), childKey, newChildNode, childChangePath, NO_COMPLETE_CHILD_SOURCE, null);\n    }\n  }\n\n  const newViewCache = viewCacheUpdateServerSnap(oldViewCache, newServerCache, oldServerSnap.isFullyInitialized() || pathIsEmpty(changePath), serverFilter.filtersNodes());\n  const source = new WriteTreeCompleteChildSource(writesCache, newViewCache, completeCache);\n  return viewProcessorGenerateEventCacheAfterServerEvent(viewProcessor, newViewCache, changePath, writesCache, source, accumulator);\n}\n\nfunction viewProcessorApplyUserOverwrite(viewProcessor, oldViewCache, changePath, changedSnap, writesCache, completeCache, accumulator) {\n  const oldEventSnap = oldViewCache.eventCache;\n  let newViewCache, newEventCache;\n  const source = new WriteTreeCompleteChildSource(writesCache, oldViewCache, completeCache);\n\n  if (pathIsEmpty(changePath)) {\n    newEventCache = viewProcessor.filter.updateFullNode(oldViewCache.eventCache.getNode(), changedSnap, accumulator);\n    newViewCache = viewCacheUpdateEventSnap(oldViewCache, newEventCache, true, viewProcessor.filter.filtersNodes());\n  } else {\n    const childKey = pathGetFront(changePath);\n\n    if (childKey === '.priority') {\n      newEventCache = viewProcessor.filter.updatePriority(oldViewCache.eventCache.getNode(), changedSnap);\n      newViewCache = viewCacheUpdateEventSnap(oldViewCache, newEventCache, oldEventSnap.isFullyInitialized(), oldEventSnap.isFiltered());\n    } else {\n      const childChangePath = pathPopFront(changePath);\n      const oldChild = oldEventSnap.getNode().getImmediateChild(childKey);\n      let newChild;\n\n      if (pathIsEmpty(childChangePath)) {\n        // Child overwrite, we can replace the child\n        newChild = changedSnap;\n      } else {\n        const childNode = source.getCompleteChild(childKey);\n\n        if (childNode != null) {\n          if (pathGetBack(childChangePath) === '.priority' && childNode.getChild(pathParent(childChangePath)).isEmpty()) {\n            // This is a priority update on an empty node. If this node exists on the server, the\n            // server will send down the priority in the update, so ignore for now\n            newChild = childNode;\n          } else {\n            newChild = childNode.updateChild(childChangePath, changedSnap);\n          }\n        } else {\n          // There is no complete child node available\n          newChild = ChildrenNode.EMPTY_NODE;\n        }\n      }\n\n      if (!oldChild.equals(newChild)) {\n        const newEventSnap = viewProcessor.filter.updateChild(oldEventSnap.getNode(), childKey, newChild, childChangePath, source, accumulator);\n        newViewCache = viewCacheUpdateEventSnap(oldViewCache, newEventSnap, oldEventSnap.isFullyInitialized(), viewProcessor.filter.filtersNodes());\n      } else {\n        newViewCache = oldViewCache;\n      }\n    }\n  }\n\n  return newViewCache;\n}\n\nfunction viewProcessorCacheHasChild(viewCache, childKey) {\n  return viewCache.eventCache.isCompleteForChild(childKey);\n}\n\nfunction viewProcessorApplyUserMerge(viewProcessor, viewCache, path, changedChildren, writesCache, serverCache, accumulator) {\n  // HACK: In the case of a limit query, there may be some changes that bump things out of the\n  // window leaving room for new items.  It's important we process these changes first, so we\n  // iterate the changes twice, first processing any that affect items currently in view.\n  // TODO: I consider an item \"in view\" if cacheHasChild is true, which checks both the server\n  // and event snap.  I'm not sure if this will result in edge cases when a child is in one but\n  // not the other.\n  let curViewCache = viewCache;\n  changedChildren.foreach((relativePath, childNode) => {\n    const writePath = pathChild(path, relativePath);\n\n    if (viewProcessorCacheHasChild(viewCache, pathGetFront(writePath))) {\n      curViewCache = viewProcessorApplyUserOverwrite(viewProcessor, curViewCache, writePath, childNode, writesCache, serverCache, accumulator);\n    }\n  });\n  changedChildren.foreach((relativePath, childNode) => {\n    const writePath = pathChild(path, relativePath);\n\n    if (!viewProcessorCacheHasChild(viewCache, pathGetFront(writePath))) {\n      curViewCache = viewProcessorApplyUserOverwrite(viewProcessor, curViewCache, writePath, childNode, writesCache, serverCache, accumulator);\n    }\n  });\n  return curViewCache;\n}\n\nfunction viewProcessorApplyMerge(viewProcessor, node, merge) {\n  merge.foreach((relativePath, childNode) => {\n    node = node.updateChild(relativePath, childNode);\n  });\n  return node;\n}\n\nfunction viewProcessorApplyServerMerge(viewProcessor, viewCache, path, changedChildren, writesCache, serverCache, filterServerNode, accumulator) {\n  // If we don't have a cache yet, this merge was intended for a previously listen in the same location. Ignore it and\n  // wait for the complete data update coming soon.\n  if (viewCache.serverCache.getNode().isEmpty() && !viewCache.serverCache.isFullyInitialized()) {\n    return viewCache;\n  } // HACK: In the case of a limit query, there may be some changes that bump things out of the\n  // window leaving room for new items.  It's important we process these changes first, so we\n  // iterate the changes twice, first processing any that affect items currently in view.\n  // TODO: I consider an item \"in view\" if cacheHasChild is true, which checks both the server\n  // and event snap.  I'm not sure if this will result in edge cases when a child is in one but\n  // not the other.\n\n\n  let curViewCache = viewCache;\n  let viewMergeTree;\n\n  if (pathIsEmpty(path)) {\n    viewMergeTree = changedChildren;\n  } else {\n    viewMergeTree = new ImmutableTree(null).setTree(path, changedChildren);\n  }\n\n  const serverNode = viewCache.serverCache.getNode();\n  viewMergeTree.children.inorderTraversal((childKey, childTree) => {\n    if (serverNode.hasChild(childKey)) {\n      const serverChild = viewCache.serverCache.getNode().getImmediateChild(childKey);\n      const newChild = viewProcessorApplyMerge(viewProcessor, serverChild, childTree);\n      curViewCache = viewProcessorApplyServerOverwrite(viewProcessor, curViewCache, new Path(childKey), newChild, writesCache, serverCache, filterServerNode, accumulator);\n    }\n  });\n  viewMergeTree.children.inorderTraversal((childKey, childMergeTree) => {\n    const isUnknownDeepMerge = !viewCache.serverCache.isCompleteForChild(childKey) && childMergeTree.value === undefined;\n\n    if (!serverNode.hasChild(childKey) && !isUnknownDeepMerge) {\n      const serverChild = viewCache.serverCache.getNode().getImmediateChild(childKey);\n      const newChild = viewProcessorApplyMerge(viewProcessor, serverChild, childMergeTree);\n      curViewCache = viewProcessorApplyServerOverwrite(viewProcessor, curViewCache, new Path(childKey), newChild, writesCache, serverCache, filterServerNode, accumulator);\n    }\n  });\n  return curViewCache;\n}\n\nfunction viewProcessorAckUserWrite(viewProcessor, viewCache, ackPath, affectedTree, writesCache, completeCache, accumulator) {\n  if (writeTreeRefShadowingWrite(writesCache, ackPath) != null) {\n    return viewCache;\n  } // Only filter server node if it is currently filtered\n\n\n  const filterServerNode = viewCache.serverCache.isFiltered(); // Essentially we'll just get our existing server cache for the affected paths and re-apply it as a server update\n  // now that it won't be shadowed.\n\n  const serverCache = viewCache.serverCache;\n\n  if (affectedTree.value != null) {\n    // This is an overwrite.\n    if (pathIsEmpty(ackPath) && serverCache.isFullyInitialized() || serverCache.isCompleteForPath(ackPath)) {\n      return viewProcessorApplyServerOverwrite(viewProcessor, viewCache, ackPath, serverCache.getNode().getChild(ackPath), writesCache, completeCache, filterServerNode, accumulator);\n    } else if (pathIsEmpty(ackPath)) {\n      // This is a goofy edge case where we are acking data at this location but don't have full data.  We\n      // should just re-apply whatever we have in our cache as a merge.\n      let changedChildren = new ImmutableTree(null);\n      serverCache.getNode().forEachChild(KEY_INDEX, (name, node) => {\n        changedChildren = changedChildren.set(new Path(name), node);\n      });\n      return viewProcessorApplyServerMerge(viewProcessor, viewCache, ackPath, changedChildren, writesCache, completeCache, filterServerNode, accumulator);\n    } else {\n      return viewCache;\n    }\n  } else {\n    // This is a merge.\n    let changedChildren = new ImmutableTree(null);\n    affectedTree.foreach((mergePath, value) => {\n      const serverCachePath = pathChild(ackPath, mergePath);\n\n      if (serverCache.isCompleteForPath(serverCachePath)) {\n        changedChildren = changedChildren.set(mergePath, serverCache.getNode().getChild(serverCachePath));\n      }\n    });\n    return viewProcessorApplyServerMerge(viewProcessor, viewCache, ackPath, changedChildren, writesCache, completeCache, filterServerNode, accumulator);\n  }\n}\n\nfunction viewProcessorListenComplete(viewProcessor, viewCache, path, writesCache, accumulator) {\n  const oldServerNode = viewCache.serverCache;\n  const newViewCache = viewCacheUpdateServerSnap(viewCache, oldServerNode.getNode(), oldServerNode.isFullyInitialized() || pathIsEmpty(path), oldServerNode.isFiltered());\n  return viewProcessorGenerateEventCacheAfterServerEvent(viewProcessor, newViewCache, path, writesCache, NO_COMPLETE_CHILD_SOURCE, accumulator);\n}\n\nfunction viewProcessorRevertUserWrite(viewProcessor, viewCache, path, writesCache, completeServerCache, accumulator) {\n  let complete;\n\n  if (writeTreeRefShadowingWrite(writesCache, path) != null) {\n    return viewCache;\n  } else {\n    const source = new WriteTreeCompleteChildSource(writesCache, viewCache, completeServerCache);\n    const oldEventCache = viewCache.eventCache.getNode();\n    let newEventCache;\n\n    if (pathIsEmpty(path) || pathGetFront(path) === '.priority') {\n      let newNode;\n\n      if (viewCache.serverCache.isFullyInitialized()) {\n        newNode = writeTreeRefCalcCompleteEventCache(writesCache, viewCacheGetCompleteServerSnap(viewCache));\n      } else {\n        const serverChildren = viewCache.serverCache.getNode();\n        assert(serverChildren instanceof ChildrenNode, 'serverChildren would be complete if leaf node');\n        newNode = writeTreeRefCalcCompleteEventChildren(writesCache, serverChildren);\n      }\n\n      newNode = newNode;\n      newEventCache = viewProcessor.filter.updateFullNode(oldEventCache, newNode, accumulator);\n    } else {\n      const childKey = pathGetFront(path);\n      let newChild = writeTreeRefCalcCompleteChild(writesCache, childKey, viewCache.serverCache);\n\n      if (newChild == null && viewCache.serverCache.isCompleteForChild(childKey)) {\n        newChild = oldEventCache.getImmediateChild(childKey);\n      }\n\n      if (newChild != null) {\n        newEventCache = viewProcessor.filter.updateChild(oldEventCache, childKey, newChild, pathPopFront(path), source, accumulator);\n      } else if (viewCache.eventCache.getNode().hasChild(childKey)) {\n        // No complete child available, delete the existing one, if any\n        newEventCache = viewProcessor.filter.updateChild(oldEventCache, childKey, ChildrenNode.EMPTY_NODE, pathPopFront(path), source, accumulator);\n      } else {\n        newEventCache = oldEventCache;\n      }\n\n      if (newEventCache.isEmpty() && viewCache.serverCache.isFullyInitialized()) {\n        // We might have reverted all child writes. Maybe the old event was a leaf node\n        complete = writeTreeRefCalcCompleteEventCache(writesCache, viewCacheGetCompleteServerSnap(viewCache));\n\n        if (complete.isLeafNode()) {\n          newEventCache = viewProcessor.filter.updateFullNode(newEventCache, complete, accumulator);\n        }\n      }\n    }\n\n    complete = viewCache.serverCache.isFullyInitialized() || writeTreeRefShadowingWrite(writesCache, newEmptyPath()) != null;\n    return viewCacheUpdateEventSnap(viewCache, newEventCache, complete, viewProcessor.filter.filtersNodes());\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A view represents a specific location and query that has 1 or more event registrations.\r\n *\r\n * It does several things:\r\n *  - Maintains the list of event registrations for this location/query.\r\n *  - Maintains a cache of the data visible for this location/query.\r\n *  - Applies new operations (via applyOperation), updates the cache, and based on the event\r\n *    registrations returns the set of events to be raised.\r\n */\n\n\nclass View {\n  constructor(query_, initialViewCache) {\n    this.query_ = query_;\n    this.eventRegistrations_ = [];\n    const params = this.query_._queryParams;\n    const indexFilter = new IndexedFilter(params.getIndex());\n    const filter = queryParamsGetNodeFilter(params);\n    this.processor_ = newViewProcessor(filter);\n    const initialServerCache = initialViewCache.serverCache;\n    const initialEventCache = initialViewCache.eventCache; // Don't filter server node with other filter than index, wait for tagged listen\n\n    const serverSnap = indexFilter.updateFullNode(ChildrenNode.EMPTY_NODE, initialServerCache.getNode(), null);\n    const eventSnap = filter.updateFullNode(ChildrenNode.EMPTY_NODE, initialEventCache.getNode(), null);\n    const newServerCache = new CacheNode(serverSnap, initialServerCache.isFullyInitialized(), indexFilter.filtersNodes());\n    const newEventCache = new CacheNode(eventSnap, initialEventCache.isFullyInitialized(), filter.filtersNodes());\n    this.viewCache_ = newViewCache(newEventCache, newServerCache);\n    this.eventGenerator_ = new EventGenerator(this.query_);\n  }\n\n  get query() {\n    return this.query_;\n  }\n\n}\n\nfunction viewGetServerCache(view) {\n  return view.viewCache_.serverCache.getNode();\n}\n\nfunction viewGetCompleteNode(view) {\n  return viewCacheGetCompleteEventSnap(view.viewCache_);\n}\n\nfunction viewGetCompleteServerCache(view, path) {\n  const cache = viewCacheGetCompleteServerSnap(view.viewCache_);\n\n  if (cache) {\n    // If this isn't a \"loadsAllData\" view, then cache isn't actually a complete cache and\n    // we need to see if it contains the child we're interested in.\n    if (view.query._queryParams.loadsAllData() || !pathIsEmpty(path) && !cache.getImmediateChild(pathGetFront(path)).isEmpty()) {\n      return cache.getChild(path);\n    }\n  }\n\n  return null;\n}\n\nfunction viewIsEmpty(view) {\n  return view.eventRegistrations_.length === 0;\n}\n\nfunction viewAddEventRegistration(view, eventRegistration) {\n  view.eventRegistrations_.push(eventRegistration);\n}\n/**\r\n * @param eventRegistration - If null, remove all callbacks.\r\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\r\n * @returns Cancel events, if cancelError was provided.\r\n */\n\n\nfunction viewRemoveEventRegistration(view, eventRegistration, cancelError) {\n  const cancelEvents = [];\n\n  if (cancelError) {\n    assert(eventRegistration == null, 'A cancel should cancel all event registrations.');\n    const path = view.query._path;\n    view.eventRegistrations_.forEach(registration => {\n      const maybeEvent = registration.createCancelEvent(cancelError, path);\n\n      if (maybeEvent) {\n        cancelEvents.push(maybeEvent);\n      }\n    });\n  }\n\n  if (eventRegistration) {\n    let remaining = [];\n\n    for (let i = 0; i < view.eventRegistrations_.length; ++i) {\n      const existing = view.eventRegistrations_[i];\n\n      if (!existing.matches(eventRegistration)) {\n        remaining.push(existing);\n      } else if (eventRegistration.hasAnyCallback()) {\n        // We're removing just this one\n        remaining = remaining.concat(view.eventRegistrations_.slice(i + 1));\n        break;\n      }\n    }\n\n    view.eventRegistrations_ = remaining;\n  } else {\n    view.eventRegistrations_ = [];\n  }\n\n  return cancelEvents;\n}\n/**\r\n * Applies the given Operation, updates our cache, and returns the appropriate events.\r\n */\n\n\nfunction viewApplyOperation(view, operation, writesCache, completeServerCache) {\n  if (operation.type === OperationType.MERGE && operation.source.queryId !== null) {\n    assert(viewCacheGetCompleteServerSnap(view.viewCache_), 'We should always have a full cache before handling merges');\n    assert(viewCacheGetCompleteEventSnap(view.viewCache_), 'Missing event cache, even though we have a server cache');\n  }\n\n  const oldViewCache = view.viewCache_;\n  const result = viewProcessorApplyOperation(view.processor_, oldViewCache, operation, writesCache, completeServerCache);\n  viewProcessorAssertIndexed(view.processor_, result.viewCache);\n  assert(result.viewCache.serverCache.isFullyInitialized() || !oldViewCache.serverCache.isFullyInitialized(), 'Once a server snap is complete, it should never go back');\n  view.viewCache_ = result.viewCache;\n  return viewGenerateEventsForChanges_(view, result.changes, result.viewCache.eventCache.getNode(), null);\n}\n\nfunction viewGetInitialEvents(view, registration) {\n  const eventSnap = view.viewCache_.eventCache;\n  const initialChanges = [];\n\n  if (!eventSnap.getNode().isLeafNode()) {\n    const eventNode = eventSnap.getNode();\n    eventNode.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n      initialChanges.push(changeChildAdded(key, childNode));\n    });\n  }\n\n  if (eventSnap.isFullyInitialized()) {\n    initialChanges.push(changeValue(eventSnap.getNode()));\n  }\n\n  return viewGenerateEventsForChanges_(view, initialChanges, eventSnap.getNode(), registration);\n}\n\nfunction viewGenerateEventsForChanges_(view, changes, eventCache, eventRegistration) {\n  const registrations = eventRegistration ? [eventRegistration] : view.eventRegistrations_;\n  return eventGeneratorGenerateEventsForChanges(view.eventGenerator_, changes, eventCache, registrations);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet referenceConstructor$1;\n/**\r\n * SyncPoint represents a single location in a SyncTree with 1 or more event registrations, meaning we need to\r\n * maintain 1 or more Views at this location to cache server data and raise appropriate events for server changes\r\n * and user writes (set, transaction, update).\r\n *\r\n * It's responsible for:\r\n *  - Maintaining the set of 1 or more views necessary at this location (a SyncPoint with 0 views should be removed).\r\n *  - Proxying user / server operations to the views as appropriate (i.e. applyServerOverwrite,\r\n *    applyUserOverwrite, etc.)\r\n */\n\nclass SyncPoint {\n  constructor() {\n    /**\r\n     * The Views being tracked at this location in the tree, stored as a map where the key is a\r\n     * queryId and the value is the View for that query.\r\n     *\r\n     * NOTE: This list will be quite small (usually 1, but perhaps 2 or 3; any more is an odd use case).\r\n     */\n    this.views = new Map();\n  }\n\n}\n\nfunction syncPointSetReferenceConstructor(val) {\n  assert(!referenceConstructor$1, '__referenceConstructor has already been defined');\n  referenceConstructor$1 = val;\n}\n\nfunction syncPointGetReferenceConstructor() {\n  assert(referenceConstructor$1, 'Reference.ts has not been loaded');\n  return referenceConstructor$1;\n}\n\nfunction syncPointIsEmpty(syncPoint) {\n  return syncPoint.views.size === 0;\n}\n\nfunction syncPointApplyOperation(syncPoint, operation, writesCache, optCompleteServerCache) {\n  const queryId = operation.source.queryId;\n\n  if (queryId !== null) {\n    const view = syncPoint.views.get(queryId);\n    assert(view != null, 'SyncTree gave us an op for an invalid query.');\n    return viewApplyOperation(view, operation, writesCache, optCompleteServerCache);\n  } else {\n    let events = [];\n\n    for (const view of syncPoint.views.values()) {\n      events = events.concat(viewApplyOperation(view, operation, writesCache, optCompleteServerCache));\n    }\n\n    return events;\n  }\n}\n/**\r\n * Get a view for the specified query.\r\n *\r\n * @param query - The query to return a view for\r\n * @param writesCache\r\n * @param serverCache\r\n * @param serverCacheComplete\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncPointGetView(syncPoint, query, writesCache, serverCache, serverCacheComplete) {\n  const queryId = query._queryIdentifier;\n  const view = syncPoint.views.get(queryId);\n\n  if (!view) {\n    // TODO: make writesCache take flag for complete server node\n    let eventCache = writeTreeRefCalcCompleteEventCache(writesCache, serverCacheComplete ? serverCache : null);\n    let eventCacheComplete = false;\n\n    if (eventCache) {\n      eventCacheComplete = true;\n    } else if (serverCache instanceof ChildrenNode) {\n      eventCache = writeTreeRefCalcCompleteEventChildren(writesCache, serverCache);\n      eventCacheComplete = false;\n    } else {\n      eventCache = ChildrenNode.EMPTY_NODE;\n      eventCacheComplete = false;\n    }\n\n    const viewCache = newViewCache(new CacheNode(eventCache, eventCacheComplete, false), new CacheNode(serverCache, serverCacheComplete, false));\n    return new View(query, viewCache);\n  }\n\n  return view;\n}\n/**\r\n * Add an event callback for the specified query.\r\n *\r\n * @param query\r\n * @param eventRegistration\r\n * @param writesCache\r\n * @param serverCache - Complete server cache, if we have it.\r\n * @param serverCacheComplete\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncPointAddEventRegistration(syncPoint, query, eventRegistration, writesCache, serverCache, serverCacheComplete) {\n  const view = syncPointGetView(syncPoint, query, writesCache, serverCache, serverCacheComplete);\n\n  if (!syncPoint.views.has(query._queryIdentifier)) {\n    syncPoint.views.set(query._queryIdentifier, view);\n  } // This is guaranteed to exist now, we just created anything that was missing\n\n\n  viewAddEventRegistration(view, eventRegistration);\n  return viewGetInitialEvents(view, eventRegistration);\n}\n/**\r\n * Remove event callback(s).  Return cancelEvents if a cancelError is specified.\r\n *\r\n * If query is the default query, we'll check all views for the specified eventRegistration.\r\n * If eventRegistration is null, we'll remove all callbacks for the specified view(s).\r\n *\r\n * @param eventRegistration - If null, remove all callbacks.\r\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\r\n * @returns removed queries and any cancel events\r\n */\n\n\nfunction syncPointRemoveEventRegistration(syncPoint, query, eventRegistration, cancelError) {\n  const queryId = query._queryIdentifier;\n  const removed = [];\n  let cancelEvents = [];\n  const hadCompleteView = syncPointHasCompleteView(syncPoint);\n\n  if (queryId === 'default') {\n    // When you do ref.off(...), we search all views for the registration to remove.\n    for (const [viewQueryId, view] of syncPoint.views.entries()) {\n      cancelEvents = cancelEvents.concat(viewRemoveEventRegistration(view, eventRegistration, cancelError));\n\n      if (viewIsEmpty(view)) {\n        syncPoint.views.delete(viewQueryId); // We'll deal with complete views later.\n\n        if (!view.query._queryParams.loadsAllData()) {\n          removed.push(view.query);\n        }\n      }\n    }\n  } else {\n    // remove the callback from the specific view.\n    const view = syncPoint.views.get(queryId);\n\n    if (view) {\n      cancelEvents = cancelEvents.concat(viewRemoveEventRegistration(view, eventRegistration, cancelError));\n\n      if (viewIsEmpty(view)) {\n        syncPoint.views.delete(queryId); // We'll deal with complete views later.\n\n        if (!view.query._queryParams.loadsAllData()) {\n          removed.push(view.query);\n        }\n      }\n    }\n  }\n\n  if (hadCompleteView && !syncPointHasCompleteView(syncPoint)) {\n    // We removed our last complete view.\n    removed.push(new (syncPointGetReferenceConstructor())(query._repo, query._path));\n  }\n\n  return {\n    removed,\n    events: cancelEvents\n  };\n}\n\nfunction syncPointGetQueryViews(syncPoint) {\n  const result = [];\n\n  for (const view of syncPoint.views.values()) {\n    if (!view.query._queryParams.loadsAllData()) {\n      result.push(view);\n    }\n  }\n\n  return result;\n}\n/**\r\n * @param path - The path to the desired complete snapshot\r\n * @returns A complete cache, if it exists\r\n */\n\n\nfunction syncPointGetCompleteServerCache(syncPoint, path) {\n  let serverCache = null;\n\n  for (const view of syncPoint.views.values()) {\n    serverCache = serverCache || viewGetCompleteServerCache(view, path);\n  }\n\n  return serverCache;\n}\n\nfunction syncPointViewForQuery(syncPoint, query) {\n  const params = query._queryParams;\n\n  if (params.loadsAllData()) {\n    return syncPointGetCompleteView(syncPoint);\n  } else {\n    const queryId = query._queryIdentifier;\n    return syncPoint.views.get(queryId);\n  }\n}\n\nfunction syncPointViewExistsForQuery(syncPoint, query) {\n  return syncPointViewForQuery(syncPoint, query) != null;\n}\n\nfunction syncPointHasCompleteView(syncPoint) {\n  return syncPointGetCompleteView(syncPoint) != null;\n}\n\nfunction syncPointGetCompleteView(syncPoint) {\n  for (const view of syncPoint.views.values()) {\n    if (view.query._queryParams.loadsAllData()) {\n      return view;\n    }\n  }\n\n  return null;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nlet referenceConstructor;\n\nfunction syncTreeSetReferenceConstructor(val) {\n  assert(!referenceConstructor, '__referenceConstructor has already been defined');\n  referenceConstructor = val;\n}\n\nfunction syncTreeGetReferenceConstructor() {\n  assert(referenceConstructor, 'Reference.ts has not been loaded');\n  return referenceConstructor;\n}\n/**\r\n * Static tracker for next query tag.\r\n */\n\n\nlet syncTreeNextQueryTag_ = 1;\n/**\r\n * SyncTree is the central class for managing event callback registration, data caching, views\r\n * (query processing), and event generation.  There are typically two SyncTree instances for\r\n * each Repo, one for the normal Firebase data, and one for the .info data.\r\n *\r\n * It has a number of responsibilities, including:\r\n *  - Tracking all user event callbacks (registered via addEventRegistration() and removeEventRegistration()).\r\n *  - Applying and caching data changes for user set(), transaction(), and update() calls\r\n *    (applyUserOverwrite(), applyUserMerge()).\r\n *  - Applying and caching data changes for server data changes (applyServerOverwrite(),\r\n *    applyServerMerge()).\r\n *  - Generating user-facing events for server and user changes (all of the apply* methods\r\n *    return the set of events that need to be raised as a result).\r\n *  - Maintaining the appropriate set of server listens to ensure we are always subscribed\r\n *    to the correct set of paths and queries to satisfy the current set of user event\r\n *    callbacks (listens are started/stopped using the provided listenProvider).\r\n *\r\n * NOTE: Although SyncTree tracks event callbacks and calculates events to raise, the actual\r\n * events are returned to the caller rather than raised synchronously.\r\n *\r\n */\n\nclass SyncTree {\n  /**\r\n   * @param listenProvider_ - Used by SyncTree to start / stop listening\r\n   *   to server data.\r\n   */\n  constructor(listenProvider_) {\n    this.listenProvider_ = listenProvider_;\n    /**\r\n     * Tree of SyncPoints.  There's a SyncPoint at any location that has 1 or more views.\r\n     */\n\n    this.syncPointTree_ = new ImmutableTree(null);\n    /**\r\n     * A tree of all pending user writes (user-initiated set()'s, transaction()'s, update()'s, etc.).\r\n     */\n\n    this.pendingWriteTree_ = newWriteTree();\n    this.tagToQueryMap = new Map();\n    this.queryToTagMap = new Map();\n  }\n\n}\n/**\r\n * Apply the data changes for a user-generated set() or transaction() call.\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyUserOverwrite(syncTree, path, newData, writeId, visible) {\n  // Record pending write.\n  writeTreeAddOverwrite(syncTree.pendingWriteTree_, path, newData, writeId, visible);\n\n  if (!visible) {\n    return [];\n  } else {\n    return syncTreeApplyOperationToSyncPoints_(syncTree, new Overwrite(newOperationSourceUser(), path, newData));\n  }\n}\n/**\r\n * Apply the data from a user-generated update() call\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyUserMerge(syncTree, path, changedChildren, writeId) {\n  // Record pending merge.\n  writeTreeAddMerge(syncTree.pendingWriteTree_, path, changedChildren, writeId);\n  const changeTree = ImmutableTree.fromObject(changedChildren);\n  return syncTreeApplyOperationToSyncPoints_(syncTree, new Merge(newOperationSourceUser(), path, changeTree));\n}\n/**\r\n * Acknowledge a pending user write that was previously registered with applyUserOverwrite() or applyUserMerge().\r\n *\r\n * @param revert - True if the given write failed and needs to be reverted\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeAckUserWrite(syncTree, writeId, revert = false) {\n  const write = writeTreeGetWrite(syncTree.pendingWriteTree_, writeId);\n  const needToReevaluate = writeTreeRemoveWrite(syncTree.pendingWriteTree_, writeId);\n\n  if (!needToReevaluate) {\n    return [];\n  } else {\n    let affectedTree = new ImmutableTree(null);\n\n    if (write.snap != null) {\n      // overwrite\n      affectedTree = affectedTree.set(newEmptyPath(), true);\n    } else {\n      each(write.children, pathString => {\n        affectedTree = affectedTree.set(new Path(pathString), true);\n      });\n    }\n\n    return syncTreeApplyOperationToSyncPoints_(syncTree, new AckUserWrite(write.path, affectedTree, revert));\n  }\n}\n/**\r\n * Apply new server data for the specified path..\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyServerOverwrite(syncTree, path, newData) {\n  return syncTreeApplyOperationToSyncPoints_(syncTree, new Overwrite(newOperationSourceServer(), path, newData));\n}\n/**\r\n * Apply new server data to be merged in at the specified path.\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyServerMerge(syncTree, path, changedChildren) {\n  const changeTree = ImmutableTree.fromObject(changedChildren);\n  return syncTreeApplyOperationToSyncPoints_(syncTree, new Merge(newOperationSourceServer(), path, changeTree));\n}\n/**\r\n * Apply a listen complete for a query\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyListenComplete(syncTree, path) {\n  return syncTreeApplyOperationToSyncPoints_(syncTree, new ListenComplete(newOperationSourceServer(), path));\n}\n/**\r\n * Apply a listen complete for a tagged query\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyTaggedListenComplete(syncTree, path, tag) {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n\n  if (queryKey) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n          queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const op = new ListenComplete(newOperationSourceServerTaggedQuery(queryId), relativePath);\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // We've already removed the query. No big deal, ignore the update\n    return [];\n  }\n}\n/**\r\n * Remove event callback(s).\r\n *\r\n * If query is the default query, we'll check all queries for the specified eventRegistration.\r\n * If eventRegistration is null, we'll remove all callbacks for the specified query/queries.\r\n *\r\n * @param eventRegistration - If null, all callbacks are removed.\r\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\r\n * @returns Cancel events, if cancelError was provided.\r\n */\n\n\nfunction syncTreeRemoveEventRegistration(syncTree, query, eventRegistration, cancelError) {\n  // Find the syncPoint first. Then deal with whether or not it has matching listeners\n  const path = query._path;\n  const maybeSyncPoint = syncTree.syncPointTree_.get(path);\n  let cancelEvents = []; // A removal on a default query affects all queries at that location. A removal on an indexed query, even one without\n  // other query constraints, does *not* affect all queries at that location. So this check must be for 'default', and\n  // not loadsAllData().\n\n  if (maybeSyncPoint && (query._queryIdentifier === 'default' || syncPointViewExistsForQuery(maybeSyncPoint, query))) {\n    const removedAndEvents = syncPointRemoveEventRegistration(maybeSyncPoint, query, eventRegistration, cancelError);\n\n    if (syncPointIsEmpty(maybeSyncPoint)) {\n      syncTree.syncPointTree_ = syncTree.syncPointTree_.remove(path);\n    }\n\n    const removed = removedAndEvents.removed;\n    cancelEvents = removedAndEvents.events; // We may have just removed one of many listeners and can short-circuit this whole process\n    // We may also not have removed a default listener, in which case all of the descendant listeners should already be\n    // properly set up.\n    //\n    // Since indexed queries can shadow if they don't have other query constraints, check for loadsAllData(), instead of\n    // queryId === 'default'\n\n    const removingDefault = -1 !== removed.findIndex(query => {\n      return query._queryParams.loadsAllData();\n    });\n    const covered = syncTree.syncPointTree_.findOnPath(path, (relativePath, parentSyncPoint) => syncPointHasCompleteView(parentSyncPoint));\n\n    if (removingDefault && !covered) {\n      const subtree = syncTree.syncPointTree_.subtree(path); // There are potentially child listeners. Determine what if any listens we need to send before executing the\n      // removal\n\n      if (!subtree.isEmpty()) {\n        // We need to fold over our subtree and collect the listeners to send\n        const newViews = syncTreeCollectDistinctViewsForSubTree_(subtree); // Ok, we've collected all the listens we need. Set them up.\n\n        for (let i = 0; i < newViews.length; ++i) {\n          const view = newViews[i],\n                newQuery = view.query;\n          const listener = syncTreeCreateListenerForView_(syncTree, view);\n          syncTree.listenProvider_.startListening(syncTreeQueryForListening_(newQuery), syncTreeTagForQuery_(syncTree, newQuery), listener.hashFn, listener.onComplete);\n        }\n      }\n    } // If we removed anything and we're not covered by a higher up listen, we need to stop listening on this query\n    // The above block has us covered in terms of making sure we're set up on listens lower in the tree.\n    // Also, note that if we have a cancelError, it's already been removed at the provider level.\n\n\n    if (!covered && removed.length > 0 && !cancelError) {\n      // If we removed a default, then we weren't listening on any of the other queries here. Just cancel the one\n      // default. Otherwise, we need to iterate through and cancel each individual query\n      if (removingDefault) {\n        // We don't tag default listeners\n        const defaultTag = null;\n        syncTree.listenProvider_.stopListening(syncTreeQueryForListening_(query), defaultTag);\n      } else {\n        removed.forEach(queryToRemove => {\n          const tagToRemove = syncTree.queryToTagMap.get(syncTreeMakeQueryKey_(queryToRemove));\n          syncTree.listenProvider_.stopListening(syncTreeQueryForListening_(queryToRemove), tagToRemove);\n        });\n      }\n    } // Now, clear all of the tags we're tracking for the removed listens\n\n\n    syncTreeRemoveTags_(syncTree, removed);\n  }\n\n  return cancelEvents;\n}\n/**\r\n * This function was added to support non-listener queries,\r\n * specifically for use in repoGetValue. It sets up all the same\r\n * local cache data-structures (SyncPoint + View) that are\r\n * needed for listeners without installing an event registration.\r\n * If `query` is not `loadsAllData`, it will also provision a tag for\r\n * the query so that query results can be merged into the sync\r\n * tree using existing logic for tagged listener queries.\r\n *\r\n * @param syncTree - Synctree to add the query to.\r\n * @param query - Query to register\r\n * @returns tag as a string if query is not a default query, null if query is not.\r\n */\n\n\nfunction syncTreeRegisterQuery(syncTree, query) {\n  const {\n    syncPoint,\n    serverCache,\n    writesCache,\n    serverCacheComplete\n  } = syncTreeRegisterSyncPoint(query, syncTree);\n  const view = syncPointGetView(syncPoint, query, writesCache, serverCache, serverCacheComplete);\n\n  if (!syncPoint.views.has(query._queryIdentifier)) {\n    syncPoint.views.set(query._queryIdentifier, view);\n  }\n\n  if (!query._queryParams.loadsAllData()) {\n    return syncTreeTagForQuery_(syncTree, query);\n  }\n\n  return null;\n}\n/**\r\n * Apply new server data for the specified tagged query.\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyTaggedQueryOverwrite(syncTree, path, snap, tag) {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n\n  if (queryKey != null) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n          queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const op = new Overwrite(newOperationSourceServerTaggedQuery(queryId), relativePath, snap);\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // Query must have been removed already\n    return [];\n  }\n}\n/**\r\n * Apply server data to be merged in for the specified tagged query.\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeApplyTaggedQueryMerge(syncTree, path, changedChildren, tag) {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n\n  if (queryKey) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n          queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const changeTree = ImmutableTree.fromObject(changedChildren);\n    const op = new Merge(newOperationSourceServerTaggedQuery(queryId), relativePath, changeTree);\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // We've already removed the query. No big deal, ignore the update\n    return [];\n  }\n}\n/**\r\n * Creates a new syncpoint for a query and creates a tag if the view doesn't exist.\r\n * Extracted from addEventRegistration to allow `repoGetValue` to properly set up the SyncTree\r\n * without actually listening on a query.\r\n */\n\n\nfunction syncTreeRegisterSyncPoint(query, syncTree) {\n  const path = query._path;\n  let serverCache = null;\n  let foundAncestorDefaultView = false; // Any covering writes will necessarily be at the root, so really all we need to find is the server cache.\n  // Consider optimizing this once there's a better understanding of what actual behavior will be.\n\n  syncTree.syncPointTree_.foreachOnPath(path, (pathToSyncPoint, sp) => {\n    const relativePath = newRelativePath(pathToSyncPoint, path);\n    serverCache = serverCache || syncPointGetCompleteServerCache(sp, relativePath);\n    foundAncestorDefaultView = foundAncestorDefaultView || syncPointHasCompleteView(sp);\n  });\n  let syncPoint = syncTree.syncPointTree_.get(path);\n\n  if (!syncPoint) {\n    syncPoint = new SyncPoint();\n    syncTree.syncPointTree_ = syncTree.syncPointTree_.set(path, syncPoint);\n  } else {\n    foundAncestorDefaultView = foundAncestorDefaultView || syncPointHasCompleteView(syncPoint);\n    serverCache = serverCache || syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n\n  let serverCacheComplete;\n\n  if (serverCache != null) {\n    serverCacheComplete = true;\n  } else {\n    serverCacheComplete = false;\n    serverCache = ChildrenNode.EMPTY_NODE;\n    const subtree = syncTree.syncPointTree_.subtree(path);\n    subtree.foreachChild((childName, childSyncPoint) => {\n      const completeCache = syncPointGetCompleteServerCache(childSyncPoint, newEmptyPath());\n\n      if (completeCache) {\n        serverCache = serverCache.updateImmediateChild(childName, completeCache);\n      }\n    });\n  }\n\n  const viewAlreadyExists = syncPointViewExistsForQuery(syncPoint, query);\n\n  if (!viewAlreadyExists && !query._queryParams.loadsAllData()) {\n    // We need to track a tag for this query\n    const queryKey = syncTreeMakeQueryKey_(query);\n    assert(!syncTree.queryToTagMap.has(queryKey), 'View does not exist, but we have a tag');\n    const tag = syncTreeGetNextQueryTag_();\n    syncTree.queryToTagMap.set(queryKey, tag);\n    syncTree.tagToQueryMap.set(tag, queryKey);\n  }\n\n  const writesCache = writeTreeChildWrites(syncTree.pendingWriteTree_, path);\n  return {\n    syncPoint,\n    writesCache,\n    serverCache,\n    serverCacheComplete,\n    foundAncestorDefaultView,\n    viewAlreadyExists\n  };\n}\n/**\r\n * Add an event callback for the specified query.\r\n *\r\n * @returns Events to raise.\r\n */\n\n\nfunction syncTreeAddEventRegistration(syncTree, query, eventRegistration) {\n  const {\n    syncPoint,\n    serverCache,\n    writesCache,\n    serverCacheComplete,\n    viewAlreadyExists,\n    foundAncestorDefaultView\n  } = syncTreeRegisterSyncPoint(query, syncTree);\n  let events = syncPointAddEventRegistration(syncPoint, query, eventRegistration, writesCache, serverCache, serverCacheComplete);\n\n  if (!viewAlreadyExists && !foundAncestorDefaultView) {\n    const view = syncPointViewForQuery(syncPoint, query);\n    events = events.concat(syncTreeSetupListener_(syncTree, query, view));\n  }\n\n  return events;\n}\n/**\r\n * Returns a complete cache, if we have one, of the data at a particular path. If the location does not have a\r\n * listener above it, we will get a false \"null\". This shouldn't be a problem because transactions will always\r\n * have a listener above, and atomic operations would correctly show a jitter of <increment value> ->\r\n *     <incremented total> as the write is applied locally and then acknowledged at the server.\r\n *\r\n * Note: this method will *include* hidden writes from transaction with applyLocally set to false.\r\n *\r\n * @param path - The path to the data we want\r\n * @param writeIdsToExclude - A specific set to be excluded\r\n */\n\n\nfunction syncTreeCalcCompleteEventCache(syncTree, path, writeIdsToExclude) {\n  const includeHiddenSets = true;\n  const writeTree = syncTree.pendingWriteTree_;\n  const serverCache = syncTree.syncPointTree_.findOnPath(path, (pathSoFar, syncPoint) => {\n    const relativePath = newRelativePath(pathSoFar, path);\n    const serverCache = syncPointGetCompleteServerCache(syncPoint, relativePath);\n\n    if (serverCache) {\n      return serverCache;\n    }\n  });\n  return writeTreeCalcCompleteEventCache(writeTree, path, serverCache, writeIdsToExclude, includeHiddenSets);\n}\n\nfunction syncTreeGetServerValue(syncTree, query) {\n  const path = query._path;\n  let serverCache = null; // Any covering writes will necessarily be at the root, so really all we need to find is the server cache.\n  // Consider optimizing this once there's a better understanding of what actual behavior will be.\n\n  syncTree.syncPointTree_.foreachOnPath(path, (pathToSyncPoint, sp) => {\n    const relativePath = newRelativePath(pathToSyncPoint, path);\n    serverCache = serverCache || syncPointGetCompleteServerCache(sp, relativePath);\n  });\n  let syncPoint = syncTree.syncPointTree_.get(path);\n\n  if (!syncPoint) {\n    syncPoint = new SyncPoint();\n    syncTree.syncPointTree_ = syncTree.syncPointTree_.set(path, syncPoint);\n  } else {\n    serverCache = serverCache || syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n\n  const serverCacheComplete = serverCache != null;\n  const serverCacheNode = serverCacheComplete ? new CacheNode(serverCache, true, false) : null;\n  const writesCache = writeTreeChildWrites(syncTree.pendingWriteTree_, query._path);\n  const view = syncPointGetView(syncPoint, query, writesCache, serverCacheComplete ? serverCacheNode.getNode() : ChildrenNode.EMPTY_NODE, serverCacheComplete);\n  return viewGetCompleteNode(view);\n}\n/**\r\n * A helper method that visits all descendant and ancestor SyncPoints, applying the operation.\r\n *\r\n * NOTES:\r\n * - Descendant SyncPoints will be visited first (since we raise events depth-first).\r\n *\r\n * - We call applyOperation() on each SyncPoint passing three things:\r\n *   1. A version of the Operation that has been made relative to the SyncPoint location.\r\n *   2. A WriteTreeRef of any writes we have cached at the SyncPoint location.\r\n *   3. A snapshot Node with cached server data, if we have it.\r\n *\r\n * - We concatenate all of the events returned by each SyncPoint and return the result.\r\n */\n\n\nfunction syncTreeApplyOperationToSyncPoints_(syncTree, operation) {\n  return syncTreeApplyOperationHelper_(operation, syncTree.syncPointTree_,\n  /*serverCache=*/\n  null, writeTreeChildWrites(syncTree.pendingWriteTree_, newEmptyPath()));\n}\n/**\r\n * Recursive helper for applyOperationToSyncPoints_\r\n */\n\n\nfunction syncTreeApplyOperationHelper_(operation, syncPointTree, serverCache, writesCache) {\n  if (pathIsEmpty(operation.path)) {\n    return syncTreeApplyOperationDescendantsHelper_(operation, syncPointTree, serverCache, writesCache);\n  } else {\n    const syncPoint = syncPointTree.get(newEmptyPath()); // If we don't have cached server data, see if we can get it from this SyncPoint.\n\n    if (serverCache == null && syncPoint != null) {\n      serverCache = syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n    }\n\n    let events = [];\n    const childName = pathGetFront(operation.path);\n    const childOperation = operation.operationForChild(childName);\n    const childTree = syncPointTree.children.get(childName);\n\n    if (childTree && childOperation) {\n      const childServerCache = serverCache ? serverCache.getImmediateChild(childName) : null;\n      const childWritesCache = writeTreeRefChild(writesCache, childName);\n      events = events.concat(syncTreeApplyOperationHelper_(childOperation, childTree, childServerCache, childWritesCache));\n    }\n\n    if (syncPoint) {\n      events = events.concat(syncPointApplyOperation(syncPoint, operation, writesCache, serverCache));\n    }\n\n    return events;\n  }\n}\n/**\r\n * Recursive helper for applyOperationToSyncPoints_\r\n */\n\n\nfunction syncTreeApplyOperationDescendantsHelper_(operation, syncPointTree, serverCache, writesCache) {\n  const syncPoint = syncPointTree.get(newEmptyPath()); // If we don't have cached server data, see if we can get it from this SyncPoint.\n\n  if (serverCache == null && syncPoint != null) {\n    serverCache = syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n\n  let events = [];\n  syncPointTree.children.inorderTraversal((childName, childTree) => {\n    const childServerCache = serverCache ? serverCache.getImmediateChild(childName) : null;\n    const childWritesCache = writeTreeRefChild(writesCache, childName);\n    const childOperation = operation.operationForChild(childName);\n\n    if (childOperation) {\n      events = events.concat(syncTreeApplyOperationDescendantsHelper_(childOperation, childTree, childServerCache, childWritesCache));\n    }\n  });\n\n  if (syncPoint) {\n    events = events.concat(syncPointApplyOperation(syncPoint, operation, writesCache, serverCache));\n  }\n\n  return events;\n}\n\nfunction syncTreeCreateListenerForView_(syncTree, view) {\n  const query = view.query;\n  const tag = syncTreeTagForQuery_(syncTree, query);\n  return {\n    hashFn: () => {\n      const cache = viewGetServerCache(view) || ChildrenNode.EMPTY_NODE;\n      return cache.hash();\n    },\n    onComplete: status => {\n      if (status === 'ok') {\n        if (tag) {\n          return syncTreeApplyTaggedListenComplete(syncTree, query._path, tag);\n        } else {\n          return syncTreeApplyListenComplete(syncTree, query._path);\n        }\n      } else {\n        // If a listen failed, kill all of the listeners here, not just the one that triggered the error.\n        // Note that this may need to be scoped to just this listener if we change permissions on filtered children\n        const error = errorForServerCode(status, query);\n        return syncTreeRemoveEventRegistration(syncTree, query,\n        /*eventRegistration*/\n        null, error);\n      }\n    }\n  };\n}\n/**\r\n * Return the tag associated with the given query.\r\n */\n\n\nfunction syncTreeTagForQuery_(syncTree, query) {\n  const queryKey = syncTreeMakeQueryKey_(query);\n  return syncTree.queryToTagMap.get(queryKey);\n}\n/**\r\n * Given a query, computes a \"queryKey\" suitable for use in our queryToTagMap_.\r\n */\n\n\nfunction syncTreeMakeQueryKey_(query) {\n  return query._path.toString() + '$' + query._queryIdentifier;\n}\n/**\r\n * Return the query associated with the given tag, if we have one\r\n */\n\n\nfunction syncTreeQueryKeyForTag_(syncTree, tag) {\n  return syncTree.tagToQueryMap.get(tag);\n}\n/**\r\n * Given a queryKey (created by makeQueryKey), parse it back into a path and queryId.\r\n */\n\n\nfunction syncTreeParseQueryKey_(queryKey) {\n  const splitIndex = queryKey.indexOf('$');\n  assert(splitIndex !== -1 && splitIndex < queryKey.length - 1, 'Bad queryKey.');\n  return {\n    queryId: queryKey.substr(splitIndex + 1),\n    path: new Path(queryKey.substr(0, splitIndex))\n  };\n}\n/**\r\n * A helper method to apply tagged operations\r\n */\n\n\nfunction syncTreeApplyTaggedOperation_(syncTree, queryPath, operation) {\n  const syncPoint = syncTree.syncPointTree_.get(queryPath);\n  assert(syncPoint, \"Missing sync point for query tag that we're tracking\");\n  const writesCache = writeTreeChildWrites(syncTree.pendingWriteTree_, queryPath);\n  return syncPointApplyOperation(syncPoint, operation, writesCache, null);\n}\n/**\r\n * This collapses multiple unfiltered views into a single view, since we only need a single\r\n * listener for them.\r\n */\n\n\nfunction syncTreeCollectDistinctViewsForSubTree_(subtree) {\n  return subtree.fold((relativePath, maybeChildSyncPoint, childMap) => {\n    if (maybeChildSyncPoint && syncPointHasCompleteView(maybeChildSyncPoint)) {\n      const completeView = syncPointGetCompleteView(maybeChildSyncPoint);\n      return [completeView];\n    } else {\n      // No complete view here, flatten any deeper listens into an array\n      let views = [];\n\n      if (maybeChildSyncPoint) {\n        views = syncPointGetQueryViews(maybeChildSyncPoint);\n      }\n\n      each(childMap, (_key, childViews) => {\n        views = views.concat(childViews);\n      });\n      return views;\n    }\n  });\n}\n/**\r\n * Normalizes a query to a query we send the server for listening\r\n *\r\n * @returns The normalized query\r\n */\n\n\nfunction syncTreeQueryForListening_(query) {\n  if (query._queryParams.loadsAllData() && !query._queryParams.isDefault()) {\n    // We treat queries that load all data as default queries\n    // Cast is necessary because ref() technically returns Firebase which is actually fb.api.Firebase which inherits\n    // from Query\n    return new (syncTreeGetReferenceConstructor())(query._repo, query._path);\n  } else {\n    return query;\n  }\n}\n\nfunction syncTreeRemoveTags_(syncTree, queries) {\n  for (let j = 0; j < queries.length; ++j) {\n    const removedQuery = queries[j];\n\n    if (!removedQuery._queryParams.loadsAllData()) {\n      // We should have a tag for this\n      const removedQueryKey = syncTreeMakeQueryKey_(removedQuery);\n      const removedQueryTag = syncTree.queryToTagMap.get(removedQueryKey);\n      syncTree.queryToTagMap.delete(removedQueryKey);\n      syncTree.tagToQueryMap.delete(removedQueryTag);\n    }\n  }\n}\n/**\r\n * Static accessor for query tags.\r\n */\n\n\nfunction syncTreeGetNextQueryTag_() {\n  return syncTreeNextQueryTag_++;\n}\n/**\r\n * For a given new listen, manage the de-duplication of outstanding subscriptions.\r\n *\r\n * @returns This method can return events to support synchronous data sources\r\n */\n\n\nfunction syncTreeSetupListener_(syncTree, query, view) {\n  const path = query._path;\n  const tag = syncTreeTagForQuery_(syncTree, query);\n  const listener = syncTreeCreateListenerForView_(syncTree, view);\n  const events = syncTree.listenProvider_.startListening(syncTreeQueryForListening_(query), tag, listener.hashFn, listener.onComplete);\n  const subtree = syncTree.syncPointTree_.subtree(path); // The root of this subtree has our query. We're here because we definitely need to send a listen for that, but we\n  // may need to shadow other listens as well.\n\n  if (tag) {\n    assert(!syncPointHasCompleteView(subtree.value), \"If we're adding a query, it shouldn't be shadowed\");\n  } else {\n    // Shadow everything at or below this location, this is a default listener.\n    const queriesToStop = subtree.fold((relativePath, maybeChildSyncPoint, childMap) => {\n      if (!pathIsEmpty(relativePath) && maybeChildSyncPoint && syncPointHasCompleteView(maybeChildSyncPoint)) {\n        return [syncPointGetCompleteView(maybeChildSyncPoint).query];\n      } else {\n        // No default listener here, flatten any deeper queries into an array\n        let queries = [];\n\n        if (maybeChildSyncPoint) {\n          queries = queries.concat(syncPointGetQueryViews(maybeChildSyncPoint).map(view => view.query));\n        }\n\n        each(childMap, (_key, childQueries) => {\n          queries = queries.concat(childQueries);\n        });\n        return queries;\n      }\n    });\n\n    for (let i = 0; i < queriesToStop.length; ++i) {\n      const queryToStop = queriesToStop[i];\n      syncTree.listenProvider_.stopListening(syncTreeQueryForListening_(queryToStop), syncTreeTagForQuery_(syncTree, queryToStop));\n    }\n  }\n\n  return events;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nclass ExistingValueProvider {\n  constructor(node_) {\n    this.node_ = node_;\n  }\n\n  getImmediateChild(childName) {\n    const child = this.node_.getImmediateChild(childName);\n    return new ExistingValueProvider(child);\n  }\n\n  node() {\n    return this.node_;\n  }\n\n}\n\nclass DeferredValueProvider {\n  constructor(syncTree, path) {\n    this.syncTree_ = syncTree;\n    this.path_ = path;\n  }\n\n  getImmediateChild(childName) {\n    const childPath = pathChild(this.path_, childName);\n    return new DeferredValueProvider(this.syncTree_, childPath);\n  }\n\n  node() {\n    return syncTreeCalcCompleteEventCache(this.syncTree_, this.path_);\n  }\n\n}\n/**\r\n * Generate placeholders for deferred values.\r\n */\n\n\nconst generateWithValues = function (values) {\n  values = values || {};\n  values['timestamp'] = values['timestamp'] || new Date().getTime();\n  return values;\n};\n/**\r\n * Value to use when firing local events. When writing server values, fire\r\n * local events with an approximate value, otherwise return value as-is.\r\n */\n\n\nconst resolveDeferredLeafValue = function (value, existingVal, serverValues) {\n  if (!value || typeof value !== 'object') {\n    return value;\n  }\n\n  assert('.sv' in value, 'Unexpected leaf node or priority contents');\n\n  if (typeof value['.sv'] === 'string') {\n    return resolveScalarDeferredValue(value['.sv'], existingVal, serverValues);\n  } else if (typeof value['.sv'] === 'object') {\n    return resolveComplexDeferredValue(value['.sv'], existingVal);\n  } else {\n    assert(false, 'Unexpected server value: ' + JSON.stringify(value, null, 2));\n  }\n};\n\nconst resolveScalarDeferredValue = function (op, existing, serverValues) {\n  switch (op) {\n    case 'timestamp':\n      return serverValues['timestamp'];\n\n    default:\n      assert(false, 'Unexpected server value: ' + op);\n  }\n};\n\nconst resolveComplexDeferredValue = function (op, existing, unused) {\n  if (!op.hasOwnProperty('increment')) {\n    assert(false, 'Unexpected server value: ' + JSON.stringify(op, null, 2));\n  }\n\n  const delta = op['increment'];\n\n  if (typeof delta !== 'number') {\n    assert(false, 'Unexpected increment value: ' + delta);\n  }\n\n  const existingNode = existing.node();\n  assert(existingNode !== null && typeof existingNode !== 'undefined', 'Expected ChildrenNode.EMPTY_NODE for nulls'); // Incrementing a non-number sets the value to the incremented amount\n\n  if (!existingNode.isLeafNode()) {\n    return delta;\n  }\n\n  const leaf = existingNode;\n  const existingVal = leaf.getValue();\n\n  if (typeof existingVal !== 'number') {\n    return delta;\n  } // No need to do over/underflow arithmetic here because JS only handles floats under the covers\n\n\n  return existingVal + delta;\n};\n/**\r\n * Recursively replace all deferred values and priorities in the tree with the\r\n * specified generated replacement values.\r\n * @param path - path to which write is relative\r\n * @param node - new data written at path\r\n * @param syncTree - current data\r\n */\n\n\nconst resolveDeferredValueTree = function (path, node, syncTree, serverValues) {\n  return resolveDeferredValue(node, new DeferredValueProvider(syncTree, path), serverValues);\n};\n/**\r\n * Recursively replace all deferred values and priorities in the node with the\r\n * specified generated replacement values.  If there are no server values in the node,\r\n * it'll be returned as-is.\r\n */\n\n\nconst resolveDeferredValueSnapshot = function (node, existing, serverValues) {\n  return resolveDeferredValue(node, new ExistingValueProvider(existing), serverValues);\n};\n\nfunction resolveDeferredValue(node, existingVal, serverValues) {\n  const rawPri = node.getPriority().val();\n  const priority = resolveDeferredLeafValue(rawPri, existingVal.getImmediateChild('.priority'), serverValues);\n  let newNode;\n\n  if (node.isLeafNode()) {\n    const leafNode = node;\n    const value = resolveDeferredLeafValue(leafNode.getValue(), existingVal, serverValues);\n\n    if (value !== leafNode.getValue() || priority !== leafNode.getPriority().val()) {\n      return new LeafNode(value, nodeFromJSON(priority));\n    } else {\n      return node;\n    }\n  } else {\n    const childrenNode = node;\n    newNode = childrenNode;\n\n    if (priority !== childrenNode.getPriority().val()) {\n      newNode = newNode.updatePriority(new LeafNode(priority));\n    }\n\n    childrenNode.forEachChild(PRIORITY_INDEX, (childName, childNode) => {\n      const newChildNode = resolveDeferredValue(childNode, existingVal.getImmediateChild(childName), serverValues);\n\n      if (newChildNode !== childNode) {\n        newNode = newNode.updateImmediateChild(childName, newChildNode);\n      }\n    });\n    return newNode;\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A light-weight tree, traversable by path.  Nodes can have both values and children.\r\n * Nodes are not enumerated (by forEachChild) unless they have a value or non-empty\r\n * children.\r\n */\n\n\nclass Tree {\n  /**\r\n   * @param name - Optional name of the node.\r\n   * @param parent - Optional parent node.\r\n   * @param node - Optional node to wrap.\r\n   */\n  constructor(name = '', parent = null, node = {\n    children: {},\n    childCount: 0\n  }) {\n    this.name = name;\n    this.parent = parent;\n    this.node = node;\n  }\n\n}\n/**\r\n * Returns a sub-Tree for the given path.\r\n *\r\n * @param pathObj - Path to look up.\r\n * @returns Tree for path.\r\n */\n\n\nfunction treeSubTree(tree, pathObj) {\n  // TODO: Require pathObj to be Path?\n  let path = pathObj instanceof Path ? pathObj : new Path(pathObj);\n  let child = tree,\n      next = pathGetFront(path);\n\n  while (next !== null) {\n    const childNode = safeGet(child.node.children, next) || {\n      children: {},\n      childCount: 0\n    };\n    child = new Tree(next, child, childNode);\n    path = pathPopFront(path);\n    next = pathGetFront(path);\n  }\n\n  return child;\n}\n/**\r\n * Returns the data associated with this tree node.\r\n *\r\n * @returns The data or null if no data exists.\r\n */\n\n\nfunction treeGetValue(tree) {\n  return tree.node.value;\n}\n/**\r\n * Sets data to this tree node.\r\n *\r\n * @param value - Value to set.\r\n */\n\n\nfunction treeSetValue(tree, value) {\n  tree.node.value = value;\n  treeUpdateParents(tree);\n}\n/**\r\n * @returns Whether the tree has any children.\r\n */\n\n\nfunction treeHasChildren(tree) {\n  return tree.node.childCount > 0;\n}\n/**\r\n * @returns Whethe rthe tree is empty (no value or children).\r\n */\n\n\nfunction treeIsEmpty(tree) {\n  return treeGetValue(tree) === undefined && !treeHasChildren(tree);\n}\n/**\r\n * Calls action for each child of this tree node.\r\n *\r\n * @param action - Action to be called for each child.\r\n */\n\n\nfunction treeForEachChild(tree, action) {\n  each(tree.node.children, (child, childTree) => {\n    action(new Tree(child, tree, childTree));\n  });\n}\n/**\r\n * Does a depth-first traversal of this node's descendants, calling action for each one.\r\n *\r\n * @param action - Action to be called for each child.\r\n * @param includeSelf - Whether to call action on this node as well. Defaults to\r\n *   false.\r\n * @param childrenFirst - Whether to call action on children before calling it on\r\n *   parent.\r\n */\n\n\nfunction treeForEachDescendant(tree, action, includeSelf, childrenFirst) {\n  if (includeSelf && !childrenFirst) {\n    action(tree);\n  }\n\n  treeForEachChild(tree, child => {\n    treeForEachDescendant(child, action, true, childrenFirst);\n  });\n\n  if (includeSelf && childrenFirst) {\n    action(tree);\n  }\n}\n/**\r\n * Calls action on each ancestor node.\r\n *\r\n * @param action - Action to be called on each parent; return\r\n *   true to abort.\r\n * @param includeSelf - Whether to call action on this node as well.\r\n * @returns true if the action callback returned true.\r\n */\n\n\nfunction treeForEachAncestor(tree, action, includeSelf) {\n  let node = includeSelf ? tree : tree.parent;\n\n  while (node !== null) {\n    if (action(node)) {\n      return true;\n    }\n\n    node = node.parent;\n  }\n\n  return false;\n}\n/**\r\n * @returns The path of this tree node, as a Path.\r\n */\n\n\nfunction treeGetPath(tree) {\n  return new Path(tree.parent === null ? tree.name : treeGetPath(tree.parent) + '/' + tree.name);\n}\n/**\r\n * Adds or removes this child from its parent based on whether it's empty or not.\r\n */\n\n\nfunction treeUpdateParents(tree) {\n  if (tree.parent !== null) {\n    treeUpdateChild(tree.parent, tree.name, tree);\n  }\n}\n/**\r\n * Adds or removes the passed child to this tree node, depending on whether it's empty.\r\n *\r\n * @param childName - The name of the child to update.\r\n * @param child - The child to update.\r\n */\n\n\nfunction treeUpdateChild(tree, childName, child) {\n  const childEmpty = treeIsEmpty(child);\n  const childExists = contains(tree.node.children, childName);\n\n  if (childEmpty && childExists) {\n    delete tree.node.children[childName];\n    tree.node.childCount--;\n    treeUpdateParents(tree);\n  } else if (!childEmpty && !childExists) {\n    tree.node.children[childName] = child.node;\n    tree.node.childCount++;\n    treeUpdateParents(tree);\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * True for invalid Firebase keys\r\n */\n\n\nconst INVALID_KEY_REGEX_ = /[\\[\\].#$\\/\\u0000-\\u001F\\u007F]/;\n/**\r\n * True for invalid Firebase paths.\r\n * Allows '/' in paths.\r\n */\n\nconst INVALID_PATH_REGEX_ = /[\\[\\].#$\\u0000-\\u001F\\u007F]/;\n/**\r\n * Maximum number of characters to allow in leaf value\r\n */\n\nconst MAX_LEAF_SIZE_ = 10 * 1024 * 1024;\n\nconst isValidKey = function (key) {\n  return typeof key === 'string' && key.length !== 0 && !INVALID_KEY_REGEX_.test(key);\n};\n\nconst isValidPathString = function (pathString) {\n  return typeof pathString === 'string' && pathString.length !== 0 && !INVALID_PATH_REGEX_.test(pathString);\n};\n\nconst isValidRootPathString = function (pathString) {\n  if (pathString) {\n    // Allow '/.info/' at the beginning.\n    pathString = pathString.replace(/^\\/*\\.info(\\/|$)/, '/');\n  }\n\n  return isValidPathString(pathString);\n};\n\nconst isValidPriority = function (priority) {\n  return priority === null || typeof priority === 'string' || typeof priority === 'number' && !isInvalidJSONNumber(priority) || priority && typeof priority === 'object' && // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  contains(priority, '.sv');\n};\n/**\r\n * Pre-validate a datum passed as an argument to Firebase function.\r\n */\n\n\nconst validateFirebaseDataArg = function (fnName, value, path, optional) {\n  if (optional && value === undefined) {\n    return;\n  }\n\n  validateFirebaseData(errorPrefix(fnName, 'value'), value, path);\n};\n/**\r\n * Validate a data object client-side before sending to server.\r\n */\n\n\nconst validateFirebaseData = function (errorPrefix, data, path_) {\n  const path = path_ instanceof Path ? new ValidationPath(path_, errorPrefix) : path_;\n\n  if (data === undefined) {\n    throw new Error(errorPrefix + 'contains undefined ' + validationPathToErrorString(path));\n  }\n\n  if (typeof data === 'function') {\n    throw new Error(errorPrefix + 'contains a function ' + validationPathToErrorString(path) + ' with contents = ' + data.toString());\n  }\n\n  if (isInvalidJSONNumber(data)) {\n    throw new Error(errorPrefix + 'contains ' + data.toString() + ' ' + validationPathToErrorString(path));\n  } // Check max leaf size, but try to avoid the utf8 conversion if we can.\n\n\n  if (typeof data === 'string' && data.length > MAX_LEAF_SIZE_ / 3 && stringLength(data) > MAX_LEAF_SIZE_) {\n    throw new Error(errorPrefix + 'contains a string greater than ' + MAX_LEAF_SIZE_ + ' utf8 bytes ' + validationPathToErrorString(path) + \" ('\" + data.substring(0, 50) + \"...')\");\n  } // TODO = Perf = Consider combining the recursive validation of keys into NodeFromJSON\n  // to save extra walking of large objects.\n\n\n  if (data && typeof data === 'object') {\n    let hasDotValue = false;\n    let hasActualChild = false;\n    each(data, (key, value) => {\n      if (key === '.value') {\n        hasDotValue = true;\n      } else if (key !== '.priority' && key !== '.sv') {\n        hasActualChild = true;\n\n        if (!isValidKey(key)) {\n          throw new Error(errorPrefix + ' contains an invalid key (' + key + ') ' + validationPathToErrorString(path) + '.  Keys must be non-empty strings ' + 'and can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\"');\n        }\n      }\n\n      validationPathPush(path, key);\n      validateFirebaseData(errorPrefix, value, path);\n      validationPathPop(path);\n    });\n\n    if (hasDotValue && hasActualChild) {\n      throw new Error(errorPrefix + ' contains \".value\" child ' + validationPathToErrorString(path) + ' in addition to actual children.');\n    }\n  }\n};\n/**\r\n * Pre-validate paths passed in the firebase function.\r\n */\n\n\nconst validateFirebaseMergePaths = function (errorPrefix, mergePaths) {\n  let i, curPath;\n\n  for (i = 0; i < mergePaths.length; i++) {\n    curPath = mergePaths[i];\n    const keys = pathSlice(curPath);\n\n    for (let j = 0; j < keys.length; j++) {\n      if (keys[j] === '.priority' && j === keys.length - 1) ;else if (!isValidKey(keys[j])) {\n        throw new Error(errorPrefix + 'contains an invalid key (' + keys[j] + ') in path ' + curPath.toString() + '. Keys must be non-empty strings ' + 'and can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\"');\n      }\n    }\n  } // Check that update keys are not descendants of each other.\n  // We rely on the property that sorting guarantees that ancestors come\n  // right before descendants.\n\n\n  mergePaths.sort(pathCompare);\n  let prevPath = null;\n\n  for (i = 0; i < mergePaths.length; i++) {\n    curPath = mergePaths[i];\n\n    if (prevPath !== null && pathContains(prevPath, curPath)) {\n      throw new Error(errorPrefix + 'contains a path ' + prevPath.toString() + ' that is ancestor of another path ' + curPath.toString());\n    }\n\n    prevPath = curPath;\n  }\n};\n/**\r\n * pre-validate an object passed as an argument to firebase function (\r\n * must be an object - e.g. for firebase.update()).\r\n */\n\n\nconst validateFirebaseMergeDataArg = function (fnName, data, path, optional) {\n  if (optional && data === undefined) {\n    return;\n  }\n\n  const errorPrefix$1 = errorPrefix(fnName, 'values');\n\n  if (!(data && typeof data === 'object') || Array.isArray(data)) {\n    throw new Error(errorPrefix$1 + ' must be an object containing the children to replace.');\n  }\n\n  const mergePaths = [];\n  each(data, (key, value) => {\n    const curPath = new Path(key);\n    validateFirebaseData(errorPrefix$1, value, pathChild(path, curPath));\n\n    if (pathGetBack(curPath) === '.priority') {\n      if (!isValidPriority(value)) {\n        throw new Error(errorPrefix$1 + \"contains an invalid value for '\" + curPath.toString() + \"', which must be a valid \" + 'Firebase priority (a string, finite number, server value, or null).');\n      }\n    }\n\n    mergePaths.push(curPath);\n  });\n  validateFirebaseMergePaths(errorPrefix$1, mergePaths);\n};\n\nconst validatePriority = function (fnName, priority, optional) {\n  if (optional && priority === undefined) {\n    return;\n  }\n\n  if (isInvalidJSONNumber(priority)) {\n    throw new Error(errorPrefix(fnName, 'priority') + 'is ' + priority.toString() + ', but must be a valid Firebase priority (a string, finite number, ' + 'server value, or null).');\n  } // Special case to allow importing data with a .sv.\n\n\n  if (!isValidPriority(priority)) {\n    throw new Error(errorPrefix(fnName, 'priority') + 'must be a valid Firebase priority ' + '(a string, finite number, server value, or null).');\n  }\n};\n\nconst validateKey = function (fnName, argumentName, key, optional) {\n  if (optional && key === undefined) {\n    return;\n  }\n\n  if (!isValidKey(key)) {\n    throw new Error(errorPrefix(fnName, argumentName) + 'was an invalid key = \"' + key + '\".  Firebase keys must be non-empty strings and ' + 'can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\").');\n  }\n};\n/**\r\n * @internal\r\n */\n\n\nconst validatePathString = function (fnName, argumentName, pathString, optional) {\n  if (optional && pathString === undefined) {\n    return;\n  }\n\n  if (!isValidPathString(pathString)) {\n    throw new Error(errorPrefix(fnName, argumentName) + 'was an invalid path = \"' + pathString + '\". Paths must be non-empty strings and ' + 'can\\'t contain \".\", \"#\", \"$\", \"[\", or \"]\"');\n  }\n};\n\nconst validateRootPathString = function (fnName, argumentName, pathString, optional) {\n  if (pathString) {\n    // Allow '/.info/' at the beginning.\n    pathString = pathString.replace(/^\\/*\\.info(\\/|$)/, '/');\n  }\n\n  validatePathString(fnName, argumentName, pathString, optional);\n};\n/**\r\n * @internal\r\n */\n\n\nconst validateWritablePath = function (fnName, path) {\n  if (pathGetFront(path) === '.info') {\n    throw new Error(fnName + \" failed = Can't modify data under /.info/\");\n  }\n};\n\nconst validateUrl = function (fnName, parsedUrl) {\n  // TODO = Validate server better.\n  const pathString = parsedUrl.path.toString();\n\n  if (!(typeof parsedUrl.repoInfo.host === 'string') || parsedUrl.repoInfo.host.length === 0 || !isValidKey(parsedUrl.repoInfo.namespace) && parsedUrl.repoInfo.host.split(':')[0] !== 'localhost' || pathString.length !== 0 && !isValidRootPathString(pathString)) {\n    throw new Error(errorPrefix(fnName, 'url') + 'must be a valid firebase URL and ' + 'the path can\\'t contain \".\", \"#\", \"$\", \"[\", or \"]\".');\n  }\n};\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * The event queue serves a few purposes:\r\n * 1. It ensures we maintain event order in the face of event callbacks doing operations that result in more\r\n *    events being queued.\r\n * 2. raiseQueuedEvents() handles being called reentrantly nicely.  That is, if in the course of raising events,\r\n *    raiseQueuedEvents() is called again, the \"inner\" call will pick up raising events where the \"outer\" call\r\n *    left off, ensuring that the events are still raised synchronously and in order.\r\n * 3. You can use raiseEventsAtPath and raiseEventsForChangedPath to ensure only relevant previously-queued\r\n *    events are raised synchronously.\r\n *\r\n * NOTE: This can all go away if/when we move to async events.\r\n *\r\n */\n\n\nclass EventQueue {\n  constructor() {\n    this.eventLists_ = [];\n    /**\r\n     * Tracks recursion depth of raiseQueuedEvents_, for debugging purposes.\r\n     */\n\n    this.recursionDepth_ = 0;\n  }\n\n}\n/**\r\n * @param eventDataList - The new events to queue.\r\n */\n\n\nfunction eventQueueQueueEvents(eventQueue, eventDataList) {\n  // We group events by path, storing them in a single EventList, to make it easier to skip over them quickly.\n  let currList = null;\n\n  for (let i = 0; i < eventDataList.length; i++) {\n    const data = eventDataList[i];\n    const path = data.getPath();\n\n    if (currList !== null && !pathEquals(path, currList.path)) {\n      eventQueue.eventLists_.push(currList);\n      currList = null;\n    }\n\n    if (currList === null) {\n      currList = {\n        events: [],\n        path\n      };\n    }\n\n    currList.events.push(data);\n  }\n\n  if (currList) {\n    eventQueue.eventLists_.push(currList);\n  }\n}\n/**\r\n * Queues the specified events and synchronously raises all events (including previously queued ones)\r\n * for the specified path.\r\n *\r\n * It is assumed that the new events are all for the specified path.\r\n *\r\n * @param path - The path to raise events for.\r\n * @param eventDataList - The new events to raise.\r\n */\n\n\nfunction eventQueueRaiseEventsAtPath(eventQueue, path, eventDataList) {\n  eventQueueQueueEvents(eventQueue, eventDataList);\n  eventQueueRaiseQueuedEventsMatchingPredicate(eventQueue, eventPath => pathEquals(eventPath, path));\n}\n/**\r\n * Queues the specified events and synchronously raises all events (including previously queued ones) for\r\n * locations related to the specified change path (i.e. all ancestors and descendants).\r\n *\r\n * It is assumed that the new events are all related (ancestor or descendant) to the specified path.\r\n *\r\n * @param changedPath - The path to raise events for.\r\n * @param eventDataList - The events to raise\r\n */\n\n\nfunction eventQueueRaiseEventsForChangedPath(eventQueue, changedPath, eventDataList) {\n  eventQueueQueueEvents(eventQueue, eventDataList);\n  eventQueueRaiseQueuedEventsMatchingPredicate(eventQueue, eventPath => pathContains(eventPath, changedPath) || pathContains(changedPath, eventPath));\n}\n\nfunction eventQueueRaiseQueuedEventsMatchingPredicate(eventQueue, predicate) {\n  eventQueue.recursionDepth_++;\n  let sentAll = true;\n\n  for (let i = 0; i < eventQueue.eventLists_.length; i++) {\n    const eventList = eventQueue.eventLists_[i];\n\n    if (eventList) {\n      const eventPath = eventList.path;\n\n      if (predicate(eventPath)) {\n        eventListRaise(eventQueue.eventLists_[i]);\n        eventQueue.eventLists_[i] = null;\n      } else {\n        sentAll = false;\n      }\n    }\n  }\n\n  if (sentAll) {\n    eventQueue.eventLists_ = [];\n  }\n\n  eventQueue.recursionDepth_--;\n}\n/**\r\n * Iterates through the list and raises each event\r\n */\n\n\nfunction eventListRaise(eventList) {\n  for (let i = 0; i < eventList.events.length; i++) {\n    const eventData = eventList.events[i];\n\n    if (eventData !== null) {\n      eventList.events[i] = null;\n      const eventFn = eventData.getEventRunner();\n\n      if (logger) {\n        log('event: ' + eventData.toString());\n      }\n\n      exceptionGuard(eventFn);\n    }\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nconst INTERRUPT_REASON = 'repo_interrupt';\n/**\r\n * If a transaction does not succeed after 25 retries, we abort it. Among other\r\n * things this ensure that if there's ever a bug causing a mismatch between\r\n * client / server hashes for some data, we won't retry indefinitely.\r\n */\n\nconst MAX_TRANSACTION_RETRIES = 25;\n/**\r\n * A connection to a single data repository.\r\n */\n\nclass Repo {\n  constructor(repoInfo_, forceRestClient_, authTokenProvider_, appCheckProvider_) {\n    this.repoInfo_ = repoInfo_;\n    this.forceRestClient_ = forceRestClient_;\n    this.authTokenProvider_ = authTokenProvider_;\n    this.appCheckProvider_ = appCheckProvider_;\n    this.dataUpdateCount = 0;\n    this.statsListener_ = null;\n    this.eventQueue_ = new EventQueue();\n    this.nextWriteId_ = 1;\n    this.interceptServerDataCallback_ = null;\n    /** A list of data pieces and paths to be set when this client disconnects. */\n\n    this.onDisconnect_ = newSparseSnapshotTree();\n    /** Stores queues of outstanding transactions for Firebase locations. */\n\n    this.transactionQueueTree_ = new Tree(); // TODO: This should be @private but it's used by test_access.js and internal.js\n\n    this.persistentConnection_ = null; // This key is intentionally not updated if RepoInfo is later changed or replaced\n\n    this.key = this.repoInfo_.toURLString();\n  }\n  /**\r\n   * @returns The URL corresponding to the root of this Firebase.\r\n   */\n\n\n  toString() {\n    return (this.repoInfo_.secure ? 'https://' : 'http://') + this.repoInfo_.host;\n  }\n\n}\n\nfunction repoStart(repo, appId, authOverride) {\n  repo.stats_ = statsManagerGetCollection(repo.repoInfo_);\n\n  if (repo.forceRestClient_ || beingCrawled()) {\n    repo.server_ = new ReadonlyRestClient(repo.repoInfo_, (pathString, data, isMerge, tag) => {\n      repoOnDataUpdate(repo, pathString, data, isMerge, tag);\n    }, repo.authTokenProvider_, repo.appCheckProvider_); // Minor hack: Fire onConnect immediately, since there's no actual connection.\n\n    setTimeout(() => repoOnConnectStatus(repo,\n    /* connectStatus= */\n    true), 0);\n  } else {\n    // Validate authOverride\n    if (typeof authOverride !== 'undefined' && authOverride !== null) {\n      if (typeof authOverride !== 'object') {\n        throw new Error('Only objects are supported for option databaseAuthVariableOverride');\n      }\n\n      try {\n        stringify(authOverride);\n      } catch (e) {\n        throw new Error('Invalid authOverride provided: ' + e);\n      }\n    }\n\n    repo.persistentConnection_ = new PersistentConnection(repo.repoInfo_, appId, (pathString, data, isMerge, tag) => {\n      repoOnDataUpdate(repo, pathString, data, isMerge, tag);\n    }, connectStatus => {\n      repoOnConnectStatus(repo, connectStatus);\n    }, updates => {\n      repoOnServerInfoUpdate(repo, updates);\n    }, repo.authTokenProvider_, repo.appCheckProvider_, authOverride);\n    repo.server_ = repo.persistentConnection_;\n  }\n\n  repo.authTokenProvider_.addTokenChangeListener(token => {\n    repo.server_.refreshAuthToken(token);\n  });\n  repo.appCheckProvider_.addTokenChangeListener(result => {\n    repo.server_.refreshAppCheckToken(result.token);\n  }); // In the case of multiple Repos for the same repoInfo (i.e. there are multiple Firebase.Contexts being used),\n  // we only want to create one StatsReporter.  As such, we'll report stats over the first Repo created.\n\n  repo.statsReporter_ = statsManagerGetOrCreateReporter(repo.repoInfo_, () => new StatsReporter(repo.stats_, repo.server_)); // Used for .info.\n\n  repo.infoData_ = new SnapshotHolder();\n  repo.infoSyncTree_ = new SyncTree({\n    startListening: (query, tag, currentHashFn, onComplete) => {\n      let infoEvents = [];\n      const node = repo.infoData_.getNode(query._path); // This is possibly a hack, but we have different semantics for .info endpoints. We don't raise null events\n      // on initial data...\n\n      if (!node.isEmpty()) {\n        infoEvents = syncTreeApplyServerOverwrite(repo.infoSyncTree_, query._path, node);\n        setTimeout(() => {\n          onComplete('ok');\n        }, 0);\n      }\n\n      return infoEvents;\n    },\n    stopListening: () => {}\n  });\n  repoUpdateInfo(repo, 'connected', false);\n  repo.serverSyncTree_ = new SyncTree({\n    startListening: (query, tag, currentHashFn, onComplete) => {\n      repo.server_.listen(query, currentHashFn, tag, (status, data) => {\n        const events = onComplete(status, data);\n        eventQueueRaiseEventsForChangedPath(repo.eventQueue_, query._path, events);\n      }); // No synchronous events for network-backed sync trees\n\n      return [];\n    },\n    stopListening: (query, tag) => {\n      repo.server_.unlisten(query, tag);\n    }\n  });\n}\n/**\r\n * @returns The time in milliseconds, taking the server offset into account if we have one.\r\n */\n\n\nfunction repoServerTime(repo) {\n  const offsetNode = repo.infoData_.getNode(new Path('.info/serverTimeOffset'));\n  const offset = offsetNode.val() || 0;\n  return new Date().getTime() + offset;\n}\n/**\r\n * Generate ServerValues using some variables from the repo object.\r\n */\n\n\nfunction repoGenerateServerValues(repo) {\n  return generateWithValues({\n    timestamp: repoServerTime(repo)\n  });\n}\n/**\r\n * Called by realtime when we get new messages from the server.\r\n */\n\n\nfunction repoOnDataUpdate(repo, pathString, data, isMerge, tag) {\n  // For testing.\n  repo.dataUpdateCount++;\n  const path = new Path(pathString);\n  data = repo.interceptServerDataCallback_ ? repo.interceptServerDataCallback_(pathString, data) : data;\n  let events = [];\n\n  if (tag) {\n    if (isMerge) {\n      const taggedChildren = map(data, raw => nodeFromJSON(raw));\n      events = syncTreeApplyTaggedQueryMerge(repo.serverSyncTree_, path, taggedChildren, tag);\n    } else {\n      const taggedSnap = nodeFromJSON(data);\n      events = syncTreeApplyTaggedQueryOverwrite(repo.serverSyncTree_, path, taggedSnap, tag);\n    }\n  } else if (isMerge) {\n    const changedChildren = map(data, raw => nodeFromJSON(raw));\n    events = syncTreeApplyServerMerge(repo.serverSyncTree_, path, changedChildren);\n  } else {\n    const snap = nodeFromJSON(data);\n    events = syncTreeApplyServerOverwrite(repo.serverSyncTree_, path, snap);\n  }\n\n  let affectedPath = path;\n\n  if (events.length > 0) {\n    // Since we have a listener outstanding for each transaction, receiving any events\n    // is a proxy for some change having occurred.\n    affectedPath = repoRerunTransactions(repo, path);\n  }\n\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, affectedPath, events);\n}\n\nfunction repoOnConnectStatus(repo, connectStatus) {\n  repoUpdateInfo(repo, 'connected', connectStatus);\n\n  if (connectStatus === false) {\n    repoRunOnDisconnectEvents(repo);\n  }\n}\n\nfunction repoOnServerInfoUpdate(repo, updates) {\n  each(updates, (key, value) => {\n    repoUpdateInfo(repo, key, value);\n  });\n}\n\nfunction repoUpdateInfo(repo, pathString, value) {\n  const path = new Path('/.info/' + pathString);\n  const newNode = nodeFromJSON(value);\n  repo.infoData_.updateSnapshot(path, newNode);\n  const events = syncTreeApplyServerOverwrite(repo.infoSyncTree_, path, newNode);\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n}\n\nfunction repoGetNextWriteId(repo) {\n  return repo.nextWriteId_++;\n}\n/**\r\n * The purpose of `getValue` is to return the latest known value\r\n * satisfying `query`.\r\n *\r\n * This method will first check for in-memory cached values\r\n * belonging to active listeners. If they are found, such values\r\n * are considered to be the most up-to-date.\r\n *\r\n * If the client is not connected, this method will try to\r\n * establish a connection and request the value for `query`. If\r\n * the client is not able to retrieve the query result, it reports\r\n * an error.\r\n *\r\n * @param query - The query to surface a value for.\r\n */\n\n\nfunction repoGetValue(repo, query) {\n  // Only active queries are cached. There is no persisted cache.\n  const cached = syncTreeGetServerValue(repo.serverSyncTree_, query);\n\n  if (cached != null) {\n    return Promise.resolve(cached);\n  }\n\n  return repo.server_.get(query).then(payload => {\n    const node = nodeFromJSON(payload).withIndex(query._queryParams.getIndex()); // if this is a filtered query, then overwrite at path\n\n    if (query._queryParams.loadsAllData()) {\n      syncTreeApplyServerOverwrite(repo.serverSyncTree_, query._path, node);\n    } else {\n      // Simulate `syncTreeAddEventRegistration` without events/listener setup.\n      // We do this (along with the syncTreeRemoveEventRegistration` below) so that\n      // `repoGetValue` results have the same cache effects as initial listener(s)\n      // updates.\n      const tag = syncTreeRegisterQuery(repo.serverSyncTree_, query);\n      syncTreeApplyTaggedQueryOverwrite(repo.serverSyncTree_, query._path, node, tag); // Call `syncTreeRemoveEventRegistration` with a null event registration, since there is none.\n      // Note: The below code essentially unregisters the query and cleans up any views/syncpoints temporarily created above.\n    }\n\n    const cancels = syncTreeRemoveEventRegistration(repo.serverSyncTree_, query, null);\n\n    if (cancels.length > 0) {\n      repoLog(repo, 'unexpected cancel events in repoGetValue');\n    }\n\n    return node;\n  }, err => {\n    repoLog(repo, 'get for query ' + stringify(query) + ' failed: ' + err);\n    return Promise.reject(new Error(err));\n  });\n}\n\nfunction repoSetWithPriority(repo, path, newVal, newPriority, onComplete) {\n  repoLog(repo, 'set', {\n    path: path.toString(),\n    value: newVal,\n    priority: newPriority\n  }); // TODO: Optimize this behavior to either (a) store flag to skip resolving where possible and / or\n  // (b) store unresolved paths on JSON parse\n\n  const serverValues = repoGenerateServerValues(repo);\n  const newNodeUnresolved = nodeFromJSON(newVal, newPriority);\n  const existing = syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path);\n  const newNode = resolveDeferredValueSnapshot(newNodeUnresolved, existing, serverValues);\n  const writeId = repoGetNextWriteId(repo);\n  const events = syncTreeApplyUserOverwrite(repo.serverSyncTree_, path, newNode, writeId, true);\n  eventQueueQueueEvents(repo.eventQueue_, events);\n  repo.server_.put(path.toString(), newNodeUnresolved.val(\n  /*export=*/\n  true), (status, errorReason) => {\n    const success = status === 'ok';\n\n    if (!success) {\n      warn('set at ' + path + ' failed: ' + status);\n    }\n\n    const clearEvents = syncTreeAckUserWrite(repo.serverSyncTree_, writeId, !success);\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, clearEvents);\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n  const affectedPath = repoAbortTransactions(repo, path);\n  repoRerunTransactions(repo, affectedPath); // We queued the events above, so just flush the queue here\n\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, affectedPath, []);\n}\n\nfunction repoUpdate(repo, path, childrenToMerge, onComplete) {\n  repoLog(repo, 'update', {\n    path: path.toString(),\n    value: childrenToMerge\n  }); // Start with our existing data and merge each child into it.\n\n  let empty = true;\n  const serverValues = repoGenerateServerValues(repo);\n  const changedChildren = {};\n  each(childrenToMerge, (changedKey, changedValue) => {\n    empty = false;\n    changedChildren[changedKey] = resolveDeferredValueTree(pathChild(path, changedKey), nodeFromJSON(changedValue), repo.serverSyncTree_, serverValues);\n  });\n\n  if (!empty) {\n    const writeId = repoGetNextWriteId(repo);\n    const events = syncTreeApplyUserMerge(repo.serverSyncTree_, path, changedChildren, writeId);\n    eventQueueQueueEvents(repo.eventQueue_, events);\n    repo.server_.merge(path.toString(), childrenToMerge, (status, errorReason) => {\n      const success = status === 'ok';\n\n      if (!success) {\n        warn('update at ' + path + ' failed: ' + status);\n      }\n\n      const clearEvents = syncTreeAckUserWrite(repo.serverSyncTree_, writeId, !success);\n      const affectedPath = clearEvents.length > 0 ? repoRerunTransactions(repo, path) : path;\n      eventQueueRaiseEventsForChangedPath(repo.eventQueue_, affectedPath, clearEvents);\n      repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n    });\n    each(childrenToMerge, changedPath => {\n      const affectedPath = repoAbortTransactions(repo, pathChild(path, changedPath));\n      repoRerunTransactions(repo, affectedPath);\n    }); // We queued the events above, so just flush the queue here\n\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, []);\n  } else {\n    log(\"update() called with empty data.  Don't do anything.\");\n    repoCallOnCompleteCallback(repo, onComplete, 'ok', undefined);\n  }\n}\n/**\r\n * Applies all of the changes stored up in the onDisconnect_ tree.\r\n */\n\n\nfunction repoRunOnDisconnectEvents(repo) {\n  repoLog(repo, 'onDisconnectEvents');\n  const serverValues = repoGenerateServerValues(repo);\n  const resolvedOnDisconnectTree = newSparseSnapshotTree();\n  sparseSnapshotTreeForEachTree(repo.onDisconnect_, newEmptyPath(), (path, node) => {\n    const resolved = resolveDeferredValueTree(path, node, repo.serverSyncTree_, serverValues);\n    sparseSnapshotTreeRemember(resolvedOnDisconnectTree, path, resolved);\n  });\n  let events = [];\n  sparseSnapshotTreeForEachTree(resolvedOnDisconnectTree, newEmptyPath(), (path, snap) => {\n    events = events.concat(syncTreeApplyServerOverwrite(repo.serverSyncTree_, path, snap));\n    const affectedPath = repoAbortTransactions(repo, path);\n    repoRerunTransactions(repo, affectedPath);\n  });\n  repo.onDisconnect_ = newSparseSnapshotTree();\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, newEmptyPath(), events);\n}\n\nfunction repoOnDisconnectCancel(repo, path, onComplete) {\n  repo.server_.onDisconnectCancel(path.toString(), (status, errorReason) => {\n    if (status === 'ok') {\n      sparseSnapshotTreeForget(repo.onDisconnect_, path);\n    }\n\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n}\n\nfunction repoOnDisconnectSet(repo, path, value, onComplete) {\n  const newNode = nodeFromJSON(value);\n  repo.server_.onDisconnectPut(path.toString(), newNode.val(\n  /*export=*/\n  true), (status, errorReason) => {\n    if (status === 'ok') {\n      sparseSnapshotTreeRemember(repo.onDisconnect_, path, newNode);\n    }\n\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n}\n\nfunction repoOnDisconnectSetWithPriority(repo, path, value, priority, onComplete) {\n  const newNode = nodeFromJSON(value, priority);\n  repo.server_.onDisconnectPut(path.toString(), newNode.val(\n  /*export=*/\n  true), (status, errorReason) => {\n    if (status === 'ok') {\n      sparseSnapshotTreeRemember(repo.onDisconnect_, path, newNode);\n    }\n\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n}\n\nfunction repoOnDisconnectUpdate(repo, path, childrenToMerge, onComplete) {\n  if (isEmpty(childrenToMerge)) {\n    log(\"onDisconnect().update() called with empty data.  Don't do anything.\");\n    repoCallOnCompleteCallback(repo, onComplete, 'ok', undefined);\n    return;\n  }\n\n  repo.server_.onDisconnectMerge(path.toString(), childrenToMerge, (status, errorReason) => {\n    if (status === 'ok') {\n      each(childrenToMerge, (childName, childNode) => {\n        const newChildNode = nodeFromJSON(childNode);\n        sparseSnapshotTreeRemember(repo.onDisconnect_, pathChild(path, childName), newChildNode);\n      });\n    }\n\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n}\n\nfunction repoAddEventCallbackForQuery(repo, query, eventRegistration) {\n  let events;\n\n  if (pathGetFront(query._path) === '.info') {\n    events = syncTreeAddEventRegistration(repo.infoSyncTree_, query, eventRegistration);\n  } else {\n    events = syncTreeAddEventRegistration(repo.serverSyncTree_, query, eventRegistration);\n  }\n\n  eventQueueRaiseEventsAtPath(repo.eventQueue_, query._path, events);\n}\n\nfunction repoRemoveEventCallbackForQuery(repo, query, eventRegistration) {\n  // These are guaranteed not to raise events, since we're not passing in a cancelError. However, we can future-proof\n  // a little bit by handling the return values anyways.\n  let events;\n\n  if (pathGetFront(query._path) === '.info') {\n    events = syncTreeRemoveEventRegistration(repo.infoSyncTree_, query, eventRegistration);\n  } else {\n    events = syncTreeRemoveEventRegistration(repo.serverSyncTree_, query, eventRegistration);\n  }\n\n  eventQueueRaiseEventsAtPath(repo.eventQueue_, query._path, events);\n}\n\nfunction repoInterrupt(repo) {\n  if (repo.persistentConnection_) {\n    repo.persistentConnection_.interrupt(INTERRUPT_REASON);\n  }\n}\n\nfunction repoResume(repo) {\n  if (repo.persistentConnection_) {\n    repo.persistentConnection_.resume(INTERRUPT_REASON);\n  }\n}\n\nfunction repoLog(repo, ...varArgs) {\n  let prefix = '';\n\n  if (repo.persistentConnection_) {\n    prefix = repo.persistentConnection_.id + ':';\n  }\n\n  log(prefix, ...varArgs);\n}\n\nfunction repoCallOnCompleteCallback(repo, callback, status, errorReason) {\n  if (callback) {\n    exceptionGuard(() => {\n      if (status === 'ok') {\n        callback(null);\n      } else {\n        const code = (status || 'error').toUpperCase();\n        let message = code;\n\n        if (errorReason) {\n          message += ': ' + errorReason;\n        }\n\n        const error = new Error(message); // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n        error.code = code;\n        callback(error);\n      }\n    });\n  }\n}\n/**\r\n * Creates a new transaction, adds it to the transactions we're tracking, and\r\n * sends it to the server if possible.\r\n *\r\n * @param path - Path at which to do transaction.\r\n * @param transactionUpdate - Update callback.\r\n * @param onComplete - Completion callback.\r\n * @param unwatcher - Function that will be called when the transaction no longer\r\n * need data updates for `path`.\r\n * @param applyLocally - Whether or not to make intermediate results visible\r\n */\n\n\nfunction repoStartTransaction(repo, path, transactionUpdate, onComplete, unwatcher, applyLocally) {\n  repoLog(repo, 'transaction on ' + path); // Initialize transaction.\n\n  const transaction = {\n    path,\n    update: transactionUpdate,\n    onComplete,\n    // One of TransactionStatus enums.\n    status: null,\n    // Used when combining transactions at different locations to figure out\n    // which one goes first.\n    order: LUIDGenerator(),\n    // Whether to raise local events for this transaction.\n    applyLocally,\n    // Count of how many times we've retried the transaction.\n    retryCount: 0,\n    // Function to call to clean up our .on() listener.\n    unwatcher,\n    // Stores why a transaction was aborted.\n    abortReason: null,\n    currentWriteId: null,\n    currentInputSnapshot: null,\n    currentOutputSnapshotRaw: null,\n    currentOutputSnapshotResolved: null\n  }; // Run transaction initially.\n\n  const currentState = repoGetLatestState(repo, path, undefined);\n  transaction.currentInputSnapshot = currentState;\n  const newVal = transaction.update(currentState.val());\n\n  if (newVal === undefined) {\n    // Abort transaction.\n    transaction.unwatcher();\n    transaction.currentOutputSnapshotRaw = null;\n    transaction.currentOutputSnapshotResolved = null;\n\n    if (transaction.onComplete) {\n      transaction.onComplete(null, false, transaction.currentInputSnapshot);\n    }\n  } else {\n    validateFirebaseData('transaction failed: Data returned ', newVal, transaction.path); // Mark as run and add to our queue.\n\n    transaction.status = 0\n    /* RUN */\n    ;\n    const queueNode = treeSubTree(repo.transactionQueueTree_, path);\n    const nodeQueue = treeGetValue(queueNode) || [];\n    nodeQueue.push(transaction);\n    treeSetValue(queueNode, nodeQueue); // Update visibleData and raise events\n    // Note: We intentionally raise events after updating all of our\n    // transaction state, since the user could start new transactions from the\n    // event callbacks.\n\n    let priorityForNode;\n\n    if (typeof newVal === 'object' && newVal !== null && contains(newVal, '.priority')) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      priorityForNode = safeGet(newVal, '.priority');\n      assert(isValidPriority(priorityForNode), 'Invalid priority returned by transaction. ' + 'Priority must be a valid string, finite number, server value, or null.');\n    } else {\n      const currentNode = syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path) || ChildrenNode.EMPTY_NODE;\n      priorityForNode = currentNode.getPriority().val();\n    }\n\n    const serverValues = repoGenerateServerValues(repo);\n    const newNodeUnresolved = nodeFromJSON(newVal, priorityForNode);\n    const newNode = resolveDeferredValueSnapshot(newNodeUnresolved, currentState, serverValues);\n    transaction.currentOutputSnapshotRaw = newNodeUnresolved;\n    transaction.currentOutputSnapshotResolved = newNode;\n    transaction.currentWriteId = repoGetNextWriteId(repo);\n    const events = syncTreeApplyUserOverwrite(repo.serverSyncTree_, path, newNode, transaction.currentWriteId, transaction.applyLocally);\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n    repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n  }\n}\n/**\r\n * @param excludeSets - A specific set to exclude\r\n */\n\n\nfunction repoGetLatestState(repo, path, excludeSets) {\n  return syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path, excludeSets) || ChildrenNode.EMPTY_NODE;\n}\n/**\r\n * Sends any already-run transactions that aren't waiting for outstanding\r\n * transactions to complete.\r\n *\r\n * Externally it's called with no arguments, but it calls itself recursively\r\n * with a particular transactionQueueTree node to recurse through the tree.\r\n *\r\n * @param node - transactionQueueTree node to start at.\r\n */\n\n\nfunction repoSendReadyTransactions(repo, node = repo.transactionQueueTree_) {\n  // Before recursing, make sure any completed transactions are removed.\n  if (!node) {\n    repoPruneCompletedTransactionsBelowNode(repo, node);\n  }\n\n  if (treeGetValue(node)) {\n    const queue = repoBuildTransactionQueue(repo, node);\n    assert(queue.length > 0, 'Sending zero length transaction queue');\n    const allRun = queue.every(transaction => transaction.status === 0\n    /* RUN */\n    ); // If they're all run (and not sent), we can send them.  Else, we must wait.\n\n    if (allRun) {\n      repoSendTransactionQueue(repo, treeGetPath(node), queue);\n    }\n  } else if (treeHasChildren(node)) {\n    treeForEachChild(node, childNode => {\n      repoSendReadyTransactions(repo, childNode);\n    });\n  }\n}\n/**\r\n * Given a list of run transactions, send them to the server and then handle\r\n * the result (success or failure).\r\n *\r\n * @param path - The location of the queue.\r\n * @param queue - Queue of transactions under the specified location.\r\n */\n\n\nfunction repoSendTransactionQueue(repo, path, queue) {\n  // Mark transactions as sent and increment retry count!\n  const setsToIgnore = queue.map(txn => {\n    return txn.currentWriteId;\n  });\n  const latestState = repoGetLatestState(repo, path, setsToIgnore);\n  let snapToSend = latestState;\n  const latestHash = latestState.hash();\n\n  for (let i = 0; i < queue.length; i++) {\n    const txn = queue[i];\n    assert(txn.status === 0\n    /* RUN */\n    , 'tryToSendTransactionQueue_: items in queue should all be run.');\n    txn.status = 1\n    /* SENT */\n    ;\n    txn.retryCount++;\n    const relativePath = newRelativePath(path, txn.path); // If we've gotten to this point, the output snapshot must be defined.\n\n    snapToSend = snapToSend.updateChild(relativePath\n    /** @type {!Node} */\n    , txn.currentOutputSnapshotRaw);\n  }\n\n  const dataToSend = snapToSend.val(true);\n  const pathToSend = path; // Send the put.\n\n  repo.server_.put(pathToSend.toString(), dataToSend, status => {\n    repoLog(repo, 'transaction put response', {\n      path: pathToSend.toString(),\n      status\n    });\n    let events = [];\n\n    if (status === 'ok') {\n      // Queue up the callbacks and fire them after cleaning up all of our\n      // transaction state, since the callback could trigger more\n      // transactions or sets.\n      const callbacks = [];\n\n      for (let i = 0; i < queue.length; i++) {\n        queue[i].status = 2\n        /* COMPLETED */\n        ;\n        events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, queue[i].currentWriteId));\n\n        if (queue[i].onComplete) {\n          // We never unset the output snapshot, and given that this\n          // transaction is complete, it should be set\n          callbacks.push(() => queue[i].onComplete(null, true, queue[i].currentOutputSnapshotResolved));\n        }\n\n        queue[i].unwatcher();\n      } // Now remove the completed transactions.\n\n\n      repoPruneCompletedTransactionsBelowNode(repo, treeSubTree(repo.transactionQueueTree_, path)); // There may be pending transactions that we can now send.\n\n      repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n      eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events); // Finally, trigger onComplete callbacks.\n\n      for (let i = 0; i < callbacks.length; i++) {\n        exceptionGuard(callbacks[i]);\n      }\n    } else {\n      // transactions are no longer sent.  Update their status appropriately.\n      if (status === 'datastale') {\n        for (let i = 0; i < queue.length; i++) {\n          if (queue[i].status === 3\n          /* SENT_NEEDS_ABORT */\n          ) {\n            queue[i].status = 4\n            /* NEEDS_ABORT */\n            ;\n          } else {\n            queue[i].status = 0\n            /* RUN */\n            ;\n          }\n        }\n      } else {\n        warn('transaction at ' + pathToSend.toString() + ' failed: ' + status);\n\n        for (let i = 0; i < queue.length; i++) {\n          queue[i].status = 4\n          /* NEEDS_ABORT */\n          ;\n          queue[i].abortReason = status;\n        }\n      }\n\n      repoRerunTransactions(repo, path);\n    }\n  }, latestHash);\n}\n/**\r\n * Finds all transactions dependent on the data at changedPath and reruns them.\r\n *\r\n * Should be called any time cached data changes.\r\n *\r\n * Return the highest path that was affected by rerunning transactions. This\r\n * is the path at which events need to be raised for.\r\n *\r\n * @param changedPath - The path in mergedData that changed.\r\n * @returns The rootmost path that was affected by rerunning transactions.\r\n */\n\n\nfunction repoRerunTransactions(repo, changedPath) {\n  const rootMostTransactionNode = repoGetAncestorTransactionNode(repo, changedPath);\n  const path = treeGetPath(rootMostTransactionNode);\n  const queue = repoBuildTransactionQueue(repo, rootMostTransactionNode);\n  repoRerunTransactionQueue(repo, queue, path);\n  return path;\n}\n/**\r\n * Does all the work of rerunning transactions (as well as cleans up aborted\r\n * transactions and whatnot).\r\n *\r\n * @param queue - The queue of transactions to run.\r\n * @param path - The path the queue is for.\r\n */\n\n\nfunction repoRerunTransactionQueue(repo, queue, path) {\n  if (queue.length === 0) {\n    return; // Nothing to do!\n  } // Queue up the callbacks and fire them after cleaning up all of our\n  // transaction state, since the callback could trigger more transactions or\n  // sets.\n\n\n  const callbacks = [];\n  let events = []; // Ignore all of the sets we're going to re-run.\n\n  const txnsToRerun = queue.filter(q => {\n    return q.status === 0\n    /* RUN */\n    ;\n  });\n  const setsToIgnore = txnsToRerun.map(q => {\n    return q.currentWriteId;\n  });\n\n  for (let i = 0; i < queue.length; i++) {\n    const transaction = queue[i];\n    const relativePath = newRelativePath(path, transaction.path);\n    let abortTransaction = false,\n        abortReason;\n    assert(relativePath !== null, 'rerunTransactionsUnderNode_: relativePath should not be null.');\n\n    if (transaction.status === 4\n    /* NEEDS_ABORT */\n    ) {\n      abortTransaction = true;\n      abortReason = transaction.abortReason;\n      events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, transaction.currentWriteId, true));\n    } else if (transaction.status === 0\n    /* RUN */\n    ) {\n      if (transaction.retryCount >= MAX_TRANSACTION_RETRIES) {\n        abortTransaction = true;\n        abortReason = 'maxretry';\n        events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, transaction.currentWriteId, true));\n      } else {\n        // This code reruns a transaction\n        const currentNode = repoGetLatestState(repo, transaction.path, setsToIgnore);\n        transaction.currentInputSnapshot = currentNode;\n        const newData = queue[i].update(currentNode.val());\n\n        if (newData !== undefined) {\n          validateFirebaseData('transaction failed: Data returned ', newData, transaction.path);\n          let newDataNode = nodeFromJSON(newData);\n          const hasExplicitPriority = typeof newData === 'object' && newData != null && contains(newData, '.priority');\n\n          if (!hasExplicitPriority) {\n            // Keep the old priority if there wasn't a priority explicitly specified.\n            newDataNode = newDataNode.updatePriority(currentNode.getPriority());\n          }\n\n          const oldWriteId = transaction.currentWriteId;\n          const serverValues = repoGenerateServerValues(repo);\n          const newNodeResolved = resolveDeferredValueSnapshot(newDataNode, currentNode, serverValues);\n          transaction.currentOutputSnapshotRaw = newDataNode;\n          transaction.currentOutputSnapshotResolved = newNodeResolved;\n          transaction.currentWriteId = repoGetNextWriteId(repo); // Mutates setsToIgnore in place\n\n          setsToIgnore.splice(setsToIgnore.indexOf(oldWriteId), 1);\n          events = events.concat(syncTreeApplyUserOverwrite(repo.serverSyncTree_, transaction.path, newNodeResolved, transaction.currentWriteId, transaction.applyLocally));\n          events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, oldWriteId, true));\n        } else {\n          abortTransaction = true;\n          abortReason = 'nodata';\n          events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, transaction.currentWriteId, true));\n        }\n      }\n    }\n\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n    events = [];\n\n    if (abortTransaction) {\n      // Abort.\n      queue[i].status = 2\n      /* COMPLETED */\n      ; // Removing a listener can trigger pruning which can muck with\n      // mergedData/visibleData (as it prunes data). So defer the unwatcher\n      // until we're done.\n\n      (function (unwatcher) {\n        setTimeout(unwatcher, Math.floor(0));\n      })(queue[i].unwatcher);\n\n      if (queue[i].onComplete) {\n        if (abortReason === 'nodata') {\n          callbacks.push(() => queue[i].onComplete(null, false, queue[i].currentInputSnapshot));\n        } else {\n          callbacks.push(() => queue[i].onComplete(new Error(abortReason), false, null));\n        }\n      }\n    }\n  } // Clean up completed transactions.\n\n\n  repoPruneCompletedTransactionsBelowNode(repo, repo.transactionQueueTree_); // Now fire callbacks, now that we're in a good, known state.\n\n  for (let i = 0; i < callbacks.length; i++) {\n    exceptionGuard(callbacks[i]);\n  } // Try to send the transaction result to the server.\n\n\n  repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n}\n/**\r\n * Returns the rootmost ancestor node of the specified path that has a pending\r\n * transaction on it, or just returns the node for the given path if there are\r\n * no pending transactions on any ancestor.\r\n *\r\n * @param path - The location to start at.\r\n * @returns The rootmost node with a transaction.\r\n */\n\n\nfunction repoGetAncestorTransactionNode(repo, path) {\n  let front; // Start at the root and walk deeper into the tree towards path until we\n  // find a node with pending transactions.\n\n  let transactionNode = repo.transactionQueueTree_;\n  front = pathGetFront(path);\n\n  while (front !== null && treeGetValue(transactionNode) === undefined) {\n    transactionNode = treeSubTree(transactionNode, front);\n    path = pathPopFront(path);\n    front = pathGetFront(path);\n  }\n\n  return transactionNode;\n}\n/**\r\n * Builds the queue of all transactions at or below the specified\r\n * transactionNode.\r\n *\r\n * @param transactionNode\r\n * @returns The generated queue.\r\n */\n\n\nfunction repoBuildTransactionQueue(repo, transactionNode) {\n  // Walk any child transaction queues and aggregate them into a single queue.\n  const transactionQueue = [];\n  repoAggregateTransactionQueuesForNode(repo, transactionNode, transactionQueue); // Sort them by the order the transactions were created.\n\n  transactionQueue.sort((a, b) => a.order - b.order);\n  return transactionQueue;\n}\n\nfunction repoAggregateTransactionQueuesForNode(repo, node, queue) {\n  const nodeQueue = treeGetValue(node);\n\n  if (nodeQueue) {\n    for (let i = 0; i < nodeQueue.length; i++) {\n      queue.push(nodeQueue[i]);\n    }\n  }\n\n  treeForEachChild(node, child => {\n    repoAggregateTransactionQueuesForNode(repo, child, queue);\n  });\n}\n/**\r\n * Remove COMPLETED transactions at or below this node in the transactionQueueTree_.\r\n */\n\n\nfunction repoPruneCompletedTransactionsBelowNode(repo, node) {\n  const queue = treeGetValue(node);\n\n  if (queue) {\n    let to = 0;\n\n    for (let from = 0; from < queue.length; from++) {\n      if (queue[from].status !== 2\n      /* COMPLETED */\n      ) {\n        queue[to] = queue[from];\n        to++;\n      }\n    }\n\n    queue.length = to;\n    treeSetValue(node, queue.length > 0 ? queue : undefined);\n  }\n\n  treeForEachChild(node, childNode => {\n    repoPruneCompletedTransactionsBelowNode(repo, childNode);\n  });\n}\n/**\r\n * Aborts all transactions on ancestors or descendants of the specified path.\r\n * Called when doing a set() or update() since we consider them incompatible\r\n * with transactions.\r\n *\r\n * @param path - Path for which we want to abort related transactions.\r\n */\n\n\nfunction repoAbortTransactions(repo, path) {\n  const affectedPath = treeGetPath(repoGetAncestorTransactionNode(repo, path));\n  const transactionNode = treeSubTree(repo.transactionQueueTree_, path);\n  treeForEachAncestor(transactionNode, node => {\n    repoAbortTransactionsOnNode(repo, node);\n  });\n  repoAbortTransactionsOnNode(repo, transactionNode);\n  treeForEachDescendant(transactionNode, node => {\n    repoAbortTransactionsOnNode(repo, node);\n  });\n  return affectedPath;\n}\n/**\r\n * Abort transactions stored in this transaction queue node.\r\n *\r\n * @param node - Node to abort transactions for.\r\n */\n\n\nfunction repoAbortTransactionsOnNode(repo, node) {\n  const queue = treeGetValue(node);\n\n  if (queue) {\n    // Queue up the callbacks and fire them after cleaning up all of our\n    // transaction state, since the callback could trigger more transactions\n    // or sets.\n    const callbacks = []; // Go through queue.  Any already-sent transactions must be marked for\n    // abort, while the unsent ones can be immediately aborted and removed.\n\n    let events = [];\n    let lastSent = -1;\n\n    for (let i = 0; i < queue.length; i++) {\n      if (queue[i].status === 3\n      /* SENT_NEEDS_ABORT */\n      ) ;else if (queue[i].status === 1\n      /* SENT */\n      ) {\n        assert(lastSent === i - 1, 'All SENT items should be at beginning of queue.');\n        lastSent = i; // Mark transaction for abort when it comes back.\n\n        queue[i].status = 3\n        /* SENT_NEEDS_ABORT */\n        ;\n        queue[i].abortReason = 'set';\n      } else {\n        assert(queue[i].status === 0\n        /* RUN */\n        , 'Unexpected transaction status in abort'); // We can abort it immediately.\n\n        queue[i].unwatcher();\n        events = events.concat(syncTreeAckUserWrite(repo.serverSyncTree_, queue[i].currentWriteId, true));\n\n        if (queue[i].onComplete) {\n          callbacks.push(queue[i].onComplete.bind(null, new Error('set'), false, null));\n        }\n      }\n    }\n\n    if (lastSent === -1) {\n      // We're not waiting for any sent transactions.  We can clear the queue.\n      treeSetValue(node, undefined);\n    } else {\n      // Remove the transactions we aborted.\n      queue.length = lastSent + 1;\n    } // Now fire the callbacks.\n\n\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, treeGetPath(node), events);\n\n    for (let i = 0; i < callbacks.length; i++) {\n      exceptionGuard(callbacks[i]);\n    }\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction decodePath(pathString) {\n  let pathStringDecoded = '';\n  const pieces = pathString.split('/');\n\n  for (let i = 0; i < pieces.length; i++) {\n    if (pieces[i].length > 0) {\n      let piece = pieces[i];\n\n      try {\n        piece = decodeURIComponent(piece.replace(/\\+/g, ' '));\n      } catch (e) {}\n\n      pathStringDecoded += '/' + piece;\n    }\n  }\n\n  return pathStringDecoded;\n}\n/**\r\n * @returns key value hash\r\n */\n\n\nfunction decodeQuery(queryString) {\n  const results = {};\n\n  if (queryString.charAt(0) === '?') {\n    queryString = queryString.substring(1);\n  }\n\n  for (const segment of queryString.split('&')) {\n    if (segment.length === 0) {\n      continue;\n    }\n\n    const kv = segment.split('=');\n\n    if (kv.length === 2) {\n      results[decodeURIComponent(kv[0])] = decodeURIComponent(kv[1]);\n    } else {\n      warn(`Invalid query segment '${segment}' in query '${queryString}'`);\n    }\n  }\n\n  return results;\n}\n\nconst parseRepoInfo = function (dataURL, nodeAdmin) {\n  const parsedUrl = parseDatabaseURL(dataURL),\n        namespace = parsedUrl.namespace;\n\n  if (parsedUrl.domain === 'firebase.com') {\n    fatal(parsedUrl.host + ' is no longer supported. ' + 'Please use <YOUR FIREBASE>.firebaseio.com instead');\n  } // Catch common error of uninitialized namespace value.\n\n\n  if ((!namespace || namespace === 'undefined') && parsedUrl.domain !== 'localhost') {\n    fatal('Cannot parse Firebase url. Please use https://<YOUR FIREBASE>.firebaseio.com');\n  }\n\n  if (!parsedUrl.secure) {\n    warnIfPageIsSecure();\n  }\n\n  const webSocketOnly = parsedUrl.scheme === 'ws' || parsedUrl.scheme === 'wss';\n  return {\n    repoInfo: new RepoInfo(parsedUrl.host, parsedUrl.secure, namespace, webSocketOnly, nodeAdmin,\n    /*persistenceKey=*/\n    '',\n    /*includeNamespaceInQueryParams=*/\n    namespace !== parsedUrl.subdomain),\n    path: new Path(parsedUrl.pathString)\n  };\n};\n\nconst parseDatabaseURL = function (dataURL) {\n  // Default to empty strings in the event of a malformed string.\n  let host = '',\n      domain = '',\n      subdomain = '',\n      pathString = '',\n      namespace = ''; // Always default to SSL, unless otherwise specified.\n\n  let secure = true,\n      scheme = 'https',\n      port = 443; // Don't do any validation here. The caller is responsible for validating the result of parsing.\n\n  if (typeof dataURL === 'string') {\n    // Parse scheme.\n    let colonInd = dataURL.indexOf('//');\n\n    if (colonInd >= 0) {\n      scheme = dataURL.substring(0, colonInd - 1);\n      dataURL = dataURL.substring(colonInd + 2);\n    } // Parse host, path, and query string.\n\n\n    let slashInd = dataURL.indexOf('/');\n\n    if (slashInd === -1) {\n      slashInd = dataURL.length;\n    }\n\n    let questionMarkInd = dataURL.indexOf('?');\n\n    if (questionMarkInd === -1) {\n      questionMarkInd = dataURL.length;\n    }\n\n    host = dataURL.substring(0, Math.min(slashInd, questionMarkInd));\n\n    if (slashInd < questionMarkInd) {\n      // For pathString, questionMarkInd will always come after slashInd\n      pathString = decodePath(dataURL.substring(slashInd, questionMarkInd));\n    }\n\n    const queryParams = decodeQuery(dataURL.substring(Math.min(dataURL.length, questionMarkInd))); // If we have a port, use scheme for determining if it's secure.\n\n    colonInd = host.indexOf(':');\n\n    if (colonInd >= 0) {\n      secure = scheme === 'https' || scheme === 'wss';\n      port = parseInt(host.substring(colonInd + 1), 10);\n    } else {\n      colonInd = host.length;\n    }\n\n    const hostWithoutPort = host.slice(0, colonInd);\n\n    if (hostWithoutPort.toLowerCase() === 'localhost') {\n      domain = 'localhost';\n    } else if (hostWithoutPort.split('.').length <= 2) {\n      domain = hostWithoutPort;\n    } else {\n      // Interpret the subdomain of a 3 or more component URL as the namespace name.\n      const dotInd = host.indexOf('.');\n      subdomain = host.substring(0, dotInd).toLowerCase();\n      domain = host.substring(dotInd + 1); // Normalize namespaces to lowercase to share storage / connection.\n\n      namespace = subdomain;\n    } // Always treat the value of the `ns` as the namespace name if it is present.\n\n\n    if ('ns' in queryParams) {\n      namespace = queryParams['ns'];\n    }\n  }\n\n  return {\n    host,\n    port,\n    domain,\n    subdomain,\n    secure,\n    scheme,\n    pathString,\n    namespace\n  };\n};\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Encapsulates the data needed to raise an event\r\n */\n\n\nclass DataEvent {\n  /**\r\n   * @param eventType - One of: value, child_added, child_changed, child_moved, child_removed\r\n   * @param eventRegistration - The function to call to with the event data. User provided\r\n   * @param snapshot - The data backing the event\r\n   * @param prevName - Optional, the name of the previous child for child_* events.\r\n   */\n  constructor(eventType, eventRegistration, snapshot, prevName) {\n    this.eventType = eventType;\n    this.eventRegistration = eventRegistration;\n    this.snapshot = snapshot;\n    this.prevName = prevName;\n  }\n\n  getPath() {\n    const ref = this.snapshot.ref;\n\n    if (this.eventType === 'value') {\n      return ref._path;\n    } else {\n      return ref.parent._path;\n    }\n  }\n\n  getEventType() {\n    return this.eventType;\n  }\n\n  getEventRunner() {\n    return this.eventRegistration.getEventRunner(this);\n  }\n\n  toString() {\n    return this.getPath().toString() + ':' + this.eventType + ':' + stringify(this.snapshot.exportVal());\n  }\n\n}\n\nclass CancelEvent {\n  constructor(eventRegistration, error, path) {\n    this.eventRegistration = eventRegistration;\n    this.error = error;\n    this.path = path;\n  }\n\n  getPath() {\n    return this.path;\n  }\n\n  getEventType() {\n    return 'cancel';\n  }\n\n  getEventRunner() {\n    return this.eventRegistration.getEventRunner(this);\n  }\n\n  toString() {\n    return this.path.toString() + ':cancel';\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A wrapper class that converts events from the database@exp SDK to the legacy\r\n * Database SDK. Events are not converted directly as event registration relies\r\n * on reference comparison of the original user callback (see `matches()`) and\r\n * relies on equality of the legacy SDK's `context` object.\r\n */\n\n\nclass CallbackContext {\n  constructor(snapshotCallback, cancelCallback) {\n    this.snapshotCallback = snapshotCallback;\n    this.cancelCallback = cancelCallback;\n  }\n\n  onValue(expDataSnapshot, previousChildName) {\n    this.snapshotCallback.call(null, expDataSnapshot, previousChildName);\n  }\n\n  onCancel(error) {\n    assert(this.hasCancelCallback, 'Raising a cancel event on a listener with no cancel callback');\n    return this.cancelCallback.call(null, error);\n  }\n\n  get hasCancelCallback() {\n    return !!this.cancelCallback;\n  }\n\n  matches(other) {\n    return this.snapshotCallback === other.snapshotCallback || this.snapshotCallback.userCallback !== undefined && this.snapshotCallback.userCallback === other.snapshotCallback.userCallback && this.snapshotCallback.context === other.snapshotCallback.context;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2021 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * The `onDisconnect` class allows you to write or clear data when your client\r\n * disconnects from the Database server. These updates occur whether your\r\n * client disconnects cleanly or not, so you can rely on them to clean up data\r\n * even if a connection is dropped or a client crashes.\r\n *\r\n * The `onDisconnect` class is most commonly used to manage presence in\r\n * applications where it is useful to detect how many clients are connected and\r\n * when other clients disconnect. See\r\n * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\r\n * for more information.\r\n *\r\n * To avoid problems when a connection is dropped before the requests can be\r\n * transferred to the Database server, these functions should be called before\r\n * writing any data.\r\n *\r\n * Note that `onDisconnect` operations are only triggered once. If you want an\r\n * operation to occur each time a disconnect occurs, you'll need to re-establish\r\n * the `onDisconnect` operations each time you reconnect.\r\n */\n\n\nclass OnDisconnect {\n  /** @hideconstructor */\n  constructor(_repo, _path) {\n    this._repo = _repo;\n    this._path = _path;\n  }\n  /**\r\n   * Cancels all previously queued `onDisconnect()` set or update events for this\r\n   * location and all children.\r\n   *\r\n   * If a write has been queued for this location via a `set()` or `update()` at a\r\n   * parent location, the write at this location will be canceled, though writes\r\n   * to sibling locations will still occur.\r\n   *\r\n   * @returns Resolves when synchronization to the server is complete.\r\n   */\n\n\n  cancel() {\n    const deferred = new Deferred();\n    repoOnDisconnectCancel(this._repo, this._path, deferred.wrapCallback(() => {}));\n    return deferred.promise;\n  }\n  /**\r\n   * Ensures the data at this location is deleted when the client is disconnected\r\n   * (due to closing the browser, navigating to a new page, or network issues).\r\n   *\r\n   * @returns Resolves when synchronization to the server is complete.\r\n   */\n\n\n  remove() {\n    validateWritablePath('OnDisconnect.remove', this._path);\n    const deferred = new Deferred();\n    repoOnDisconnectSet(this._repo, this._path, null, deferred.wrapCallback(() => {}));\n    return deferred.promise;\n  }\n  /**\r\n   * Ensures the data at this location is set to the specified value when the\r\n   * client is disconnected (due to closing the browser, navigating to a new page,\r\n   * or network issues).\r\n   *\r\n   * `set()` is especially useful for implementing \"presence\" systems, where a\r\n   * value should be changed or cleared when a user disconnects so that they\r\n   * appear \"offline\" to other users. See\r\n   * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\r\n   * for more information.\r\n   *\r\n   * Note that `onDisconnect` operations are only triggered once. If you want an\r\n   * operation to occur each time a disconnect occurs, you'll need to re-establish\r\n   * the `onDisconnect` operations each time.\r\n   *\r\n   * @param value - The value to be written to this location on disconnect (can\r\n   * be an object, array, string, number, boolean, or null).\r\n   * @returns Resolves when synchronization to the Database is complete.\r\n   */\n\n\n  set(value) {\n    validateWritablePath('OnDisconnect.set', this._path);\n    validateFirebaseDataArg('OnDisconnect.set', value, this._path, false);\n    const deferred = new Deferred();\n    repoOnDisconnectSet(this._repo, this._path, value, deferred.wrapCallback(() => {}));\n    return deferred.promise;\n  }\n  /**\r\n   * Ensures the data at this location is set to the specified value and priority\r\n   * when the client is disconnected (due to closing the browser, navigating to a\r\n   * new page, or network issues).\r\n   *\r\n   * @param value - The value to be written to this location on disconnect (can\r\n   * be an object, array, string, number, boolean, or null).\r\n   * @param priority - The priority to be written (string, number, or null).\r\n   * @returns Resolves when synchronization to the Database is complete.\r\n   */\n\n\n  setWithPriority(value, priority) {\n    validateWritablePath('OnDisconnect.setWithPriority', this._path);\n    validateFirebaseDataArg('OnDisconnect.setWithPriority', value, this._path, false);\n    validatePriority('OnDisconnect.setWithPriority', priority, false);\n    const deferred = new Deferred();\n    repoOnDisconnectSetWithPriority(this._repo, this._path, value, priority, deferred.wrapCallback(() => {}));\n    return deferred.promise;\n  }\n  /**\r\n   * Writes multiple values at this location when the client is disconnected (due\r\n   * to closing the browser, navigating to a new page, or network issues).\r\n   *\r\n   * The `values` argument contains multiple property-value pairs that will be\r\n   * written to the Database together. Each child property can either be a simple\r\n   * property (for example, \"name\") or a relative path (for example, \"name/first\")\r\n   * from the current location to the data to update.\r\n   *\r\n   * As opposed to the `set()` method, `update()` can be use to selectively update\r\n   * only the referenced properties at the current location (instead of replacing\r\n   * all the child properties at the current location).\r\n   *\r\n   * @param values - Object containing multiple values.\r\n   * @returns Resolves when synchronization to the Database is complete.\r\n   */\n\n\n  update(values) {\n    validateWritablePath('OnDisconnect.update', this._path);\n    validateFirebaseMergeDataArg('OnDisconnect.update', values, this._path, false);\n    const deferred = new Deferred();\n    repoOnDisconnectUpdate(this._repo, this._path, values, deferred.wrapCallback(() => {}));\n    return deferred.promise;\n  }\n\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * @internal\r\n */\n\n\nclass QueryImpl {\n  /**\r\n   * @hideconstructor\r\n   */\n  constructor(_repo, _path, _queryParams, _orderByCalled) {\n    this._repo = _repo;\n    this._path = _path;\n    this._queryParams = _queryParams;\n    this._orderByCalled = _orderByCalled;\n  }\n\n  get key() {\n    if (pathIsEmpty(this._path)) {\n      return null;\n    } else {\n      return pathGetBack(this._path);\n    }\n  }\n\n  get ref() {\n    return new ReferenceImpl(this._repo, this._path);\n  }\n\n  get _queryIdentifier() {\n    const obj = queryParamsGetQueryObject(this._queryParams);\n    const id = ObjectToUniqueKey(obj);\n    return id === '{}' ? 'default' : id;\n  }\n  /**\r\n   * An object representation of the query parameters used by this Query.\r\n   */\n\n\n  get _queryObject() {\n    return queryParamsGetQueryObject(this._queryParams);\n  }\n\n  isEqual(other) {\n    other = getModularInstance(other);\n\n    if (!(other instanceof QueryImpl)) {\n      return false;\n    }\n\n    const sameRepo = this._repo === other._repo;\n    const samePath = pathEquals(this._path, other._path);\n    const sameQueryIdentifier = this._queryIdentifier === other._queryIdentifier;\n    return sameRepo && samePath && sameQueryIdentifier;\n  }\n\n  toJSON() {\n    return this.toString();\n  }\n\n  toString() {\n    return this._repo.toString() + pathToUrlEncodedString(this._path);\n  }\n\n}\n/**\r\n * Validates that no other order by call has been made\r\n */\n\n\nfunction validateNoPreviousOrderByCall(query, fnName) {\n  if (query._orderByCalled === true) {\n    throw new Error(fnName + \": You can't combine multiple orderBy calls.\");\n  }\n}\n/**\r\n * Validates start/end values for queries.\r\n */\n\n\nfunction validateQueryEndpoints(params) {\n  let startNode = null;\n  let endNode = null;\n\n  if (params.hasStart()) {\n    startNode = params.getIndexStartValue();\n  }\n\n  if (params.hasEnd()) {\n    endNode = params.getIndexEndValue();\n  }\n\n  if (params.getIndex() === KEY_INDEX) {\n    const tooManyArgsError = 'Query: When ordering by key, you may only pass one argument to ' + 'startAt(), endAt(), or equalTo().';\n    const wrongArgTypeError = 'Query: When ordering by key, the argument passed to startAt(), startAfter(), ' + 'endAt(), endBefore(), or equalTo() must be a string.';\n\n    if (params.hasStart()) {\n      const startName = params.getIndexStartName();\n\n      if (startName !== MIN_NAME) {\n        throw new Error(tooManyArgsError);\n      } else if (typeof startNode !== 'string') {\n        throw new Error(wrongArgTypeError);\n      }\n    }\n\n    if (params.hasEnd()) {\n      const endName = params.getIndexEndName();\n\n      if (endName !== MAX_NAME) {\n        throw new Error(tooManyArgsError);\n      } else if (typeof endNode !== 'string') {\n        throw new Error(wrongArgTypeError);\n      }\n    }\n  } else if (params.getIndex() === PRIORITY_INDEX) {\n    if (startNode != null && !isValidPriority(startNode) || endNode != null && !isValidPriority(endNode)) {\n      throw new Error('Query: When ordering by priority, the first argument passed to startAt(), ' + 'startAfter() endAt(), endBefore(), or equalTo() must be a valid priority value ' + '(null, a number, or a string).');\n    }\n  } else {\n    assert(params.getIndex() instanceof PathIndex || params.getIndex() === VALUE_INDEX, 'unknown index type.');\n\n    if (startNode != null && typeof startNode === 'object' || endNode != null && typeof endNode === 'object') {\n      throw new Error('Query: First argument passed to startAt(), startAfter(), endAt(), endBefore(), or ' + 'equalTo() cannot be an object.');\n    }\n  }\n}\n/**\r\n * Validates that limit* has been called with the correct combination of parameters\r\n */\n\n\nfunction validateLimit(params) {\n  if (params.hasStart() && params.hasEnd() && params.hasLimit() && !params.hasAnchoredLimit()) {\n    throw new Error(\"Query: Can't combine startAt(), startAfter(), endAt(), endBefore(), and limit(). Use \" + 'limitToFirst() or limitToLast() instead.');\n  }\n}\n/**\r\n * @internal\r\n */\n\n\nclass ReferenceImpl extends QueryImpl {\n  /** @hideconstructor */\n  constructor(repo, path) {\n    super(repo, path, new QueryParams(), false);\n  }\n\n  get parent() {\n    const parentPath = pathParent(this._path);\n    return parentPath === null ? null : new ReferenceImpl(this._repo, parentPath);\n  }\n\n  get root() {\n    let ref = this;\n\n    while (ref.parent !== null) {\n      ref = ref.parent;\n    }\n\n    return ref;\n  }\n\n}\n/**\r\n * A `DataSnapshot` contains data from a Database location.\r\n *\r\n * Any time you read data from the Database, you receive the data as a\r\n * `DataSnapshot`. A `DataSnapshot` is passed to the event callbacks you attach\r\n * with `on()` or `once()`. You can extract the contents of the snapshot as a\r\n * JavaScript object by calling the `val()` method. Alternatively, you can\r\n * traverse into the snapshot by calling `child()` to return child snapshots\r\n * (which you could then call `val()` on).\r\n *\r\n * A `DataSnapshot` is an efficiently generated, immutable copy of the data at\r\n * a Database location. It cannot be modified and will never change (to modify\r\n * data, you always call the `set()` method on a `Reference` directly).\r\n */\n\n\nclass DataSnapshot {\n  /**\r\n   * @param _node - A SnapshotNode to wrap.\r\n   * @param ref - The location this snapshot came from.\r\n   * @param _index - The iteration order for this snapshot\r\n   * @hideconstructor\r\n   */\n  constructor(_node,\n  /**\r\n   * The location of this DataSnapshot.\r\n   */\n  ref, _index) {\n    this._node = _node;\n    this.ref = ref;\n    this._index = _index;\n  }\n  /**\r\n   * Gets the priority value of the data in this `DataSnapshot`.\r\n   *\r\n   * Applications need not use priority but can order collections by\r\n   * ordinary properties (see\r\n   * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data |Sorting and filtering data}\r\n   * ).\r\n   */\n\n\n  get priority() {\n    // typecast here because we never return deferred values or internal priorities (MAX_PRIORITY)\n    return this._node.getPriority().val();\n  }\n  /**\r\n   * The key (last part of the path) of the location of this `DataSnapshot`.\r\n   *\r\n   * The last token in a Database location is considered its key. For example,\r\n   * \"ada\" is the key for the /users/ada/ node. Accessing the key on any\r\n   * `DataSnapshot` will return the key for the location that generated it.\r\n   * However, accessing the key on the root URL of a Database will return\r\n   * `null`.\r\n   */\n\n\n  get key() {\n    return this.ref.key;\n  }\n  /** Returns the number of child properties of this `DataSnapshot`. */\n\n\n  get size() {\n    return this._node.numChildren();\n  }\n  /**\r\n   * Gets another `DataSnapshot` for the location at the specified relative path.\r\n   *\r\n   * Passing a relative path to the `child()` method of a DataSnapshot returns\r\n   * another `DataSnapshot` for the location at the specified relative path. The\r\n   * relative path can either be a simple child name (for example, \"ada\") or a\r\n   * deeper, slash-separated path (for example, \"ada/name/first\"). If the child\r\n   * location has no data, an empty `DataSnapshot` (that is, a `DataSnapshot`\r\n   * whose value is `null`) is returned.\r\n   *\r\n   * @param path - A relative path to the location of child data.\r\n   */\n\n\n  child(path) {\n    const childPath = new Path(path);\n    const childRef = child(this.ref, path);\n    return new DataSnapshot(this._node.getChild(childPath), childRef, PRIORITY_INDEX);\n  }\n  /**\r\n   * Returns true if this `DataSnapshot` contains any data. It is slightly more\r\n   * efficient than using `snapshot.val() !== null`.\r\n   */\n\n\n  exists() {\n    return !this._node.isEmpty();\n  }\n  /**\r\n   * Exports the entire contents of the DataSnapshot as a JavaScript object.\r\n   *\r\n   * The `exportVal()` method is similar to `val()`, except priority information\r\n   * is included (if available), making it suitable for backing up your data.\r\n   *\r\n   * @returns The DataSnapshot's contents as a JavaScript value (Object,\r\n   *   Array, string, number, boolean, or `null`).\r\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\n  exportVal() {\n    return this._node.val(true);\n  }\n  /**\r\n   * Enumerates the top-level children in the `DataSnapshot`.\r\n   *\r\n   * Because of the way JavaScript objects work, the ordering of data in the\r\n   * JavaScript object returned by `val()` is not guaranteed to match the\r\n   * ordering on the server nor the ordering of `onChildAdded()` events. That is\r\n   * where `forEach()` comes in handy. It guarantees the children of a\r\n   * `DataSnapshot` will be iterated in their query order.\r\n   *\r\n   * If no explicit `orderBy*()` method is used, results are returned\r\n   * ordered by key (unless priorities are used, in which case, results are\r\n   * returned by priority).\r\n   *\r\n   * @param action - A function that will be called for each child DataSnapshot.\r\n   * The callback can return true to cancel further enumeration.\r\n   * @returns true if enumeration was canceled due to your callback returning\r\n   * true.\r\n   */\n\n\n  forEach(action) {\n    if (this._node.isLeafNode()) {\n      return false;\n    }\n\n    const childrenNode = this._node; // Sanitize the return value to a boolean. ChildrenNode.forEachChild has a weird return type...\n\n    return !!childrenNode.forEachChild(this._index, (key, node) => {\n      return action(new DataSnapshot(node, child(this.ref, key), PRIORITY_INDEX));\n    });\n  }\n  /**\r\n   * Returns true if the specified child path has (non-null) data.\r\n   *\r\n   * @param path - A relative path to the location of a potential child.\r\n   * @returns `true` if data exists at the specified child path; else\r\n   *  `false`.\r\n   */\n\n\n  hasChild(path) {\n    const childPath = new Path(path);\n    return !this._node.getChild(childPath).isEmpty();\n  }\n  /**\r\n   * Returns whether or not the `DataSnapshot` has any non-`null` child\r\n   * properties.\r\n   *\r\n   * You can use `hasChildren()` to determine if a `DataSnapshot` has any\r\n   * children. If it does, you can enumerate them using `forEach()`. If it\r\n   * doesn't, then either this snapshot contains a primitive value (which can be\r\n   * retrieved with `val()`) or it is empty (in which case, `val()` will return\r\n   * `null`).\r\n   *\r\n   * @returns true if this snapshot has any children; else false.\r\n   */\n\n\n  hasChildren() {\n    if (this._node.isLeafNode()) {\n      return false;\n    } else {\n      return !this._node.isEmpty();\n    }\n  }\n  /**\r\n   * Returns a JSON-serializable representation of this object.\r\n   */\n\n\n  toJSON() {\n    return this.exportVal();\n  }\n  /**\r\n   * Extracts a JavaScript value from a `DataSnapshot`.\r\n   *\r\n   * Depending on the data in a `DataSnapshot`, the `val()` method may return a\r\n   * scalar type (string, number, or boolean), an array, or an object. It may\r\n   * also return null, indicating that the `DataSnapshot` is empty (contains no\r\n   * data).\r\n   *\r\n   * @returns The DataSnapshot's contents as a JavaScript value (Object,\r\n   *   Array, string, number, boolean, or `null`).\r\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\n  val() {\n    return this._node.val();\n  }\n\n}\n/**\r\n *\r\n * Returns a `Reference` representing the location in the Database\r\n * corresponding to the provided path. If no path is provided, the `Reference`\r\n * will point to the root of the Database.\r\n *\r\n * @param db - The database instance to obtain a reference for.\r\n * @param path - Optional path representing the location the returned\r\n *   `Reference` will point. If not provided, the returned `Reference` will\r\n *   point to the root of the Database.\r\n * @returns If a path is provided, a `Reference`\r\n *   pointing to the provided path. Otherwise, a `Reference` pointing to the\r\n *   root of the Database.\r\n */\n\n\nfunction ref(db, path) {\n  db = getModularInstance(db);\n\n  db._checkNotDeleted('ref');\n\n  return path !== undefined ? child(db._root, path) : db._root;\n}\n/**\r\n * Returns a `Reference` representing the location in the Database\r\n * corresponding to the provided Firebase URL.\r\n *\r\n * An exception is thrown if the URL is not a valid Firebase Database URL or it\r\n * has a different domain than the current `Database` instance.\r\n *\r\n * Note that all query parameters (`orderBy`, `limitToLast`, etc.) are ignored\r\n * and are not applied to the returned `Reference`.\r\n *\r\n * @param db - The database instance to obtain a reference for.\r\n * @param url - The Firebase URL at which the returned `Reference` will\r\n *   point.\r\n * @returns A `Reference` pointing to the provided\r\n *   Firebase URL.\r\n */\n\n\nfunction refFromURL(db, url) {\n  db = getModularInstance(db);\n\n  db._checkNotDeleted('refFromURL');\n\n  const parsedURL = parseRepoInfo(url, db._repo.repoInfo_.nodeAdmin);\n  validateUrl('refFromURL', parsedURL);\n  const repoInfo = parsedURL.repoInfo;\n\n  if (!db._repo.repoInfo_.isCustomHost() && repoInfo.host !== db._repo.repoInfo_.host) {\n    fatal('refFromURL' + ': Host name does not match the current database: ' + '(found ' + repoInfo.host + ' but expected ' + db._repo.repoInfo_.host + ')');\n  }\n\n  return ref(db, parsedURL.path.toString());\n}\n/**\r\n * Gets a `Reference` for the location at the specified relative path.\r\n *\r\n * The relative path can either be a simple child name (for example, \"ada\") or\r\n * a deeper slash-separated path (for example, \"ada/name/first\").\r\n *\r\n * @param parent - The parent location.\r\n * @param path - A relative path from this location to the desired child\r\n *   location.\r\n * @returns The specified child location.\r\n */\n\n\nfunction child(parent, path) {\n  parent = getModularInstance(parent);\n\n  if (pathGetFront(parent._path) === null) {\n    validateRootPathString('child', 'path', path, false);\n  } else {\n    validatePathString('child', 'path', path, false);\n  }\n\n  return new ReferenceImpl(parent._repo, pathChild(parent._path, path));\n}\n/**\r\n * Returns an `OnDisconnect` object - see\r\n * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\r\n * for more information on how to use it.\r\n *\r\n * @param ref - The reference to add OnDisconnect triggers for.\r\n */\n\n\nfunction onDisconnect(ref) {\n  ref = getModularInstance(ref);\n  return new OnDisconnect(ref._repo, ref._path);\n}\n/**\r\n * Generates a new child location using a unique key and returns its\r\n * `Reference`.\r\n *\r\n * This is the most common pattern for adding data to a collection of items.\r\n *\r\n * If you provide a value to `push()`, the value is written to the\r\n * generated location. If you don't pass a value, nothing is written to the\r\n * database and the child remains empty (but you can use the `Reference`\r\n * elsewhere).\r\n *\r\n * The unique keys generated by `push()` are ordered by the current time, so the\r\n * resulting list of items is chronologically sorted. The keys are also\r\n * designed to be unguessable (they contain 72 random bits of entropy).\r\n *\r\n * See {@link https://firebase.google.com/docs/database/web/lists-of-data#append_to_a_list_of_data | Append to a list of data}\r\n * </br>See {@link ttps://firebase.googleblog.com/2015/02/the-2120-ways-to-ensure-unique_68.html | The 2^120 Ways to Ensure Unique Identifiers}\r\n *\r\n * @param parent - The parent location.\r\n * @param value - Optional value to be written at the generated location.\r\n * @returns Combined `Promise` and `Reference`; resolves when write is complete,\r\n * but can be used immediately as the `Reference` to the child location.\r\n */\n\n\nfunction push(parent, value) {\n  parent = getModularInstance(parent);\n  validateWritablePath('push', parent._path);\n  validateFirebaseDataArg('push', value, parent._path, true);\n  const now = repoServerTime(parent._repo);\n  const name = nextPushId(now); // push() returns a ThennableReference whose promise is fulfilled with a\n  // regular Reference. We use child() to create handles to two different\n  // references. The first is turned into a ThennableReference below by adding\n  // then() and catch() methods and is used as the return value of push(). The\n  // second remains a regular Reference and is used as the fulfilled value of\n  // the first ThennableReference.\n\n  const thennablePushRef = child(parent, name);\n  const pushRef = child(parent, name);\n  let promise;\n\n  if (value != null) {\n    promise = set(pushRef, value).then(() => pushRef);\n  } else {\n    promise = Promise.resolve(pushRef);\n  }\n\n  thennablePushRef.then = promise.then.bind(promise);\n  thennablePushRef.catch = promise.then.bind(promise, undefined);\n  return thennablePushRef;\n}\n/**\r\n * Removes the data at this Database location.\r\n *\r\n * Any data at child locations will also be deleted.\r\n *\r\n * The effect of the remove will be visible immediately and the corresponding\r\n * event 'value' will be triggered. Synchronization of the remove to the\r\n * Firebase servers will also be started, and the returned Promise will resolve\r\n * when complete. If provided, the onComplete callback will be called\r\n * asynchronously after synchronization has finished.\r\n *\r\n * @param ref - The location to remove.\r\n * @returns Resolves when remove on server is complete.\r\n */\n\n\nfunction remove(ref) {\n  validateWritablePath('remove', ref._path);\n  return set(ref, null);\n}\n/**\r\n * Writes data to this Database location.\r\n *\r\n * This will overwrite any data at this location and all child locations.\r\n *\r\n * The effect of the write will be visible immediately, and the corresponding\r\n * events (\"value\", \"child_added\", etc.) will be triggered. Synchronization of\r\n * the data to the Firebase servers will also be started, and the returned\r\n * Promise will resolve when complete. If provided, the `onComplete` callback\r\n * will be called asynchronously after synchronization has finished.\r\n *\r\n * Passing `null` for the new value is equivalent to calling `remove()`; namely,\r\n * all data at this location and all child locations will be deleted.\r\n *\r\n * `set()` will remove any priority stored at this location, so if priority is\r\n * meant to be preserved, you need to use `setWithPriority()` instead.\r\n *\r\n * Note that modifying data with `set()` will cancel any pending transactions\r\n * at that location, so extreme care should be taken if mixing `set()` and\r\n * `transaction()` to modify the same data.\r\n *\r\n * A single `set()` will generate a single \"value\" event at the location where\r\n * the `set()` was performed.\r\n *\r\n * @param ref - The location to write to.\r\n * @param value - The value to be written (string, number, boolean, object,\r\n *   array, or null).\r\n * @returns Resolves when write to server is complete.\r\n */\n\n\nfunction set(ref, value) {\n  ref = getModularInstance(ref);\n  validateWritablePath('set', ref._path);\n  validateFirebaseDataArg('set', value, ref._path, false);\n  const deferred = new Deferred();\n  repoSetWithPriority(ref._repo, ref._path, value,\n  /*priority=*/\n  null, deferred.wrapCallback(() => {}));\n  return deferred.promise;\n}\n/**\r\n * Sets a priority for the data at this Database location.\r\n *\r\n * Applications need not use priority but can order collections by\r\n * ordinary properties (see\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data | Sorting and filtering data}\r\n * ).\r\n *\r\n * @param ref - The location to write to.\r\n * @param priority - The priority to be written (string, number, or null).\r\n * @returns Resolves when write to server is complete.\r\n */\n\n\nfunction setPriority(ref, priority) {\n  ref = getModularInstance(ref);\n  validateWritablePath('setPriority', ref._path);\n  validatePriority('setPriority', priority, false);\n  const deferred = new Deferred();\n  repoSetWithPriority(ref._repo, pathChild(ref._path, '.priority'), priority, null, deferred.wrapCallback(() => {}));\n  return deferred.promise;\n}\n/**\r\n * Writes data the Database location. Like `set()` but also specifies the\r\n * priority for that data.\r\n *\r\n * Applications need not use priority but can order collections by\r\n * ordinary properties (see\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data | Sorting and filtering data}\r\n * ).\r\n *\r\n * @param ref - The location to write to.\r\n * @param value - The value to be written (string, number, boolean, object,\r\n *   array, or null).\r\n * @param priority - The priority to be written (string, number, or null).\r\n * @returns Resolves when write to server is complete.\r\n */\n\n\nfunction setWithPriority(ref, value, priority) {\n  validateWritablePath('setWithPriority', ref._path);\n  validateFirebaseDataArg('setWithPriority', value, ref._path, false);\n  validatePriority('setWithPriority', priority, false);\n\n  if (ref.key === '.length' || ref.key === '.keys') {\n    throw 'setWithPriority failed: ' + ref.key + ' is a read-only object.';\n  }\n\n  const deferred = new Deferred();\n  repoSetWithPriority(ref._repo, ref._path, value, priority, deferred.wrapCallback(() => {}));\n  return deferred.promise;\n}\n/**\r\n * Writes multiple values to the Database at once.\r\n *\r\n * The `values` argument contains multiple property-value pairs that will be\r\n * written to the Database together. Each child property can either be a simple\r\n * property (for example, \"name\") or a relative path (for example,\r\n * \"name/first\") from the current location to the data to update.\r\n *\r\n * As opposed to the `set()` method, `update()` can be use to selectively update\r\n * only the referenced properties at the current location (instead of replacing\r\n * all the child properties at the current location).\r\n *\r\n * The effect of the write will be visible immediately, and the corresponding\r\n * events ('value', 'child_added', etc.) will be triggered. Synchronization of\r\n * the data to the Firebase servers will also be started, and the returned\r\n * Promise will resolve when complete. If provided, the `onComplete` callback\r\n * will be called asynchronously after synchronization has finished.\r\n *\r\n * A single `update()` will generate a single \"value\" event at the location\r\n * where the `update()` was performed, regardless of how many children were\r\n * modified.\r\n *\r\n * Note that modifying data with `update()` will cancel any pending\r\n * transactions at that location, so extreme care should be taken if mixing\r\n * `update()` and `transaction()` to modify the same data.\r\n *\r\n * Passing `null` to `update()` will remove the data at this location.\r\n *\r\n * See\r\n * {@link https://firebase.googleblog.com/2015/09/introducing-multi-location-updates-and_86.html | Introducing multi-location updates and more}.\r\n *\r\n * @param ref - The location to write to.\r\n * @param values - Object containing multiple values.\r\n * @returns Resolves when update on server is complete.\r\n */\n\n\nfunction update(ref, values) {\n  validateFirebaseMergeDataArg('update', values, ref._path, false);\n  const deferred = new Deferred();\n  repoUpdate(ref._repo, ref._path, values, deferred.wrapCallback(() => {}));\n  return deferred.promise;\n}\n/**\r\n * Gets the most up-to-date result for this query.\r\n *\r\n * @param query - The query to run.\r\n * @returns A `Promise` which resolves to the resulting DataSnapshot if a value is\r\n * available, or rejects if the client is unable to return a value (e.g., if the\r\n * server is unreachable and there is nothing cached).\r\n */\n\n\nfunction get(query) {\n  query = getModularInstance(query);\n  return repoGetValue(query._repo, query).then(node => {\n    return new DataSnapshot(node, new ReferenceImpl(query._repo, query._path), query._queryParams.getIndex());\n  });\n}\n/**\r\n * Represents registration for 'value' events.\r\n */\n\n\nclass ValueEventRegistration {\n  constructor(callbackContext) {\n    this.callbackContext = callbackContext;\n  }\n\n  respondsTo(eventType) {\n    return eventType === 'value';\n  }\n\n  createEvent(change, query) {\n    const index = query._queryParams.getIndex();\n\n    return new DataEvent('value', this, new DataSnapshot(change.snapshotNode, new ReferenceImpl(query._repo, query._path), index));\n  }\n\n  getEventRunner(eventData) {\n    if (eventData.getEventType() === 'cancel') {\n      return () => this.callbackContext.onCancel(eventData.error);\n    } else {\n      return () => this.callbackContext.onValue(eventData.snapshot, null);\n    }\n  }\n\n  createCancelEvent(error, path) {\n    if (this.callbackContext.hasCancelCallback) {\n      return new CancelEvent(this, error, path);\n    } else {\n      return null;\n    }\n  }\n\n  matches(other) {\n    if (!(other instanceof ValueEventRegistration)) {\n      return false;\n    } else if (!other.callbackContext || !this.callbackContext) {\n      // If no callback specified, we consider it to match any callback.\n      return true;\n    } else {\n      return other.callbackContext.matches(this.callbackContext);\n    }\n  }\n\n  hasAnyCallback() {\n    return this.callbackContext !== null;\n  }\n\n}\n/**\r\n * Represents the registration of a child_x event.\r\n */\n\n\nclass ChildEventRegistration {\n  constructor(eventType, callbackContext) {\n    this.eventType = eventType;\n    this.callbackContext = callbackContext;\n  }\n\n  respondsTo(eventType) {\n    let eventToCheck = eventType === 'children_added' ? 'child_added' : eventType;\n    eventToCheck = eventToCheck === 'children_removed' ? 'child_removed' : eventToCheck;\n    return this.eventType === eventToCheck;\n  }\n\n  createCancelEvent(error, path) {\n    if (this.callbackContext.hasCancelCallback) {\n      return new CancelEvent(this, error, path);\n    } else {\n      return null;\n    }\n  }\n\n  createEvent(change, query) {\n    assert(change.childName != null, 'Child events should have a childName.');\n    const childRef = child(new ReferenceImpl(query._repo, query._path), change.childName);\n\n    const index = query._queryParams.getIndex();\n\n    return new DataEvent(change.type, this, new DataSnapshot(change.snapshotNode, childRef, index), change.prevName);\n  }\n\n  getEventRunner(eventData) {\n    if (eventData.getEventType() === 'cancel') {\n      return () => this.callbackContext.onCancel(eventData.error);\n    } else {\n      return () => this.callbackContext.onValue(eventData.snapshot, eventData.prevName);\n    }\n  }\n\n  matches(other) {\n    if (other instanceof ChildEventRegistration) {\n      return this.eventType === other.eventType && (!this.callbackContext || !other.callbackContext || this.callbackContext.matches(other.callbackContext));\n    }\n\n    return false;\n  }\n\n  hasAnyCallback() {\n    return !!this.callbackContext;\n  }\n\n}\n\nfunction addEventListener(query, eventType, callback, cancelCallbackOrListenOptions, options) {\n  let cancelCallback;\n\n  if (typeof cancelCallbackOrListenOptions === 'object') {\n    cancelCallback = undefined;\n    options = cancelCallbackOrListenOptions;\n  }\n\n  if (typeof cancelCallbackOrListenOptions === 'function') {\n    cancelCallback = cancelCallbackOrListenOptions;\n  }\n\n  if (options && options.onlyOnce) {\n    const userCallback = callback;\n\n    const onceCallback = (dataSnapshot, previousChildName) => {\n      repoRemoveEventCallbackForQuery(query._repo, query, container);\n      userCallback(dataSnapshot, previousChildName);\n    };\n\n    onceCallback.userCallback = callback.userCallback;\n    onceCallback.context = callback.context;\n    callback = onceCallback;\n  }\n\n  const callbackContext = new CallbackContext(callback, cancelCallback || undefined);\n  const container = eventType === 'value' ? new ValueEventRegistration(callbackContext) : new ChildEventRegistration(eventType, callbackContext);\n  repoAddEventCallbackForQuery(query._repo, query, container);\n  return () => repoRemoveEventCallbackForQuery(query._repo, query, container);\n}\n\nfunction onValue(query, callback, cancelCallbackOrListenOptions, options) {\n  return addEventListener(query, 'value', callback, cancelCallbackOrListenOptions, options);\n}\n\nfunction onChildAdded(query, callback, cancelCallbackOrListenOptions, options) {\n  return addEventListener(query, 'child_added', callback, cancelCallbackOrListenOptions, options);\n}\n\nfunction onChildChanged(query, callback, cancelCallbackOrListenOptions, options) {\n  return addEventListener(query, 'child_changed', callback, cancelCallbackOrListenOptions, options);\n}\n\nfunction onChildMoved(query, callback, cancelCallbackOrListenOptions, options) {\n  return addEventListener(query, 'child_moved', callback, cancelCallbackOrListenOptions, options);\n}\n\nfunction onChildRemoved(query, callback, cancelCallbackOrListenOptions, options) {\n  return addEventListener(query, 'child_removed', callback, cancelCallbackOrListenOptions, options);\n}\n/**\r\n * Detaches a callback previously attached with `on()`.\r\n *\r\n * Detach a callback previously attached with `on()`. Note that if `on()` was\r\n * called multiple times with the same eventType and callback, the callback\r\n * will be called multiple times for each event, and `off()` must be called\r\n * multiple times to remove the callback. Calling `off()` on a parent listener\r\n * will not automatically remove listeners registered on child nodes, `off()`\r\n * must also be called on any child listeners to remove the callback.\r\n *\r\n * If a callback is not specified, all callbacks for the specified eventType\r\n * will be removed. Similarly, if no eventType is specified, all callbacks\r\n * for the `Reference` will be removed.\r\n *\r\n * Individual listeners can also be removed by invoking their unsubscribe\r\n * callbacks.\r\n *\r\n * @param query - The query that the listener was registered with.\r\n * @param eventType - One of the following strings: \"value\", \"child_added\",\r\n * \"child_changed\", \"child_removed\", or \"child_moved.\" If omitted, all callbacks\r\n * for the `Reference` will be removed.\r\n * @param callback - The callback function that was passed to `on()` or\r\n * `undefined` to remove all callbacks.\r\n */\n\n\nfunction off(query, eventType, callback) {\n  let container = null;\n  const expCallback = callback ? new CallbackContext(callback) : null;\n\n  if (eventType === 'value') {\n    container = new ValueEventRegistration(expCallback);\n  } else if (eventType) {\n    container = new ChildEventRegistration(eventType, expCallback);\n  }\n\n  repoRemoveEventCallbackForQuery(query._repo, query, container);\n}\n/**\r\n * A `QueryConstraint` is used to narrow the set of documents returned by a\r\n * Database query. `QueryConstraint`s are created by invoking {@link endAt},\r\n * {@link endBefore}, {@link startAt}, {@link startAfter}, {@link\r\n * limitToFirst}, {@link limitToLast}, {@link orderByChild},\r\n * {@link orderByChild}, {@link orderByKey} , {@link orderByPriority} ,\r\n * {@link orderByValue}  or {@link equalTo} and\r\n * can then be passed to {@link query} to create a new query instance that\r\n * also contains this `QueryConstraint`.\r\n */\n\n\nclass QueryConstraint {}\n\nclass QueryEndAtConstraint extends QueryConstraint {\n  constructor(_value, _key) {\n    super();\n    this._value = _value;\n    this._key = _key;\n  }\n\n  _apply(query) {\n    validateFirebaseDataArg('endAt', this._value, query._path, true);\n    const newParams = queryParamsEndAt(query._queryParams, this._value, this._key);\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n\n    if (query._queryParams.hasEnd()) {\n      throw new Error('endAt: Starting point was already set (by another call to endAt, ' + 'endBefore or equalTo).');\n    }\n\n    return new QueryImpl(query._repo, query._path, newParams, query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a `QueryConstraint` with the specified ending point.\r\n *\r\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\r\n * allows you to choose arbitrary starting and ending points for your queries.\r\n *\r\n * The ending point is inclusive, so children with exactly the specified value\r\n * will be included in the query. The optional key argument can be used to\r\n * further limit the range of the query. If it is specified, then children that\r\n * have exactly the specified value must also have a key name less than or equal\r\n * to the specified key.\r\n *\r\n * You can read more about `endAt()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\r\n *\r\n * @param value - The value to end at. The argument type depends on which\r\n * `orderBy*()` function was used in this query. Specify a value that matches\r\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\r\n * value must be a string.\r\n * @param key - The child key to end at, among the children with the previously\r\n * specified priority. This argument is only allowed if ordering by child,\r\n * value, or priority.\r\n */\n\n\nfunction endAt(value, key) {\n  validateKey('endAt', 'key', key, true);\n  return new QueryEndAtConstraint(value, key);\n}\n\nclass QueryEndBeforeConstraint extends QueryConstraint {\n  constructor(_value, _key) {\n    super();\n    this._value = _value;\n    this._key = _key;\n  }\n\n  _apply(query) {\n    validateFirebaseDataArg('endBefore', this._value, query._path, false);\n    const newParams = queryParamsEndBefore(query._queryParams, this._value, this._key);\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n\n    if (query._queryParams.hasEnd()) {\n      throw new Error('endBefore: Starting point was already set (by another call to endAt, ' + 'endBefore or equalTo).');\n    }\n\n    return new QueryImpl(query._repo, query._path, newParams, query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a `QueryConstraint` with the specified ending point (exclusive).\r\n *\r\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\r\n * allows you to choose arbitrary starting and ending points for your queries.\r\n *\r\n * The ending point is exclusive. If only a value is provided, children\r\n * with a value less than the specified value will be included in the query.\r\n * If a key is specified, then children must have a value lesss than or equal\r\n * to the specified value and a a key name less than the specified key.\r\n *\r\n * @param value - The value to end before. The argument type depends on which\r\n * `orderBy*()` function was used in this query. Specify a value that matches\r\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\r\n * value must be a string.\r\n * @param key - The child key to end before, among the children with the\r\n * previously specified priority. This argument is only allowed if ordering by\r\n * child, value, or priority.\r\n */\n\n\nfunction endBefore(value, key) {\n  validateKey('endBefore', 'key', key, true);\n  return new QueryEndBeforeConstraint(value, key);\n}\n\nclass QueryStartAtConstraint extends QueryConstraint {\n  constructor(_value, _key) {\n    super();\n    this._value = _value;\n    this._key = _key;\n  }\n\n  _apply(query) {\n    validateFirebaseDataArg('startAt', this._value, query._path, true);\n    const newParams = queryParamsStartAt(query._queryParams, this._value, this._key);\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n\n    if (query._queryParams.hasStart()) {\n      throw new Error('startAt: Starting point was already set (by another call to startAt, ' + 'startBefore or equalTo).');\n    }\n\n    return new QueryImpl(query._repo, query._path, newParams, query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a `QueryConstraint` with the specified starting point.\r\n *\r\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\r\n * allows you to choose arbitrary starting and ending points for your queries.\r\n *\r\n * The starting point is inclusive, so children with exactly the specified value\r\n * will be included in the query. The optional key argument can be used to\r\n * further limit the range of the query. If it is specified, then children that\r\n * have exactly the specified value must also have a key name greater than or\r\n * equal to the specified key.\r\n *\r\n * You can read more about `startAt()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\r\n *\r\n * @param value - The value to start at. The argument type depends on which\r\n * `orderBy*()` function was used in this query. Specify a value that matches\r\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\r\n * value must be a string.\r\n * @param key - The child key to start at. This argument is only allowed if\r\n * ordering by child, value, or priority.\r\n */\n\n\nfunction startAt(value = null, key) {\n  validateKey('startAt', 'key', key, true);\n  return new QueryStartAtConstraint(value, key);\n}\n\nclass QueryStartAfterConstraint extends QueryConstraint {\n  constructor(_value, _key) {\n    super();\n    this._value = _value;\n    this._key = _key;\n  }\n\n  _apply(query) {\n    validateFirebaseDataArg('startAfter', this._value, query._path, false);\n    const newParams = queryParamsStartAfter(query._queryParams, this._value, this._key);\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n\n    if (query._queryParams.hasStart()) {\n      throw new Error('startAfter: Starting point was already set (by another call to startAt, ' + 'startAfter, or equalTo).');\n    }\n\n    return new QueryImpl(query._repo, query._path, newParams, query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a `QueryConstraint` with the specified starting point (exclusive).\r\n *\r\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\r\n * allows you to choose arbitrary starting and ending points for your queries.\r\n *\r\n * The starting point is exclusive. If only a value is provided, children\r\n * with a value greater than the specified value will be included in the query.\r\n * If a key is specified, then children must have a value greater than or equal\r\n * to the specified value and a a key name greater than the specified key.\r\n *\r\n * @param value - The value to start after. The argument type depends on which\r\n * `orderBy*()` function was used in this query. Specify a value that matches\r\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\r\n * value must be a string.\r\n * @param key - The child key to start after. This argument is only allowed if\r\n * ordering by child, value, or priority.\r\n */\n\n\nfunction startAfter(value, key) {\n  validateKey('startAfter', 'key', key, true);\n  return new QueryStartAfterConstraint(value, key);\n}\n\nclass QueryLimitToFirstConstraint extends QueryConstraint {\n  constructor(_limit) {\n    super();\n    this._limit = _limit;\n  }\n\n  _apply(query) {\n    if (query._queryParams.hasLimit()) {\n      throw new Error('limitToFirst: Limit was already set (by another call to limitToFirst ' + 'or limitToLast).');\n    }\n\n    return new QueryImpl(query._repo, query._path, queryParamsLimitToFirst(query._queryParams, this._limit), query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that if limited to the first specific number\r\n * of children.\r\n *\r\n * The `limitToFirst()` method is used to set a maximum number of children to be\r\n * synced for a given callback. If we set a limit of 100, we will initially only\r\n * receive up to 100 `child_added` events. If we have fewer than 100 messages\r\n * stored in our Database, a `child_added` event will fire for each message.\r\n * However, if we have over 100 messages, we will only receive a `child_added`\r\n * event for the first 100 ordered messages. As items change, we will receive\r\n * `child_removed` events for each item that drops out of the active list so\r\n * that the total number stays at 100.\r\n *\r\n * You can read more about `limitToFirst()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\r\n *\r\n * @param limit - The maximum number of nodes to include in this query.\r\n */\n\n\nfunction limitToFirst(limit) {\n  if (typeof limit !== 'number' || Math.floor(limit) !== limit || limit <= 0) {\n    throw new Error('limitToFirst: First argument must be a positive integer.');\n  }\n\n  return new QueryLimitToFirstConstraint(limit);\n}\n\nclass QueryLimitToLastConstraint extends QueryConstraint {\n  constructor(_limit) {\n    super();\n    this._limit = _limit;\n  }\n\n  _apply(query) {\n    if (query._queryParams.hasLimit()) {\n      throw new Error('limitToLast: Limit was already set (by another call to limitToFirst ' + 'or limitToLast).');\n    }\n\n    return new QueryImpl(query._repo, query._path, queryParamsLimitToLast(query._queryParams, this._limit), query._orderByCalled);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that is limited to return only the last\r\n * specified number of children.\r\n *\r\n * The `limitToLast()` method is used to set a maximum number of children to be\r\n * synced for a given callback. If we set a limit of 100, we will initially only\r\n * receive up to 100 `child_added` events. If we have fewer than 100 messages\r\n * stored in our Database, a `child_added` event will fire for each message.\r\n * However, if we have over 100 messages, we will only receive a `child_added`\r\n * event for the last 100 ordered messages. As items change, we will receive\r\n * `child_removed` events for each item that drops out of the active list so\r\n * that the total number stays at 100.\r\n *\r\n * You can read more about `limitToLast()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\r\n *\r\n * @param limit - The maximum number of nodes to include in this query.\r\n */\n\n\nfunction limitToLast(limit) {\n  if (typeof limit !== 'number' || Math.floor(limit) !== limit || limit <= 0) {\n    throw new Error('limitToLast: First argument must be a positive integer.');\n  }\n\n  return new QueryLimitToLastConstraint(limit);\n}\n\nclass QueryOrderByChildConstraint extends QueryConstraint {\n  constructor(_path) {\n    super();\n    this._path = _path;\n  }\n\n  _apply(query) {\n    validateNoPreviousOrderByCall(query, 'orderByChild');\n    const parsedPath = new Path(this._path);\n\n    if (pathIsEmpty(parsedPath)) {\n      throw new Error('orderByChild: cannot pass in empty path. Use orderByValue() instead.');\n    }\n\n    const index = new PathIndex(parsedPath);\n    const newParams = queryParamsOrderBy(query._queryParams, index);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(query._repo, query._path, newParams,\n    /*orderByCalled=*/\n    true);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that orders by the specified child key.\r\n *\r\n * Queries can only order by one key at a time. Calling `orderByChild()`\r\n * multiple times on the same query is an error.\r\n *\r\n * Firebase queries allow you to order your data by any child key on the fly.\r\n * However, if you know in advance what your indexes will be, you can define\r\n * them via the .indexOn rule in your Security Rules for better performance. See\r\n * the{@link https://firebase.google.com/docs/database/security/indexing-data}\r\n * rule for more information.\r\n *\r\n * You can read more about `orderByChild()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\r\n *\r\n * @param path - The path to order by.\r\n */\n\n\nfunction orderByChild(path) {\n  if (path === '$key') {\n    throw new Error('orderByChild: \"$key\" is invalid.  Use orderByKey() instead.');\n  } else if (path === '$priority') {\n    throw new Error('orderByChild: \"$priority\" is invalid.  Use orderByPriority() instead.');\n  } else if (path === '$value') {\n    throw new Error('orderByChild: \"$value\" is invalid.  Use orderByValue() instead.');\n  }\n\n  validatePathString('orderByChild', 'path', path, false);\n  return new QueryOrderByChildConstraint(path);\n}\n\nclass QueryOrderByKeyConstraint extends QueryConstraint {\n  _apply(query) {\n    validateNoPreviousOrderByCall(query, 'orderByKey');\n    const newParams = queryParamsOrderBy(query._queryParams, KEY_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(query._repo, query._path, newParams,\n    /*orderByCalled=*/\n    true);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that orders by the key.\r\n *\r\n * Sorts the results of a query by their (ascending) key values.\r\n *\r\n * You can read more about `orderByKey()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\r\n */\n\n\nfunction orderByKey() {\n  return new QueryOrderByKeyConstraint();\n}\n\nclass QueryOrderByPriorityConstraint extends QueryConstraint {\n  _apply(query) {\n    validateNoPreviousOrderByCall(query, 'orderByPriority');\n    const newParams = queryParamsOrderBy(query._queryParams, PRIORITY_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(query._repo, query._path, newParams,\n    /*orderByCalled=*/\n    true);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that orders by priority.\r\n *\r\n * Applications need not use priority but can order collections by\r\n * ordinary properties (see\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}\r\n * for alternatives to priority.\r\n */\n\n\nfunction orderByPriority() {\n  return new QueryOrderByPriorityConstraint();\n}\n\nclass QueryOrderByValueConstraint extends QueryConstraint {\n  _apply(query) {\n    validateNoPreviousOrderByCall(query, 'orderByValue');\n    const newParams = queryParamsOrderBy(query._queryParams, VALUE_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(query._repo, query._path, newParams,\n    /*orderByCalled=*/\n    true);\n  }\n\n}\n/**\r\n * Creates a new `QueryConstraint` that orders by value.\r\n *\r\n * If the children of a query are all scalar values (string, number, or\r\n * boolean), you can order the results by their (ascending) values.\r\n *\r\n * You can read more about `orderByValue()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\r\n */\n\n\nfunction orderByValue() {\n  return new QueryOrderByValueConstraint();\n}\n\nclass QueryEqualToValueConstraint extends QueryConstraint {\n  constructor(_value, _key) {\n    super();\n    this._value = _value;\n    this._key = _key;\n  }\n\n  _apply(query) {\n    validateFirebaseDataArg('equalTo', this._value, query._path, false);\n\n    if (query._queryParams.hasStart()) {\n      throw new Error('equalTo: Starting point was already set (by another call to startAt/startAfter or ' + 'equalTo).');\n    }\n\n    if (query._queryParams.hasEnd()) {\n      throw new Error('equalTo: Ending point was already set (by another call to endAt/endBefore or ' + 'equalTo).');\n    }\n\n    return new QueryEndAtConstraint(this._value, this._key)._apply(new QueryStartAtConstraint(this._value, this._key)._apply(query));\n  }\n\n}\n/**\r\n * Creates a `QueryConstraint` that includes children that match the specified\r\n * value.\r\n *\r\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\r\n * allows you to choose arbitrary starting and ending points for your queries.\r\n *\r\n * The optional key argument can be used to further limit the range of the\r\n * query. If it is specified, then children that have exactly the specified\r\n * value must also have exactly the specified key as their key name. This can be\r\n * used to filter result sets with many matches for the same value.\r\n *\r\n * You can read more about `equalTo()` in\r\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\r\n *\r\n * @param value - The value to match for. The argument type depends on which\r\n * `orderBy*()` function was used in this query. Specify a value that matches\r\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\r\n * value must be a string.\r\n * @param key - The child key to start at, among the children with the\r\n * previously specified priority. This argument is only allowed if ordering by\r\n * child, value, or priority.\r\n */\n\n\nfunction equalTo(value, key) {\n  validateKey('equalTo', 'key', key, true);\n  return new QueryEqualToValueConstraint(value, key);\n}\n/**\r\n * Creates a new immutable instance of `Query` that is extended to also include\r\n * additional query constraints.\r\n *\r\n * @param query - The Query instance to use as a base for the new constraints.\r\n * @param queryConstraints - The list of `QueryConstraint`s to apply.\r\n * @throws if any of the provided query constraints cannot be combined with the\r\n * existing or new constraints.\r\n */\n\n\nfunction query(query, ...queryConstraints) {\n  let queryImpl = getModularInstance(query);\n\n  for (const constraint of queryConstraints) {\n    queryImpl = constraint._apply(queryImpl);\n  }\n\n  return queryImpl;\n}\n/**\r\n * Define reference constructor in various modules\r\n *\r\n * We are doing this here to avoid several circular\r\n * dependency issues\r\n */\n\n\nsyncPointSetReferenceConstructor(ReferenceImpl);\nsyncTreeSetReferenceConstructor(ReferenceImpl);\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * This variable is also defined in the firebase Node.js Admin SDK. Before\r\n * modifying this definition, consult the definition in:\r\n *\r\n * https://github.com/firebase/firebase-admin-node\r\n *\r\n * and make sure the two are consistent.\r\n */\n\nconst FIREBASE_DATABASE_EMULATOR_HOST_VAR = 'FIREBASE_DATABASE_EMULATOR_HOST';\n/**\r\n * Creates and caches `Repo` instances.\r\n */\n\nconst repos = {};\n/**\r\n * If true, any new `Repo` will be created to use `ReadonlyRestClient` (for testing purposes).\r\n */\n\nlet useRestClient = false;\n/**\r\n * Update an existing `Repo` in place to point to a new host/port.\r\n */\n\nfunction repoManagerApplyEmulatorSettings(repo, host, port, tokenProvider) {\n  repo.repoInfo_ = new RepoInfo(`${host}:${port}`,\n  /* secure= */\n  false, repo.repoInfo_.namespace, repo.repoInfo_.webSocketOnly, repo.repoInfo_.nodeAdmin, repo.repoInfo_.persistenceKey, repo.repoInfo_.includeNamespaceInQueryParams);\n\n  if (tokenProvider) {\n    repo.authTokenProvider_ = tokenProvider;\n  }\n}\n/**\r\n * This function should only ever be called to CREATE a new database instance.\r\n * @internal\r\n */\n\n\nfunction repoManagerDatabaseFromApp(app, authProvider, appCheckProvider, url, nodeAdmin) {\n  let dbUrl = url || app.options.databaseURL;\n\n  if (dbUrl === undefined) {\n    if (!app.options.projectId) {\n      fatal(\"Can't determine Firebase Database URL. Be sure to include \" + ' a Project ID when calling firebase.initializeApp().');\n    }\n\n    log('Using default host for project ', app.options.projectId);\n    dbUrl = `${app.options.projectId}-default-rtdb.firebaseio.com`;\n  }\n\n  let parsedUrl = parseRepoInfo(dbUrl, nodeAdmin);\n  let repoInfo = parsedUrl.repoInfo;\n  let isEmulator;\n  let dbEmulatorHost = undefined;\n\n  if (typeof process !== 'undefined' && process.env) {\n    dbEmulatorHost = process.env[FIREBASE_DATABASE_EMULATOR_HOST_VAR];\n  }\n\n  if (dbEmulatorHost) {\n    isEmulator = true;\n    dbUrl = `http://${dbEmulatorHost}?ns=${repoInfo.namespace}`;\n    parsedUrl = parseRepoInfo(dbUrl, nodeAdmin);\n    repoInfo = parsedUrl.repoInfo;\n  } else {\n    isEmulator = !parsedUrl.repoInfo.secure;\n  }\n\n  const authTokenProvider = nodeAdmin && isEmulator ? new EmulatorTokenProvider(EmulatorTokenProvider.OWNER) : new FirebaseAuthTokenProvider(app.name, app.options, authProvider);\n  validateUrl('Invalid Firebase Database URL', parsedUrl);\n\n  if (!pathIsEmpty(parsedUrl.path)) {\n    fatal('Database URL must point to the root of a Firebase Database ' + '(not including a child path).');\n  }\n\n  const repo = repoManagerCreateRepo(repoInfo, app, authTokenProvider, new AppCheckTokenProvider(app.name, appCheckProvider));\n  return new Database(repo, app);\n}\n/**\r\n * Remove the repo and make sure it is disconnected.\r\n *\r\n */\n\n\nfunction repoManagerDeleteRepo(repo, appName) {\n  const appRepos = repos[appName]; // This should never happen...\n\n  if (!appRepos || appRepos[repo.key] !== repo) {\n    fatal(`Database ${appName}(${repo.repoInfo_}) has already been deleted.`);\n  }\n\n  repoInterrupt(repo);\n  delete appRepos[repo.key];\n}\n/**\r\n * Ensures a repo doesn't already exist and then creates one using the\r\n * provided app.\r\n *\r\n * @param repoInfo - The metadata about the Repo\r\n * @returns The Repo object for the specified server / repoName.\r\n */\n\n\nfunction repoManagerCreateRepo(repoInfo, app, authTokenProvider, appCheckProvider) {\n  let appRepos = repos[app.name];\n\n  if (!appRepos) {\n    appRepos = {};\n    repos[app.name] = appRepos;\n  }\n\n  let repo = appRepos[repoInfo.toURLString()];\n\n  if (repo) {\n    fatal('Database initialized multiple times. Please make sure the format of the database URL matches with each database() call.');\n  }\n\n  repo = new Repo(repoInfo, useRestClient, authTokenProvider, appCheckProvider);\n  appRepos[repoInfo.toURLString()] = repo;\n  return repo;\n}\n/**\r\n * Forces us to use ReadonlyRestClient instead of PersistentConnection for new Repos.\r\n */\n\n\nfunction repoManagerForceRestClient(forceRestClient) {\n  useRestClient = forceRestClient;\n}\n/**\r\n * Class representing a Firebase Realtime Database.\r\n */\n\n\nclass Database {\n  /** @hideconstructor */\n  constructor(_repoInternal,\n  /** The {@link @firebase/app#FirebaseApp} associated with this Realtime Database instance. */\n  app) {\n    this._repoInternal = _repoInternal;\n    this.app = app;\n    /** Represents a `Database` instance. */\n\n    this['type'] = 'database';\n    /** Track if the instance has been used (root or repo accessed) */\n\n    this._instanceStarted = false;\n  }\n\n  get _repo() {\n    if (!this._instanceStarted) {\n      repoStart(this._repoInternal, this.app.options.appId, this.app.options['databaseAuthVariableOverride']);\n      this._instanceStarted = true;\n    }\n\n    return this._repoInternal;\n  }\n\n  get _root() {\n    if (!this._rootInternal) {\n      this._rootInternal = new ReferenceImpl(this._repo, newEmptyPath());\n    }\n\n    return this._rootInternal;\n  }\n\n  _delete() {\n    if (this._rootInternal !== null) {\n      repoManagerDeleteRepo(this._repo, this.app.name);\n      this._repoInternal = null;\n      this._rootInternal = null;\n    }\n\n    return Promise.resolve();\n  }\n\n  _checkNotDeleted(apiName) {\n    if (this._rootInternal === null) {\n      fatal('Cannot call ' + apiName + ' on a deleted database.');\n    }\n  }\n\n}\n\nfunction checkTransportInit() {\n  if (TransportManager.IS_TRANSPORT_INITIALIZED) {\n    warn('Transport has already been initialized. Please call this function before calling ref or setting up a listener');\n  }\n}\n/**\r\n * Force the use of websockets instead of longPolling.\r\n */\n\n\nfunction forceWebSockets() {\n  checkTransportInit();\n  BrowserPollConnection.forceDisallow();\n}\n/**\r\n * Force the use of longPolling instead of websockets. This will be ignored if websocket protocol is used in databaseURL.\r\n */\n\n\nfunction forceLongPolling() {\n  checkTransportInit();\n  WebSocketConnection.forceDisallow();\n  BrowserPollConnection.forceAllow();\n}\n/**\r\n * Returns the instance of the Realtime Database SDK that is associated\r\n * with the provided {@link @firebase/app#FirebaseApp}. Initializes a new instance with\r\n * with default settings if no instance exists or if the existing instance uses\r\n * a custom database URL.\r\n *\r\n * @param app - The {@link @firebase/app#FirebaseApp} instance that the returned Realtime\r\n * Database instance is associated with.\r\n * @param url - The URL of the Realtime Database instance to connect to. If not\r\n * provided, the SDK connects to the default instance of the Firebase App.\r\n * @returns The `Database` instance of the provided app.\r\n */\n\n\nfunction getDatabase(app = getApp(), url) {\n  return _getProvider(app, 'database').getImmediate({\n    identifier: url\n  });\n}\n/**\r\n * Modify the provided instance to communicate with the Realtime Database\r\n * emulator.\r\n *\r\n * <p>Note: This method must be called before performing any other operation.\r\n *\r\n * @param db - The instance to modify.\r\n * @param host - The emulator host (ex: localhost)\r\n * @param port - The emulator port (ex: 8080)\r\n * @param options.mockUserToken - the mock auth token to use for unit testing Security Rules\r\n */\n\n\nfunction connectDatabaseEmulator(db, host, port, options = {}) {\n  db = getModularInstance(db);\n\n  db._checkNotDeleted('useEmulator');\n\n  if (db._instanceStarted) {\n    fatal('Cannot call useEmulator() after instance has already been initialized.');\n  }\n\n  const repo = db._repoInternal;\n  let tokenProvider = undefined;\n\n  if (repo.repoInfo_.nodeAdmin) {\n    if (options.mockUserToken) {\n      fatal('mockUserToken is not supported by the Admin SDK. For client access with mock users, please use the \"firebase\" package instead of \"firebase-admin\".');\n    }\n\n    tokenProvider = new EmulatorTokenProvider(EmulatorTokenProvider.OWNER);\n  } else if (options.mockUserToken) {\n    const token = typeof options.mockUserToken === 'string' ? options.mockUserToken : createMockUserToken(options.mockUserToken, db.app.options.projectId);\n    tokenProvider = new EmulatorTokenProvider(token);\n  } // Modify the repo to apply emulator settings\n\n\n  repoManagerApplyEmulatorSettings(repo, host, port, tokenProvider);\n}\n/**\r\n * Disconnects from the server (all Database operations will be completed\r\n * offline).\r\n *\r\n * The client automatically maintains a persistent connection to the Database\r\n * server, which will remain active indefinitely and reconnect when\r\n * disconnected. However, the `goOffline()` and `goOnline()` methods may be used\r\n * to control the client connection in cases where a persistent connection is\r\n * undesirable.\r\n *\r\n * While offline, the client will no longer receive data updates from the\r\n * Database. However, all Database operations performed locally will continue to\r\n * immediately fire events, allowing your application to continue behaving\r\n * normally. Additionally, each operation performed locally will automatically\r\n * be queued and retried upon reconnection to the Database server.\r\n *\r\n * To reconnect to the Database and begin receiving remote events, see\r\n * `goOnline()`.\r\n *\r\n * @param db - The instance to disconnect.\r\n */\n\n\nfunction goOffline(db) {\n  db = getModularInstance(db);\n\n  db._checkNotDeleted('goOffline');\n\n  repoInterrupt(db._repo);\n}\n/**\r\n * Reconnects to the server and synchronizes the offline Database state\r\n * with the server state.\r\n *\r\n * This method should be used after disabling the active connection with\r\n * `goOffline()`. Once reconnected, the client will transmit the proper data\r\n * and fire the appropriate events so that your client \"catches up\"\r\n * automatically.\r\n *\r\n * @param db - The instance to reconnect.\r\n */\n\n\nfunction goOnline(db) {\n  db = getModularInstance(db);\n\n  db._checkNotDeleted('goOnline');\n\n  repoResume(db._repo);\n}\n\nfunction enableLogging(logger, persistent) {\n  enableLogging$1(logger, persistent);\n}\n/**\r\n * @license\r\n * Copyright 2021 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction registerDatabase(variant) {\n  setSDKVersion(SDK_VERSION$1);\n\n  _registerComponent(new Component('database', (container, {\n    instanceIdentifier: url\n  }) => {\n    const app = container.getProvider('app').getImmediate();\n    const authProvider = container.getProvider('auth-internal');\n    const appCheckProvider = container.getProvider('app-check-internal');\n    return repoManagerDatabaseFromApp(app, authProvider, appCheckProvider, url);\n  }, \"PUBLIC\"\n  /* PUBLIC */\n  ).setMultipleInstances(true));\n\n  registerVersion(name, version, variant); // BUILD_TARGET will be replaced by values like esm5, esm2017, cjs5, etc during the compilation\n\n  registerVersion(name, version, 'esm2017');\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nconst SERVER_TIMESTAMP = {\n  '.sv': 'timestamp'\n};\n/**\r\n * Returns a placeholder value for auto-populating the current timestamp (time\r\n * since the Unix epoch, in milliseconds) as determined by the Firebase\r\n * servers.\r\n */\n\nfunction serverTimestamp() {\n  return SERVER_TIMESTAMP;\n}\n/**\r\n * Returns a placeholder value that can be used to atomically increment the\r\n * current database value by the provided delta.\r\n *\r\n * @param delta - the amount to modify the current value atomically.\r\n * @returns A placeholder value for modifying data atomically server-side.\r\n */\n\n\nfunction increment(delta) {\n  return {\n    '.sv': {\n      'increment': delta\n    }\n  };\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A type for the resolve value of {@link runTransaction}.\r\n */\n\n\nclass TransactionResult {\n  /** @hideconstructor */\n  constructor(\n  /** Whether the transaction was successfully committed. */\n  committed,\n  /** The resulting data snapshot. */\n  snapshot) {\n    this.committed = committed;\n    this.snapshot = snapshot;\n  }\n  /** Returns a JSON-serializable representation of this object. */\n\n\n  toJSON() {\n    return {\n      committed: this.committed,\n      snapshot: this.snapshot.toJSON()\n    };\n  }\n\n}\n/**\r\n * Atomically modifies the data at this location.\r\n *\r\n * Atomically modify the data at this location. Unlike a normal `set()`, which\r\n * just overwrites the data regardless of its previous value, `runTransaction()` is\r\n * used to modify the existing value to a new value, ensuring there are no\r\n * conflicts with other clients writing to the same location at the same time.\r\n *\r\n * To accomplish this, you pass `runTransaction()` an update function which is\r\n * used to transform the current value into a new value. If another client\r\n * writes to the location before your new value is successfully written, your\r\n * update function will be called again with the new current value, and the\r\n * write will be retried. This will happen repeatedly until your write succeeds\r\n * without conflict or you abort the transaction by not returning a value from\r\n * your update function.\r\n *\r\n * Note: Modifying data with `set()` will cancel any pending transactions at\r\n * that location, so extreme care should be taken if mixing `set()` and\r\n * `runTransaction()` to update the same data.\r\n *\r\n * Note: When using transactions with Security and Firebase Rules in place, be\r\n * aware that a client needs `.read` access in addition to `.write` access in\r\n * order to perform a transaction. This is because the client-side nature of\r\n * transactions requires the client to read the data in order to transactionally\r\n * update it.\r\n *\r\n * @param ref - The location to atomically modify.\r\n * @param transactionUpdate - A developer-supplied function which will be passed\r\n * the current data stored at this location (as a JavaScript object). The\r\n * function should return the new value it would like written (as a JavaScript\r\n * object). If `undefined` is returned (i.e. you return with no arguments) the\r\n * transaction will be aborted and the data at this location will not be\r\n * modified.\r\n * @param options - An options object to configure transactions.\r\n * @returns A `Promise` that can optionally be used instead of the `onComplete`\r\n * callback to handle success and failure.\r\n */\n\n\nfunction runTransaction(ref, // eslint-disable-next-line @typescript-eslint/no-explicit-any\ntransactionUpdate, options) {\n  var _a;\n\n  ref = getModularInstance(ref);\n  validateWritablePath('Reference.transaction', ref._path);\n\n  if (ref.key === '.length' || ref.key === '.keys') {\n    throw 'Reference.transaction failed: ' + ref.key + ' is a read-only object.';\n  }\n\n  const applyLocally = (_a = options === null || options === void 0 ? void 0 : options.applyLocally) !== null && _a !== void 0 ? _a : true;\n  const deferred = new Deferred();\n\n  const promiseComplete = (error, committed, node) => {\n    let dataSnapshot = null;\n\n    if (error) {\n      deferred.reject(error);\n    } else {\n      dataSnapshot = new DataSnapshot(node, new ReferenceImpl(ref._repo, ref._path), PRIORITY_INDEX);\n      deferred.resolve(new TransactionResult(committed, dataSnapshot));\n    }\n  }; // Add a watch to make sure we get server updates.\n\n\n  const unwatcher = onValue(ref, () => {});\n  repoStartTransaction(ref._repo, ref._path, transactionUpdate, promiseComplete, unwatcher, applyLocally);\n  return deferred.promise;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nPersistentConnection; // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\nPersistentConnection.prototype.simpleListen = function (pathString, onComplete) {\n  this.sendRequest('q', {\n    p: pathString\n  }, onComplete);\n}; // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\nPersistentConnection.prototype.echo = function (data, onEcho) {\n  this.sendRequest('echo', {\n    d: data\n  }, onEcho);\n}; // RealTimeConnection properties that we use in tests.\n\n\nConnection;\n/**\r\n * @internal\r\n */\n\nconst hijackHash = function (newHash) {\n  const oldPut = PersistentConnection.prototype.put;\n\n  PersistentConnection.prototype.put = function (pathString, data, onComplete, hash) {\n    if (hash !== undefined) {\n      hash = newHash();\n    }\n\n    oldPut.call(this, pathString, data, onComplete, hash);\n  };\n\n  return function () {\n    PersistentConnection.prototype.put = oldPut;\n  };\n};\n\nRepoInfo;\n/**\r\n * Forces the RepoManager to create Repos that use ReadonlyRestClient instead of PersistentConnection.\r\n * @internal\r\n */\n\nconst forceRestClient = function (forceRestClient) {\n  repoManagerForceRestClient(forceRestClient);\n};\n/**\r\n * Firebase Realtime Database\r\n *\r\n * @packageDocumentation\r\n */\n\n\nregisterDatabase();\nexport { DataSnapshot, Database, OnDisconnect, QueryConstraint, TransactionResult, QueryImpl as _QueryImpl, QueryParams as _QueryParams, ReferenceImpl as _ReferenceImpl, forceRestClient as _TEST_ACCESS_forceRestClient, hijackHash as _TEST_ACCESS_hijackHash, repoManagerDatabaseFromApp as _repoManagerDatabaseFromApp, setSDKVersion as _setSDKVersion, validatePathString as _validatePathString, validateWritablePath as _validateWritablePath, child, connectDatabaseEmulator, enableLogging, endAt, endBefore, equalTo, forceLongPolling, forceWebSockets, get, getDatabase, goOffline, goOnline, increment, limitToFirst, limitToLast, off, onChildAdded, onChildChanged, onChildMoved, onChildRemoved, onDisconnect, onValue, orderByChild, orderByKey, orderByPriority, orderByValue, push, query, ref, refFromURL, remove, runTransaction, serverTimestamp, set, setPriority, setWithPriority, startAfter, startAt, update }; //# sourceMappingURL=index.esm2017.js.map","map":null,"metadata":{},"sourceType":"module"}